{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker-sdk extension example using `Trainer` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Sagemaker Session with local AWS Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From outside these notebooks, `get_execution_role()` will return an exception because it does not know what is the role name that SageMaker requires.\n",
    "\n",
    "To solve this issue, pass the IAM role name instead of using `get_execution_role()`.\n",
    "\n",
    "Therefore you have to create an IAM-Role with correct permission for sagemaker to start training jobs and download files from s3. Beware that you need s3 permission on bucket-level `\"arn:aws:s3:::sagemaker-*\"` and on object-level     `\"arn:aws:s3:::sagemaker-*/*\"`. \n",
    "\n",
    "You can read [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) how to create a role with right permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local aws profile configured in ~/.aws/credentials\n",
    "local_profile_name='default' # optional if you only have default configured\n",
    "\n",
    "# role name for sagemaker -> needs the described permissions from above\n",
    "role_name = \"AmazonSageMaker-ExecutionRole-20201222T210251\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name lagunas to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::854676674973:role/service-role/AmazonSageMaker-ExecutionRole-20201222T210251\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "try:\n",
    "    sess = sagemaker.Session()\n",
    "    role = sagemaker.get_execution_role()\n",
    "except Exception:\n",
    "    import boto3\n",
    "    # creates a boto3 session using the local profile we defined\n",
    "    if local_profile_name:\n",
    "        os.environ['AWS_PROFILE'] = local_profile_name # setting env var bc local-mode cannot use boto3 session\n",
    "        #bt3 = boto3.session.Session(profile_name=local_profile_name)\n",
    "        #iam = bt3.client('iam')\n",
    "        # create sagemaker session with boto3 session\n",
    "        #sess = sagemaker.Session(boto_session=bt3)\n",
    "    iam = boto3.client('iam')\n",
    "    sess = sagemaker.Session()\n",
    "    # get role arn\n",
    "    role = iam.get_role(RoleName=role_name)['Role']['Arn']\n",
    "    \n",
    "\n",
    "\n",
    "print(role)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Session prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/imdb/test/dataset.arrow', 'datasets/imdb/test/dataset_info.json', 'datasets/imdb/test/state.json', 'datasets/imdb/train/dataset.arrow', 'datasets/imdb/train/dataset_info.json', 'datasets/imdb/train/state.json']\n",
      "sagemaker-eu-west-1-854676674973\n",
      "eu-west-1\n"
     ]
    }
   ],
   "source": [
    "print(sess.list_s3_files(sess.default_bucket(),'datasets/')) # list objects in s3 under datsets/\n",
    "print(sess.default_bucket()) # s3 bucketname\n",
    "print(sess.boto_region_name) # aws region of sagemaker session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Since we are using the `.py` module directly from `huggingface/` we have to adjust our `sys.path` to be able to import our estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to sagemaker S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an local estimator for testing\n",
    "\n",
    "You run PyTorch training scripts on SageMaker by creating PyTorch Estimators. SageMaker training of your script is invoked when you call fit on a PyTorch Estimator. The following code sample shows how you train a custom PyTorch script `train.py`, passing in three hyperparameters (`epochs`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n",
    "\n",
    "in sagemaker you can test you training in a \"local-mode\" by setting your instance_type to `'local'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing custom sdk-extension for HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface.estimator import HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an local Estimator\n",
    "\n",
    "The following code sample shows how you train a custom HuggingFace script `train.py`, passing in three hyperparameters (`epochs`,`train_batch_size`,`model_name`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn-pruning-v1\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "<huggingface.estimator.HuggingFace object at 0x7ffb35f520d0>\n",
      "2021-01-15 14:36:12,060 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2021-01-15 14:36:12,415 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-15 14:36:12,426 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-15 14:36:39,455 - sagemaker - INFO - Creating training-job with name: nn-pruning-v1-2021-01-15-13-36-11-984\n",
      "2021-01-15 14:36:39,456 - sagemaker.local.local_session - INFO - Starting training job\n",
      "2021-01-15 14:36:39,457 - sagemaker.local.image - INFO - Using the long-lived AWS credentials found in session\n",
      "2021-01-15 14:36:39,459 - sagemaker.local.image - INFO - docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-4uojc:\n",
      "    command: train\n",
      "    environment:\n",
      "    - AWS_ACCESS_KEY_ID=AKIA4N7VTDGO7EVDEQXG\n",
      "    - AWS_SECRET_ACCESS_KEY=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\n",
      "    - AWS_REGION=eu-west-1\n",
      "    - TRAINING_JOB_NAME=nn-pruning-v1-2021-01-15-13-36-11-984\n",
      "    image: 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-4uojc\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmptlzaii6j/algo-1-4uojc/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmptlzaii6j/algo-1-4uojc/output:/opt/ml/output\n",
      "    - /tmp/tmptlzaii6j/algo-1-4uojc/input:/opt/ml/input\n",
      "    - /tmp/tmptlzaii6j/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "version: '2.3'\n",
      "\n",
      "2021-01-15 14:36:39,459 - sagemaker.local.image - INFO - docker command: docker-compose -f /tmp/tmptlzaii6j/docker-compose.yaml up --build --abort-on-container-exit\n",
      "Creating tmptlzaii6j_algo-1-4uojc_1 ... \n",
      "\u001b[1BAttaching to tmptlzaii6j_algo-1-4uojc_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:40,547 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:40,549 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:40,557 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:40,560 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:40,637 botocore.credentials INFO     Found credentials in environment variables.\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:43,933 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:43,943 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:43,953 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m 2021-01-15 13:36:43,962 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"current_host\": \"algo-1-4uojc\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"algo-1-4uojc\"\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"attention-block-rows\": 16,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"attention-block-cols\": 16,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"regularization-final-lambda\": 20.0,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"num-train-epochs\": 0.0005,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"logging-steps\": 20,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"per-device-train-batch-size\": 1\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"job_name\": \"nn-pruning-v1-2021-01-15-13-36-11-984\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"master_hostname\": \"algo-1-4uojc\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-eu-west-1-854676674973/nn-pruning-v1-2021-01-15-13-36-11-984/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"module_name\": \"nn_pruning_train\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"current_host\": \"algo-1-4uojc\",\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m             \"algo-1-4uojc\"\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m     \"user_entry_point\": \"nn_pruning_train.py\"\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_HOSTS=[\"algo-1-4uojc\"]\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_HPS={\"attention-block-cols\":16,\"attention-block-rows\":16,\"logging-steps\":20,\"num-train-epochs\":0.0005,\"per-device-train-batch-size\":1,\"regularization-final-lambda\":20.0}\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_USER_ENTRY_POINT=nn_pruning_train.py\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-4uojc\",\"hosts\":[\"algo-1-4uojc\"]}\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_CURRENT_HOST=algo-1-4uojc\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_MODULE_NAME=nn_pruning_train\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-eu-west-1-854676674973/nn-pruning-v1-2021-01-15-13-36-11-984/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-4uojc\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-4uojc\"],\"hyperparameters\":{\"attention-block-cols\":16,\"attention-block-rows\":16,\"logging-steps\":20,\"num-train-epochs\":0.0005,\"per-device-train-batch-size\":1,\"regularization-final-lambda\":20.0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"nn-pruning-v1-2021-01-15-13-36-11-984\",\"log_level\":20,\"master_hostname\":\"algo-1-4uojc\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-854676674973/nn-pruning-v1-2021-01-15-13-36-11-984/source/sourcedir.tar.gz\",\"module_name\":\"nn_pruning_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-4uojc\",\"hosts\":[\"algo-1-4uojc\"]},\"user_entry_point\":\"nn_pruning_train.py\"}\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_USER_ARGS=[\"--attention-block-cols\",\"16\",\"--attention-block-rows\",\"16\",\"--logging-steps\",\"20\",\"--num-train-epochs\",\"0.0005\",\"--per-device-train-batch-size\",\"1\",\"--regularization-final-lambda\",\"20.0\"]\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_HP_ATTENTION-BLOCK-ROWS=16\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_HP_ATTENTION-BLOCK-COLS=16\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_HP_REGULARIZATION-FINAL-LAMBDA=20.0\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_HP_NUM-TRAIN-EPOCHS=0.0005\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_HP_LOGGING-STEPS=20\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m SM_HP_PER-DEVICE-TRAIN-BATCH-SIZE=1\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages:/root/nn_pruning\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m /opt/conda/bin/python nn_pruning_train.py --attention-block-cols 16 --attention-block-rows 16 --logging-steps 20 --num-train-epochs 0.0005 --per-device-train-batch-size 1 --regularization-final-lambda 20.0\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m ['nn_pruning_train.py', '--attention-block-cols', '16', '--attention-block-rows', '16', '--logging-steps', '20', '--num-train-epochs', '0.0005', '--per-device-train-batch-size', '1', '--regularization-final-lambda', '20.0']\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m {'model_name_or_path': 'bert-base-uncased', 'dataset_name': 'squad', 'do_train': 1, 'do_eval': 1, 'per_device_train_batch_size': 1, 'max_seq_length': 384, 'doc_stride': 128, 'num_train_epochs': 0.0005, 'logging_steps': 20, 'save_steps': 5000, 'eval_steps': 5000, 'save_total_limit': 50, 'seed': 17, 'evaluation_strategy': 'steps', 'learning_rate': 3e-05, 'mask_scores_learning_rate': 0.01, 'output_dir': '/opt/ml/model', 'logging_dir': '/opt/ml/output', 'overwrite_cache': 0, 'overwrite_output_dir': 1, 'warmup_steps': 5400, 'initial_warmup': 1, 'final_warmup': 10, 'initial_threshold': 0, 'final_threshold': 0.1, 'dense_pruning_method': 'sigmoied_threshold:1d_alt', 'dense_block_rows': 1, 'dense_block_cols': 1, 'dense_lambda': 1.0, 'attention_pruning_method': 'sigmoied_threshold', 'attention_block_rows': 16, 'attention_block_cols': 16, 'attention_lambda': 1.0, 'ampere_pruning_method': 'disabled', 'mask_init': 'constant', 'mask_scale': 0.0, 'regularization': 'l1', 'regularization_final_lambda': 20.0, 'distil_teacher_name_or_path': 'csarron/bert-base-uncased-squad-v1', 'distil_alpha_ce': 0.1, 'distil_alpha_teacher': 0.9, 'attention_output_with_dense': 0}\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/output/data\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/input/config/resourceconfig.json\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/input/config/hyperparameters.json\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/input/config/inputdataconfig.json\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/input/data\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/input/config\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/code/dataset_cache/train_dataset\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/code/dataset_cache/eval_dataset\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/code/pad.txt\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/code/nn_pruning_train.py\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/code/train.py\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/code/dataset_cache\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/model\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/output\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/metadata\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/input\r\n",
      "\u001b[36malgo-1-4uojc_1  |\u001b[0m opt:before:/opt/ml/code\r\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-613b573f5485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregu_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/devel/hf/sagemaker-sdk-huggingface/src/huggingface/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# parent fit method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHuggingFace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuggingface_token\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"downloading model to {self.latest_training_job.name}/ \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda-sagemaker/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda-sagemaker/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \"\"\"\n\u001b[1;32m   1417\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda-sagemaker/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/anaconda3/envs/conda-sagemaker/lib/python3.7/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda-sagemaker/lib/python3.7/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda-sagemaker/lib/python3.7/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# _stream_output() doesn't have the command line. We will handle the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conda-sagemaker/lib/python3.7/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "local = True\n",
    "if local:\n",
    "    instance_type = \"local\"\n",
    "    sess = None\n",
    "    batch_size = 1\n",
    "    num_train_epochs = 0.0005\n",
    "    logging_steps=20\n",
    "else:\n",
    "    instance_type = \"ml.p3.2xlarge\"\n",
    "    sagemaker_session=sess\n",
    "    batch_size = 16\n",
    "    num_train_epochs=20\n",
    "    logging_steps=250\n",
    "\n",
    "    \n",
    "    \n",
    "def build_metric_definitions():\n",
    "    ret = []\n",
    "    train_metrics = ['loss',\n",
    " 'learning_rate',\n",
    " 'threshold',\n",
    " 'ampere_temperature',\n",
    " 'regu_lambda',\n",
    " 'ce_loss',\n",
    " 'distil_loss',\n",
    " 'nnz_perc_attention',\n",
    " 'regu_loss_attention',\n",
    " 'nnz_perc_dense',\n",
    " 'regu_loss_dense',\n",
    " 'regu_loss',\n",
    " 'nnz_perc',\n",
    " 'epoch']\n",
    "    eval_metrics = [\"f1\", \"exact_match\"]\n",
    "        \n",
    "    metric_types = {\"train\":(\"\",train_metrics), \"validation\":(\"eval_\", eval_metrics)}\n",
    "    for k, (prefix, metrics) in metric_types.items():\n",
    "        for m in metrics:\n",
    "            ret += {'Name': f\"{k}:{m}\", 'Regex':f\"'{prefix}{m}': (.*?),\"},\n",
    "    return ret\n",
    "        \n",
    "    \n",
    "metric_definitions = build_metric_definitions()\n",
    "\n",
    "from nn_pruning.examples.question_answering.qa_sparse_xp import SparseQAShortNamer\n",
    "\n",
    "def estimator_build(attention:int, regu_lambda:float):\n",
    "    hyperparameters = {\"attention_block_rows\":attention,\n",
    "                       \"attention_block_cols\":attention,\n",
    "                       \"regularization_final_lambda\": regu_lambda,\n",
    "                       \"num_train_epochs\":num_train_epochs,\n",
    "                       \"logging_steps\":logging_steps,\n",
    "                       \"per_device_train_batch_size\":batch_size}\n",
    "    \n",
    "    hyperparameters = {k.replace(\"_\", \"-\"):v for k,v in hyperparameters.items()}\n",
    "\n",
    "    def get_hp_name(hyper_parameters):\n",
    "        p = {k.replace(\"-\", \"_\"):v for k,v in hyper_parameters.items()}    \n",
    "\n",
    "        sn = SparseQAShortNamer()\n",
    "\n",
    "        ret = sn.shortname(p)\n",
    "        return ret\n",
    "\n",
    "    base_job_name = \"nn-pruning-v1\" #+ get_hp_name(hyperparameters)[3:].replace(\".\", \"-\")\n",
    "    print(base_job_name)\n",
    "\n",
    "    huggingface_estimator = HuggingFace(entry_point='nn_pruning_train.py',\n",
    "                                        source_dir='../scripts',\n",
    "                                        sagemaker_session=sess,\n",
    "                                        base_job_name=base_job_name,\n",
    "                                        volume_size=50,\n",
    "                                        instance_type=instance_type,\n",
    "                                        instance_count=1,\n",
    "                                        role=role,\n",
    "                                        framework_version={'transformers':'4.1.1','datasets':'1.1.3'},\n",
    "                                        py_version='py3',\n",
    "                                        metric_definitions = metric_definitions,\n",
    "                                        hyperparameters = hyperparameters)\n",
    "    #print(huggingface_estimator.image_uri)\n",
    "    return huggingface_estimator\n",
    "\n",
    "estimators = []\n",
    "\n",
    "attentions = [16]\n",
    "regu_lambdas = [20.0]\n",
    "for attention in attentions:\n",
    "    for regu_lambda in regu_lambdas:\n",
    "        estimator = estimator_build(attention, regu_lambda)\n",
    "        print(estimator)\n",
    "        estimator.fit(wait = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Estimator\n",
    "\n",
    "The following code sample shows how you train a custom HuggingFace script `train.py`, passing in three hyperparameters (`epochs`,`train_batch_size`,`model_name`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface.estimator import HuggingFace\n",
    "\n",
    "\n",
    "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
    "                            source_dir='../scripts',\n",
    "                            sagemaker_session=sess,\n",
    "                            base_job_name='huggingface-sdk-extension',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            framework_version={'transformers':'4.1.1','datasets':'1.1.3'},\n",
    "                            py_version='py3',\n",
    "                            hyperparameters = {'epochs': 1,\n",
    "                                               'train_batch_size': 32,\n",
    "                                               'model_name':'distilbert-base-uncased'\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get S3 url for model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get latest training job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach to old estimator \n",
    "\n",
    "e.g. to get model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_job_name='huggingface-sdk-extension-2020-12-27-15-25-50-506'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator_loaded = Estimator.attach(old_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_loaded.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model from s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using huggingface utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface.utils import download_model\n",
    "\n",
    "download_model(model_data=huggingface_estimator_loaded.model_data,\n",
    "               unzip=True,\n",
    "               model_dir=huggingface_estimator_loaded.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using class built-in method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.download_model(unzip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access logs\n",
    "\n",
    "until [PR](https://github.com/aws/sagemaker-python-sdk/pull/2059) is merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.sagemaker_session.logs_for_job(huggingface_estimator.latest_training_job.name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**after merged PR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"attention_block_rows\":attention,\n",
    "                   \"attention_block_cols\":attention,\n",
    "                   \"regularization_final_lambda\": regu_lambda,\n",
    "                   \"num_train_epochs\":num_train_epochs,\n",
    "                   \"logging_steps\":logging_steps,\n",
    "                   \"per_device_train_batch_size\":batch_size}\n",
    "hp2 = {k.replace(\"-\", \"_\"):v for k,v in hyperparameters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
