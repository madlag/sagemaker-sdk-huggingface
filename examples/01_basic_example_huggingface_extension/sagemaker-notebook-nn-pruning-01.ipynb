{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker-sdk extension example using `Trainer` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs requirements if you havenÂ´t already done it and sets up ipywidgets for datasets in sagemaker studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os \n",
    "import IPython\n",
    "if 'SAGEMAKER_TRAINING_MODULE' in os.environ:\n",
    "    !conda install -c conda-forge ipywidgets -y\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) # has to restart kernel so changes are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Sagemaker Session with local AWS Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From outside these notebooks, `get_execution_role()` will return an exception because it does not know what is the role name that SageMaker requires.\n",
    "\n",
    "To solve this issue, pass the IAM role name instead of using `get_execution_role()`.\n",
    "\n",
    "Therefore you have to create an IAM-Role with correct permission for sagemaker to start training jobs and download files from s3. Beware that you need s3 permission on bucket-level `\"arn:aws:s3:::sagemaker-*\"` and on object-level     `\"arn:aws:s3:::sagemaker-*/*\"`. \n",
    "\n",
    "You can read [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) how to create a role with right permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local aws profile configured in ~/.aws/credentials\n",
    "local_profile_name='default' # optional if you only have default configured\n",
    "\n",
    "# role name for sagemaker -> needs the described permissions from above\n",
    "role_name = \"AmazonSageMaker-ExecutionRole-20201222T210251\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name lagunas to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::854676674973:role/service-role/AmazonSageMaker-ExecutionRole-20201222T210251\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "try:\n",
    "    sess = sagemaker.Session()\n",
    "    role = sagemaker.get_execution_role()\n",
    "except Exception:\n",
    "    import boto3\n",
    "    # creates a boto3 session using the local profile we defined\n",
    "    if local_profile_name:\n",
    "        os.environ['AWS_PROFILE'] = local_profile_name # setting env var bc local-mode cannot use boto3 session\n",
    "        #bt3 = boto3.session.Session(profile_name=local_profile_name)\n",
    "        #iam = bt3.client('iam')\n",
    "        # create sagemaker session with boto3 session\n",
    "        #sess = sagemaker.Session(boto_session=bt3)\n",
    "    iam = boto3.client('iam')\n",
    "    sess = sagemaker.Session()\n",
    "    # get role arn\n",
    "    role = iam.get_role(RoleName=role_name)['Role']['Arn']\n",
    "    \n",
    "\n",
    "\n",
    "print(role)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Session prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/imdb/test/dataset.arrow', 'datasets/imdb/test/dataset_info.json', 'datasets/imdb/test/state.json', 'datasets/imdb/train/dataset.arrow', 'datasets/imdb/train/dataset_info.json', 'datasets/imdb/train/state.json']\n",
      "sagemaker-eu-west-1-854676674973\n",
      "eu-west-1\n"
     ]
    }
   ],
   "source": [
    "print(sess.list_s3_files(sess.default_bucket(),'datasets/')) # list objects in s3 under datsets/\n",
    "print(sess.default_bucket()) # s3 bucketname\n",
    "print(sess.boto_region_name) # aws region of sagemaker session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Since we are using the `.py` module directly from `huggingface/` we have to adjust our `sys.path` to be able to import our estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to sagemaker S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an local estimator for testing\n",
    "\n",
    "You run PyTorch training scripts on SageMaker by creating PyTorch Estimators. SageMaker training of your script is invoked when you call fit on a PyTorch Estimator. The following code sample shows how you train a custom PyTorch script `train.py`, passing in three hyperparameters (`epochs`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n",
    "\n",
    "in sagemaker you can test you training in a \"local-mode\" by setting your instance_type to `'local'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing custom sdk-extension for HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface.estimator import HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an local Estimator\n",
    "\n",
    "The following code sample shows how you train a custom HuggingFace script `train.py`, passing in three hyperparameters (`epochs`,`train_batch_size`,`model_name`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn-pruning-nte0-1\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "local = False\n",
    "if local:\n",
    "    instance_type = \"local-gpu\"\n",
    "    sess = None\n",
    "    batch_size = 1\n",
    "else:\n",
    "    instance_type = \"ml.p3.2xlarge\"\n",
    "    sagemaker_session=sess\n",
    "    batch_size = 16\n",
    "\n",
    "    \n",
    "{'loss': 12.476279296875, 'learning_rate': 0.0004629629629629629, 'threshold': 0, 'ampere_temperature': 0.0, 'regu_lambda': 0.0, 'ce_loss': 5.739205135345459, 'distil_loss': 13.224848453521728, 'nnz_perc_attention': 1.0, 'regu_loss_attention': 0.2500004979968071, 'nnz_perc_dense': 1.0, 'regu_loss_dense': 0.24996592348814012, 'regu_loss': 0.49996642220020293, 'nnz_perc': 1.0, 'epoch': 0.04518344478583047}\n",
    "    \n",
    "def build_metric_definitions():\n",
    "    ret = []\n",
    "    train_metrics = ['loss',\n",
    " 'learning_rate',\n",
    " 'threshold',\n",
    " 'ampere_temperature',\n",
    " 'regu_lambda',\n",
    " 'ce_loss',\n",
    " 'distil_loss',\n",
    " 'nnz_perc_attention',\n",
    " 'regu_loss_attention',\n",
    " 'nnz_perc_dense',\n",
    " 'regu_loss_dense',\n",
    " 'regu_loss',\n",
    " 'nnz_perc',\n",
    " 'epoch']\n",
    "    eval_metrics = [\"f1\", \"precision\"]\n",
    "        \n",
    "    metric_types = {\"train\":(\"\",train_metrics), \"validation\":(\"eval_\", eval_metrics)}\n",
    "    for k, (prefix, metrics) in metric_types.items():\n",
    "        for m in metrics:\n",
    "            ret += {'Name': f\"{k}:{m}\", 'Regex':f\"'{prefix}{m}': (.*?),\"},\n",
    "    return ret\n",
    "        \n",
    "\n",
    "    \n",
    "metric_definitions = build_metric_definitions()\n",
    "\n",
    "from nn_pruning.examples.question_answering.qa_sparse_xp import SparseQAShortNamer\n",
    "\n",
    "hyperparameters = {'num-train-epochs': 0.1, \"per-device-train-batch-size\": batch_size}\n",
    "\n",
    "def get_hp_name(hyper_parameters):\n",
    "    p = {k.replace(\"-\", \"_\"):v for k,v in hyper_parameters.items()}    \n",
    "    \n",
    "    sn = SparseQAShortNamer()\n",
    "    \n",
    "    ret = sn.shortname(p)\n",
    "    return ret\n",
    "    \n",
    "base_job_name = \"nn-pruning-\" + get_hp_name(hyperparameters)[3:].replace(\".\", \"-\")\n",
    "print(base_job_name)\n",
    "        \n",
    "huggingface_estimator = HuggingFace(entry_point='nn_pruning_train.py',\n",
    "                                    source_dir='../scripts',\n",
    "                                    sagemaker_session=sess,\n",
    "                                    base_job_name=base_job_name,\n",
    "                                    instance_type=instance_type,\n",
    "                                    instance_count=1,\n",
    "                                    role=role,\n",
    "                                    framework_version={'transformers':'4.1.1','datasets':'1.1.3'},\n",
    "                                    py_version='py3',\n",
    "                                    metric_definitions = metric_definitions,\n",
    "                                    hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator.image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 16:45:13,020 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-14 16:45:13,024 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-14 16:45:13,181 - sagemaker - INFO - Creating training-job with name: nn-pruning-nte0-1-2021-01-14-15-45-12-691\n",
      "2021-01-14 15:45:13 Starting - Starting the training job...\n",
      "2021-01-14 15:45:36 Starting - Launching requested ML instancesProfilerReport-1610639113: InProgress\n",
      "......\n",
      "2021-01-14 15:46:38 Starting - Preparing the instances for training......\n",
      "2021-01-14 15:47:38 Downloading - Downloading input data\n",
      "2021-01-14 15:47:38 Training - Downloading the training image.....................\n",
      "2021-01-14 15:51:20 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-01-14 15:51:14,885 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-01-14 15:51:14,908 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-01-14 15:51:21,278 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-01-14 15:51:21,678 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"per-device-train-batch-size\": 16,\n",
      "        \"num-train-epochs\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"nn-pruning-nte0-1-2021-01-14-15-45-12-691\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-854676674973/nn-pruning-nte0-1-2021-01-14-15-45-12-691/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"nn_pruning_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"nn_pruning_train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"num-train-epochs\":0.1,\"per-device-train-batch-size\":16}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=nn_pruning_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=nn_pruning_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-854676674973/nn-pruning-nte0-1-2021-01-14-15-45-12-691/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"num-train-epochs\":0.1,\"per-device-train-batch-size\":16},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"nn-pruning-nte0-1-2021-01-14-15-45-12-691\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-854676674973/nn-pruning-nte0-1-2021-01-14-15-45-12-691/source/sourcedir.tar.gz\",\"module_name\":\"nn_pruning_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"nn_pruning_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--num-train-epochs\",\"0.1\",\"--per-device-train-batch-size\",\"16\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_PER-DEVICE-TRAIN-BATCH-SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-TRAIN-EPOCHS=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages:/root/nn_pruning\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python nn_pruning_train.py --num-train-epochs 0.1 --per-device-train-batch-size 16\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m['nn_pruning_train.py', '--num-train-epochs', '0.1', '--per-device-train-batch-size', '16']\u001b[0m\n",
      "\u001b[34m{'model_name_or_path': 'bert-base-uncased', 'dataset_name': 'squad', 'do_train': 1, 'do_eval': 1, 'per_device_train_batch_size': 16, 'max_seq_length': 384, 'doc_stride': 128, 'num_train_epochs': 0.1, 'logging_steps': 100, 'save_steps': 5000, 'eval_steps': 250, 'save_total_limit': 5, 'seed': 17, 'evaluation_strategy': 'steps', 'learning_rate': 3e-05, 'mask_scores_learning_rate': 0.01, 'output_dir': '/opt/ml/model', 'logging_dir': '/opt/ml/model', 'overwrite_cache': 0, 'overwrite_output_dir': 1, 'warmup_steps': 5400, 'initial_warmup': 1, 'final_warmup': 10, 'initial_threshold': 0, 'final_threshold': 0.1, 'dense_pruning_method': 'sigmoied_threshold:1d_alt', 'dense_block_rows': 1, 'dense_block_cols': 1, 'dense_lambda': 1.0, 'attention_pruning_method': 'sigmoied_threshold', 'attention_block_rows': 1, 'attention_block_cols': 1, 'attention_lambda': 1.0, 'ampere_pruning_method': 'disabled', 'mask_init': 'constant', 'mask_scale': 0.0, 'regularization': 'l1', 'regularization_final_lambda': 10, 'distil_teacher_name_or_path': 'csarron/bert-base-uncased-squad-v1', 'distil_alpha_ce': 0.1, 'distil_alpha_teacher': 0.9, 'attention_output_with_dense': 0}\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.75 MiB, post-processed: Unknown size, total: 119.27 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41...\u001b[0m\n",
      "\u001b[34mDataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:04.891 algo-1:25 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:04.891 algo-1:25 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:04.891 algo-1:25 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:04.892 algo-1:25 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:04.920 algo-1:25 INFO hook.py:398] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:04.920 algo-1:25 INFO hook.py:461] Hook is writing from the hook with pid: 25\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:05.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:05.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.009 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.010 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.011 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.011 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.019 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.020 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.020 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.020 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.021 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.021 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.022 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.026 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.026 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.030 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.030 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.031 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.031 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.031 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.031 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.034 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.034 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.036 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.036 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.037 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.037 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.042 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.042 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.043 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.044 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.044 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.048 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.049 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.052 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.052 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.054 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.054 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.055 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.056 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.059 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.059 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.059 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.060 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.060 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.061 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.061 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.062 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.063 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.066 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.066 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.072 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.072 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.078 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.078 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.079 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.081 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.081 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.085 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.085 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.092 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.092 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.099 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.099 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.103 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.103 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.114 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.114 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.114 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.114 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.125 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.125 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.136 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.137 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.146 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.146 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.148 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.148 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.152 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.152 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.152 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.152 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.153 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.153 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.154 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.155 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.155 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.159 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.159 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.163 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.163 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.165 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.165 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.167 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.167 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.171 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.171 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.171 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.171 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.173 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.174 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.174 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.178 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.178 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.180 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.180 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.180 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.180 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.182 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.182 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.186 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.186 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.191 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.191 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.192 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.193 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.193 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.197 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.197 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.198 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.199 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.199 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.199 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.201 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.201 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.205 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.205 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.221 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.221 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.221 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.221 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.222 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.222 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.223 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.225 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.225 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.229 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.229 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.231 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.231 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.231 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.232 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.233 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.233 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.235 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.235 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.238 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.238 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.244 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.244 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.244 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.244 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.246 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.246 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.247 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.249 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.249 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.253 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.253 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module int\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.255 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.255 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.256 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.256 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.256 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.256 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:53:06.267 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'loss': 12.78487548828125, 'learning_rate': 0.00018518518518518518, 'threshold': 0, 'ampere_temperature': 0.0, 'regu_lambda': 0.0, 'ce_loss': 5.920670676231384, 'distil_loss': 13.547569284439087, 'nnz_perc_attention': 1.0, 'regu_loss_attention': 0.24999995067715644, 'nnz_perc_dense': 1.0, 'regu_loss_dense': 0.2499970443546772, 'regu_loss': 0.49999699532985686, 'nnz_perc': 1.0, 'epoch': 0.018073377914332188}\u001b[0m\n",
      "\u001b[34m{'loss': 12.50663330078125, 'learning_rate': 0.00037037037037037035, 'threshold': 0, 'ampere_temperature': 0.0, 'regu_lambda': 0.0, 'ce_loss': 5.75607280254364, 'distil_loss': 13.256698904037476, 'nnz_perc_attention': 1.0, 'regu_loss_attention': 0.25000024259090425, 'nnz_perc_dense': 1.0, 'regu_loss_dense': 0.2499660810828209, 'regu_loss': 0.4999663245677948, 'nnz_perc': 1.0, 'epoch': 0.036146755828664376}\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.014 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.015 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.016 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.016 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.017 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.017 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.018 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.018 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.018 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.018 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.019 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.019 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.020 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.021 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.021 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.023 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.023 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.024 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.024 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.024 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.024 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.025 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.026 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.027 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.027 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.028 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.028 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.029 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.029 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.029 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.029 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.030 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.030 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.031 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.032 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.032 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.035 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.035 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.035 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.036 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.036 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.036 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.037 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.037 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.039 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.039 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.040 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.040 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.042 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.043 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.043 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.044 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.045 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.045 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.047 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.047 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.048 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.048 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.048 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.048 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.051 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.051 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.052 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.052 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.053 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.053 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.053 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.053 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.054 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.055 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.055 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.056 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.056 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.059 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.059 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.059 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.059 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.060 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.060 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.061 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.061 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.062 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.062 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.063 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.064 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.065 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.065 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.065 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.065 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.066 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.066 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.066 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.072 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.072 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.074 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.075 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.075 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.076 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.076 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.076 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.076 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.078 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.079 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.079 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.081 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.081 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.082 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.082 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.082 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.082 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.083 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.083 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.085 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.085 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.089 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.092 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.092 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.095 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.095 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.099 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.106 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.106 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.109 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.109 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.109 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.112 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.112 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.119 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.119 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.120 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.128 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.128 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.131 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.131 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.132 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.132 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.137 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.137 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.137 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.139 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.139 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.143 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.143 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.143 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.143 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.145 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.146 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.146 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.148 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.148 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:56:07.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-01-14 15:57:09.878 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.878 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.879 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.879 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.880 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.880 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.881 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.882 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.882 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.882 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.883 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.883 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.884 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.885 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.885 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.887 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.887 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.888 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.888 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.888 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.888 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.889 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.889 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.891 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.891 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.892 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.892 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.894 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.894 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.894 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.894 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.895 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.895 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.896 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.897 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.897 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.899 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.899 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.900 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.900 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.900 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.900 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.901 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.901 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.903 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.903 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.904 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.904 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.905 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.905 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.905 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.905 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.906 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.906 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.907 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.908 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.908 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.910 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.910 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.911 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.911 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.911 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.911 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.912 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.913 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.914 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.914 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.915 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.915 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.916 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.916 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.916 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.916 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.917 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.917 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.918 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.919 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.919 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.921 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.922 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.922 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.922 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.922 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.922 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.924 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.924 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.925 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.925 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.926 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.926 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.927 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.927 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.928 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.928 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.929 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.929 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.929 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.931 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.931 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.933 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.933 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.934 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.934 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.934 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.934 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.935 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.935 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.936 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.937 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.938 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.938 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.939 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.939 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.939 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.939 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.940 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.940 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.941 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.942 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.942 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.944 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.944 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.945 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.945 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.945 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.945 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.946 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.946 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.947 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.948 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.949 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.949 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.950 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.950 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.950 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.950 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.951 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.951 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.952 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.953 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.953 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.955 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.955 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.956 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.956 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.956 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.956 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.957 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.958 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.959 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.959 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.960 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.960 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.961 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.961 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.961 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.962 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.963 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.963 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.963 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.964 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.964 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.967 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.967 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.967 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.967 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.968 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.968 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.969 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.969 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.970 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.970 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.971 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.972 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.973 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.973 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.973 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.973 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.974 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.974 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.974 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.976 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.976 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.978 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.978 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.979 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.979 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.979 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.979 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.980 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.980 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.981 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.982 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.983 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.983 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.984 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.984 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.984 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.984 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.985 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.985 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.986 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.987 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.987 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.989 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.989 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.990 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.990 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.990 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.990 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.991 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.991 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.992 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.993 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.994 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.994 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.995 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.995 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.995 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.995 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.996 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.996 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.997 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.998 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:09.998 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.000 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.000 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.001 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.001 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.001 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.001 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.002 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.002 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.004 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.004 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.005 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.005 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.006 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.006 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.006 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.006 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.007 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.007 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.008 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.009 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.009 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.011 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.011 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.012 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.012 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.012 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.012 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.012 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.013 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:57:10.013 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-01-14 15:58:12.750 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.751 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.752 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.752 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.753 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.753 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.754 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.754 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.754 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.754 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.755 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.755 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.756 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.757 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.757 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.759 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.759 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.760 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.760 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.760 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.760 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.762 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.762 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.763 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.763 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.764 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.764 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.765 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.765 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.765 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.766 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.767 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.767 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.767 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.768 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.768 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.771 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.771 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.771 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.771 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.772 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.772 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.773 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.773 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.774 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.774 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.776 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.776 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.777 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.777 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.777 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.777 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.778 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.778 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.779 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.780 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.780 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.782 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.782 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.783 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.783 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.783 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.783 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.784 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.784 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.786 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.786 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.787 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.787 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.788 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.788 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.788 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.788 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.789 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.789 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.790 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.791 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.791 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.793 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.793 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.794 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.794 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.794 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.794 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.796 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.796 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.797 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.797 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.798 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.798 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.799 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.799 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.799 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.800 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.801 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.801 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.801 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.802 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.802 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.805 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.805 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.805 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.806 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.806 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.806 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.807 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.807 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.808 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.808 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.810 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.810 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.811 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.811 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.811 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.811 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.812 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.812 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.813 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.814 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.814 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.816 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.816 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.817 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.817 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.817 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.817 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.819 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.819 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.820 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.820 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.821 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.821 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.822 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.822 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.822 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.823 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.823 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.824 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.824 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.825 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.825 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.828 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.828 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.828 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.828 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.829 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.829 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.830 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.830 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.831 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.831 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.833 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.833 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.834 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.834 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.834 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.834 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.835 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.835 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.836 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.837 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.837 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.839 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.839 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.840 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.840 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.840 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.840 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.841 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.841 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.843 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.843 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.844 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.844 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.845 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.845 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.845 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.845 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.846 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.846 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.847 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.848 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.848 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.850 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.851 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.851 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.851 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.851 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.851 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.853 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.853 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.854 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.854 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.855 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.855 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.856 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.857 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.857 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.857 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.858 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.858 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.858 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.860 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.860 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.862 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.862 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.863 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.863 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.863 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.863 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.864 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.864 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.865 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.865 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.867 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.867 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.868 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.868 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.868 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.868 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.869 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.869 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.870 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.871 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.871 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.873 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.873 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.874 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.874 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.874 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.874 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.875 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.875 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.877 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.877 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.878 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.878 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.879 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.879 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.879 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.879 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.880 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.880 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.881 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.882 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.882 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.884 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.884 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.885 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.885 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.885 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.885 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.885 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.886 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 15:58:12.886 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'eval_exact_match': 1.315042573320719, 'eval_f1': 9.593677739438615, 'eval_threshold': 0.1, 'eval_ampere_temperature': 20.0, 'eval_regu_lambda': 10.0, 'ce_loss': 5.342538719177246, 'distil_loss': 12.515705890655518, 'nnz_perc_attention': 1.0, 'regu_loss_attention': 0.2500021034479141, 'nnz_perc_dense': 1.0, 'regu_loss_dense': 0.24990336656570433, 'regu_loss': 0.4999054712057114, 'nnz_perc': 1.0, 'epoch': 0.04518344478583047}\u001b[0m\n",
      "\u001b[34m{'loss': 11.19134765625, 'learning_rate': 0.0005555555555555556, 'threshold': 0, 'ampere_temperature': 0.0, 'regu_lambda': 0.0, 'ce_loss': 4.896269073486328, 'distil_loss': 11.216312217712403, 'nnz_perc_attention': 1.0, 'regu_loss_attention': 0.2500062555074692, 'nnz_perc_dense': 1.0, 'regu_loss_dense': 0.24983613640069963, 'regu_loss': 0.4998423945903778, 'nnz_perc': 1.0, 'epoch': 0.054220133742996564}\u001b[0m\n",
      "\u001b[34m{'loss': 9.512986450195312, 'learning_rate': 0.0007407407407407407, 'threshold': 0, 'ampere_temperature': 0.0, 'regu_lambda': 0.0, 'ce_loss': 4.499001407623291, 'distil_loss': 10.070096473693848, 'nnz_perc_attention': 1.0, 'regu_loss_attention': 0.25001847177743913, 'nnz_perc_dense': 1.0, 'regu_loss_dense': 0.2496576315164566, 'regu_loss': 0.49967610657215117, 'nnz_perc': 1.0, 'epoch': 0.07229351165732875}\u001b[0m\n",
      "\u001b[34m{'loss': 8.217581176757813, 'learning_rate': 0.0009259259259259259, 'threshold': 0, 'ampere_temperature': 0.0, 'regu_lambda': 0.0, 'ce_loss': 3.980504114627838, 'distil_loss': 8.688368811607361, 'nnz_perc_attention': 1.0, 'regu_loss_attention': 0.25004928082227706, 'nnz_perc_dense': 1.0, 'regu_loss_dense': 0.24939026683568954, 'regu_loss': 0.49943954825401304, 'nnz_perc': 1.0, 'epoch': 0.09036688957166095}\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.634 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.634 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.635 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.635 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.636 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.637 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.637 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.638 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.638 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.638 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.639 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.639 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.639 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.641 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.641 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.643 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.643 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.644 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.644 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.644 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.644 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.645 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.645 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.647 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.647 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.648 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.648 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.649 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.649 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.649 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.649 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.650 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.650 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.651 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.652 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.652 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.654 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.655 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.655 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.655 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.655 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.655 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.657 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.657 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.658 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.658 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.659 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.659 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.660 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.661 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.661 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.661 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.662 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.662 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.662 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.664 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.664 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.666 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.666 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.667 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.667 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.667 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.667 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.668 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.668 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.669 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.670 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.671 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.671 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.672 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.672 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.672 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.672 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.673 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.673 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.674 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.675 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.675 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.677 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.677 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.678 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.678 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.678 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.678 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.680 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.680 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.681 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.681 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.682 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.682 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.683 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.683 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.684 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.684 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.685 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.685 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.685 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.687 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.687 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.689 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.689 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.690 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.690 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.690 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.690 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.691 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.691 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.692 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.693 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.694 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.694 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.695 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.695 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.695 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.695 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.696 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.696 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.697 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.698 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.698 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.700 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.700 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.701 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.701 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.701 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.701 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.703 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.703 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.704 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.704 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.705 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.705 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.706 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.706 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.707 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.707 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.708 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.708 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.708 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.709 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.710 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.712 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.712 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.713 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.713 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.713 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.713 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.714 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.714 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.715 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.715 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.717 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.717 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.718 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.718 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.718 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.718 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.719 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.719 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.720 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.721 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.721 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.723 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.723 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.724 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.724 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.724 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.724 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.725 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.726 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.727 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.727 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.728 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.728 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.729 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.729 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.729 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.729 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.730 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.731 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.731 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.732 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.732 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.735 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.735 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.735 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.735 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.736 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.736 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.737 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.737 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.738 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.738 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.740 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.740 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.741 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.741 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.741 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.741 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.742 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.742 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.743 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.744 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.744 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.746 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.746 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.747 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.747 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.747 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.747 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.748 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.748 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.750 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.750 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.751 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.751 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.752 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.752 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.752 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.752 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.753 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.753 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.754 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.755 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.755 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.757 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.758 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.758 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.758 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.758 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.758 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.760 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.760 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.761 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.761 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.762 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.762 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.763 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.764 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.764 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.764 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.765 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.765 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.765 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.767 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.767 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.769 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.769 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.770 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.770 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.770 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.770 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.770 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.770 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:02:02.771 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-01-14 16:03:06.006 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.006 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.007 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.008 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.009 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.009 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.010 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.010 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.010 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.010 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.011 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.011 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.012 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.013 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.013 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.015 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.015 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.016 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.016 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.016 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.016 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.017 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.017 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.019 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.019 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.020 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.020 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.021 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.021 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.021 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.021 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.022 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.022 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.023 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.024 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.024 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.026 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.026 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.027 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.027 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.027 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.027 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.029 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.029 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.030 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.030 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.031 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.031 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.032 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.032 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.033 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.033 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.034 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.034 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.034 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.035 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.036 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.038 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.038 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.039 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.039 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.039 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.039 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.040 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.040 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.041 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.043 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.043 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.044 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.044 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.044 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.044 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.045 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.045 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.046 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.047 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.047 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.049 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.049 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.050 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.051 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.051 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.053 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.053 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.054 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.054 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.055 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.055 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.055 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.055 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.056 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.057 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.057 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.058 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.058 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.061 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.061 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.061 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.061 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.062 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.062 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.063 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.063 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.064 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.064 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.066 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.066 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.067 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.067 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.067 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.067 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.069 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.072 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.072 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.074 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.074 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.076 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.076 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.078 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.078 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.078 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.078 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.079 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.079 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.080 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.081 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.081 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.085 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.089 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.091 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.091 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.091 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.095 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.095 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.102 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.102 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.103 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.106 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.106 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.112 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.112 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.112 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.112 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.113 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.113 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.114 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.120 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.120 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.124 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.125 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.125 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.125 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.131 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.131 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.132 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.132 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.136 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.136 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.137 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:03:06.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-01-14 16:04:09.067 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.068 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.069 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.069 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.070 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.071 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.072 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.073 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.074 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.074 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.077 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.078 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.079 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.079 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.080 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.080 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.081 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.082 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.082 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.083 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.083 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.083 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.089 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.089 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.089 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.089 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.091 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.091 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.094 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.094 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.094 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.094 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.095 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.095 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.099 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.099 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.103 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.103 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.105 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.106 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.106 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.112 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.113 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.114 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.114 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.119 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.119 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.124 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.124 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.125 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.125 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.128 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.136 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.136 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.139 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.139 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.139 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.139 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.142 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.145 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.145 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.145 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.145 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.146 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.146 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.148 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.148 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.151 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.151 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.152 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.153 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.153 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.155 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.155 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.156 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.156 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.156 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.156 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.157 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.158 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.159 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.159 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.160 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.160 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.162 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.162 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.163 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.164 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.164 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.166 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.166 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.167 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.167 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.167 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.167 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.169 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.169 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.170 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.170 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.171 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.171 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.173 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.174 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.174 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.174 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.175 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.175 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.178 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.178 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.178 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.178 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.179 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.179 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.180 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.180 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.181 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.181 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.184 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.184 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.184 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.184 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.185 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.185 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.186 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.187 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.187 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.189 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.189 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.191 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.191 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.193 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.193 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.194 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.194 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.196 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.196 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.196 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.196 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.197 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.197 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.198 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.199 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.199 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.202 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.202 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:04:09.204 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'eval_exact_match': 14.3519394512772, 'eval_f1': 26.77266717929784, 'eval_threshold': 0.1, 'eval_ampere_temperature': 20.0, 'eval_regu_lambda': 10.0, 'epoch': 0.09036688957166095}\u001b[0m\n",
      "\u001b[34m{'threshold': 0, 'ampere_temperature': 0.0, 'regu_lambda': 0.0, 'ce_loss': 3.323194795184665, 'distil_loss': 7.077506692321212, 'nnz_perc_attention': 1.0, 'regu_loss_attention': 0.25007145051602964, 'nnz_perc_dense': 1.0, 'regu_loss_dense': 0.24922610405418608, 'regu_loss': 0.49929755705374257, 'nnz_perc': 1.0, 'epoch': 0.10012651364540033}\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.083 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.083 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.084 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.085 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.086 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.087 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.088 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.089 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.090 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.092 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.092 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.093 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.094 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.095 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.096 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.097 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.098 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.099 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.099 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.100 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.101 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.103 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.104 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.106 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.106 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.107 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.108 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.109 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.109 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.110 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.111 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.112 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.113 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.115 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.116 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.117 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.118 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.120 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.120 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.121 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.122 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.123 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.124 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.124 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.126 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.127 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.129 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.130 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.131 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.131 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.132 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.132 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.132 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.133 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.134 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.135 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.138 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.139 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.139 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.140 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.141 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.143 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.143 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.144 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.145 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.145 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.146 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.147 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.147 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.149 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.150 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.151 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.151 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.152 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.153 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.154 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.154 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.155 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.155 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.155 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.155 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.156 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.156 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.157 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.158 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.158 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.160 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.160 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.161 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.162 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.162 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.164 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.164 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.165 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.165 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.166 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.166 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.166 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.166 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.167 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.167 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.168 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.169 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.169 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.171 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.171 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.172 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.174 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.174 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.175 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.175 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.176 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.176 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.177 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.177 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.177 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.177 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.178 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.179 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.179 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.180 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.180 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.183 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.184 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.185 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.185 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.186 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.186 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.187 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.188 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.189 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.189 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.189 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.189 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.190 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.192 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.192 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.194 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.194 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.195 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.195 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.195 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.195 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.196 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.196 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.197 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.198 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.199 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.199 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.200 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.200 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.200 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.200 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.201 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.201 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.202 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.203 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.205 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.205 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.206 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.206 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.206 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.206 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.207 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.207 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.209 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.209 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.210 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.210 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.211 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.211 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.211 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.211 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.212 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.212 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.213 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.214 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.214 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.216 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.217 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.217 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.217 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.217 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.217 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.217 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.218 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:06:27.218 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-01-14 16:07:30.288 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.288 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.290 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.290 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.291 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.291 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.292 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.292 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.292 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.292 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.293 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.293 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.294 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.295 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.295 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.297 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.298 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.298 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.298 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.298 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.298 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.300 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.300 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.301 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.301 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.302 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.302 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.303 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.303 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.304 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.304 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.305 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.305 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.305 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.306 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.307 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.309 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.309 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.310 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.310 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.310 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.310 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.311 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.311 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.312 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.312 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.314 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.314 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.315 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.315 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.315 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.315 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.316 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.316 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.317 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.318 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.318 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.320 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.320 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.321 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.321 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.321 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.321 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.322 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.322 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.324 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.324 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.325 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.325 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.326 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.326 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.326 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.326 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.327 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.327 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.328 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.329 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.329 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.331 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.331 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.332 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.332 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.332 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.332 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.334 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.334 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.335 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.335 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.336 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.336 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.337 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.337 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.337 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.338 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.339 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.339 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.339 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.340 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.341 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.343 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.343 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.343 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.344 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.344 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.344 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.345 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.345 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.346 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.346 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.348 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.348 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.349 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.349 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.349 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.349 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.350 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.350 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.351 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.352 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.352 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.354 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.354 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.355 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.355 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.355 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.355 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.356 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.356 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.358 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.358 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.359 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.359 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.360 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.360 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.360 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.360 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.361 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.361 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.362 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.363 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.363 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.365 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.365 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.366 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.366 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.366 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.366 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.368 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.368 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.369 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.369 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.370 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.370 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.371 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.371 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.371 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.371 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.372 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.373 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.373 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.374 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.374 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.377 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.377 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.377 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.377 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.377 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.378 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.379 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.379 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.380 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.380 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.381 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.382 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.382 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.383 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.383 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.383 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.384 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.384 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.384 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.386 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.386 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.388 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.388 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.389 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.389 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.389 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.389 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.390 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.390 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.391 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.392 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.393 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.393 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.394 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.394 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.394 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.394 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.395 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.395 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.396 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.397 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.397 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.399 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.399 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.400 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.400 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.400 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.400 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.401 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.401 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.403 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.403 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.404 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.404 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.405 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.405 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.405 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.405 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.406 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.406 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.407 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.408 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.408 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.411 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.411 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.411 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.411 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.411 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.411 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.413 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.413 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.414 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.414 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.415 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.415 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.416 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.417 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.417 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.417 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.418 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.418 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.418 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.419 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.420 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.422 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.422 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.422 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.423 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.423 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.423 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.423 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.423 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:07:30.423 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-01-14 16:08:33.493 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.493 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.494 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.494 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.496 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.496 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.497 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.497 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.497 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.497 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.498 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.498 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.499 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.500 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.500 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.502 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.502 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.503 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.503 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.503 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.503 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.0 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.504 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.505 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.506 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.506 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.507 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.507 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.508 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.508 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.508 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.509 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.510 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.510 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.510 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.511 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.511 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.514 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.514 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.514 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.514 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.515 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.515 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.1 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.516 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.516 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.517 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.517 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.518 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.519 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.519 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.520 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.520 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.520 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.521 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.521 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.521 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.523 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.523 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.525 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.525 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.526 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.526 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.526 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.526 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.2 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.527 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.527 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.528 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.529 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.530 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.530 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.531 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.531 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.531 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.531 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.532 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.532 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.533 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.534 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.534 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.536 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.537 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.537 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.537 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.537 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.537 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.3 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.539 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.539 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.540 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.540 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.541 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.541 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.542 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.542 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.542 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.543 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.544 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.544 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.544 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.545 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.545 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.548 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.548 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.548 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.548 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.549 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.549 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.4 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.550 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.550 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.551 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.551 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.553 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.553 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.554 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.554 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.554 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.554 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.555 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.555 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.556 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.557 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.557 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.559 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.559 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.560 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.560 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.560 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.561 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.5 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.562 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.562 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.563 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.563 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.565 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.565 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.566 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.566 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.566 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.566 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.567 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.568 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.568 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.570 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.570 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.572 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.572 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.573 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.573 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.573 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.573 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.6 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.574 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.574 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.575 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.576 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.577 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.577 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.578 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.578 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.578 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.578 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.579 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.579 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.580 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.581 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.581 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.583 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.583 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.584 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.584 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.584 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.584 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.7 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.585 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.585 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.587 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.587 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.588 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.588 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.589 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.589 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.589 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.589 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.590 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.590 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.591 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.592 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.592 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.594 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.594 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.595 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.595 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.595 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.595 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.8 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.597 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.597 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.598 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.598 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.599 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.599 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.600 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.600 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.600 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.601 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.602 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.602 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.602 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.603 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.603 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.606 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.606 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.606 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.606 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.606 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.607 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.9 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.608 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.608 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.609 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.609 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.610 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.611 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.612 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.612 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.612 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.612 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.613 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.613 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.613 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.615 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.615 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.617 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.617 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.618 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.618 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.618 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.618 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.10 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.619 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.619 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.query.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.620 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.621 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.key.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.622 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.622 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self.value.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.623 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.623 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.623 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.623 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.self bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.624 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.624 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.625 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.attention NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.626 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.626 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.intermediate.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.628 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module Parameter\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.628 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11.output.dense.mask_module float\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.629 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.629 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.629 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 NoneType\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.629 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder.layer.11 bool\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.629 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert.encoder BaseModelOutputWithCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.630 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:bert BaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\n",
      "\u001b[34m[2021-01-14 16:08:33.630 algo-1:25 WARNING hook.py:978] var is not Tensor or list or tuple of Tensors, module_name:BertForQuestionAnswering QuestionAnsweringModelOutput\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m01/14/2021 15:51:25 - INFO - __main__ -   Training/evaluation parameters {'model_name_or_path': 'bert-base-uncased', 'dataset_name': 'squad', 'do_train': 1, 'do_eval': 1, 'per_device_train_batch_size': 16, 'max_seq_length': 384, 'doc_stride': 128, 'num_train_epochs': 0.1, 'logging_steps': 100, 'save_steps': 5000, 'eval_steps': 250, 'save_total_limit': 5, 'seed': 17, 'evaluation_strategy': 'steps', 'learning_rate': 3e-05, 'mask_scores_learning_rate': 0.01, 'output_dir': '/opt/ml/model', 'logging_dir': '/opt/ml/model', 'overwrite_cache': 0, 'overwrite_output_dir': 1, 'warmup_steps': 5400, 'initial_warmup': 1, 'final_warmup': 10, 'initial_threshold': 0, 'final_threshold': 0.1, 'dense_pruning_method': 'sigmoied_threshold:1d_alt', 'dense_block_rows': 1, 'dense_block_cols': 1, 'dense_lambda': 1.0, 'attention_pruning_method': 'sigmoied_threshold', 'attention_block_rows': 1, 'attention_block_cols': 1, 'attention_lambda': 1.0, 'ampere_pruning_method': 'disabled', 'mask_init': 'constant', 'mask_scale': 0.0, 'regularization': 'l1', 'regularization_final_lambda': 10, 'distil_teacher_name_or_path': 'csarron/bert-base-uncased-squad-v1', 'distil_alpha_ce': 0.1, 'distil_alpha_teacher': 0.9, 'attention_output_with_dense': 0}\u001b[0m\n",
      "\u001b[34m[INFO|training_args.py:453] 2021-01-14 15:51:26,030 >> PyTorch: setting up devices\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:26 - INFO - filelock -   Lock 140187688386288 acquired on /root/.cache/huggingface/transformers/640b91f8033e2e306d54097441ba060de086cfa8e2b334fc6ca7a40de0f56ed2.1afc8e7ce4fe9efe54e1f9ac968f42b33a2baac9f294d23e1123658693b0ec80.lock\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1301] 2021-01-14 15:51:26,303 >> https://huggingface.co/csarron/bert-base-uncased-squad-v1/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp9irdsfhf\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/477 [00:00<?, ?B/s]#015Downloading: 100%|ââââââââââ| 477/477 [00:00<00:00, 523kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1305] 2021-01-14 15:51:26,521 >> storing https://huggingface.co/csarron/bert-base-uncased-squad-v1/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/640b91f8033e2e306d54097441ba060de086cfa8e2b334fc6ca7a40de0f56ed2.1afc8e7ce4fe9efe54e1f9ac968f42b33a2baac9f294d23e1123658693b0ec80\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1308] 2021-01-14 15:51:26,521 >> creating metadata file for /root/.cache/huggingface/transformers/640b91f8033e2e306d54097441ba060de086cfa8e2b334fc6ca7a40de0f56ed2.1afc8e7ce4fe9efe54e1f9ac968f42b33a2baac9f294d23e1123658693b0ec80\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:26 - INFO - filelock -   Lock 140187688386288 released on /root/.cache/huggingface/transformers/640b91f8033e2e306d54097441ba060de086cfa8e2b334fc6ca7a40de0f56ed2.1afc8e7ce4fe9efe54e1f9ac968f42b33a2baac9f294d23e1123658693b0ec80.lock\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:431] 2021-01-14 15:51:26,522 >> loading configuration file https://huggingface.co/csarron/bert-base-uncased-squad-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/640b91f8033e2e306d54097441ba060de086cfa8e2b334fc6ca7a40de0f56ed2.1afc8e7ce4fe9efe54e1f9ac968f42b33a2baac9f294d23e1123658693b0ec80\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:467] 2021-01-14 15:51:26,522 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:26 - INFO - filelock -   Lock 140187688383208 acquired on /root/.cache/huggingface/transformers/cc49866c357ded9e5e5047656847944e31b4fdbac69bd2ddd8567352acac8973.9113a3a907fc5caecafe526ef30b1b18dd4dcc741d60cb2080ae038c9b3b0cba.lock\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1301] 2021-01-14 15:51:26,740 >> https://huggingface.co/csarron/bert-base-uncased-squad-v1/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpdqbyjim0\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]#015Downloading:   1%|          | 2.65M/438M [00:00<00:16, 26.5MB/s]#015Downloading:   2%|â         | 7.03M/438M [00:00<00:14, 30.0MB/s]#015Downloading:   3%|â         | 11.6M/438M [00:00<00:12, 33.5MB/s]#015Downloading:   4%|â         | 15.9M/438M [00:00<00:11, 35.8MB/s]#015Downloading:   5%|â         | 20.4M/438M [00:00<00:10, 38.3MB/s]#015Downloading:   6%|â         | 25.0M/438M [00:00<00:10, 40.3MB/s]#015Downloading:   7%|â         | 30.4M/438M [00:00<00:09, 43.6MB/s]#015Downloading:   8%|â         | 35.8M/438M [00:00<00:08, 46.3MB/s]#015Downloading:   9%|â         | 41.3M/438M [00:00<00:08, 48.6MB/s]#015Downloading:  11%|â         | 46.8M/438M [00:01<00:07, 50.3MB/s]#015Downloading:  12%|ââ        | 52.3M/438M [00:01<00:07, 51.6MB/s]#015Downloading:  13%|ââ        | 57.8M/438M [00:01<00:07, 52.7MB/s]#015Downloading:  14%|ââ        | 63.4M/438M [00:01<00:07, 53.4MB/s]#015Downloading:  16%|ââ        | 68.9M/438M [00:01<00:06, 54.0MB/s]#015Downloading:  17%|ââ        | 74.3M/438M [00:01<00:06, 54.1MB/s]#015Downloading:  18%|ââ        | 79.8M/438M [00:01<00:06, 53.9MB/s]#015Downloading:  19%|ââ        | 85.3M/438M [00:01<00:06, 54.3MB/s]#015Downloading:  21%|ââ        | 90.9M/438M [00:01<00:06, 54.7MB/s]#015Downloading:  22%|âââ       | 96.4M/438M [00:01<00:06, 55.1MB/s]#015Downloading:  23%|âââ       | 102M/438M [00:02<00:06, 55.2MB/s] #015Downloading:  25%|âââ       | 108M/438M [00:02<00:05, 55.4MB/s]#015Downloading:  26%|âââ       | 113M/438M [00:02<00:05, 55.6MB/s]#015Downloading:  27%|âââ       | 119M/438M [00:02<00:05, 55.8MB/s]#015Downloading:  28%|âââ       | 124M/438M [00:02<00:05, 55.9MB/s]#015Downloading:  30%|âââ       | 130M/438M [00:02<00:05, 55.9MB/s]#015Downloading:  31%|âââ       | 136M/438M [00:02<00:05, 55.6MB/s]#015Downloading:  32%|ââââ      | 141M/438M [00:02<00:05, 55.7MB/s]#015Downloading:  34%|ââââ      | 147M/438M [00:02<00:05, 55.7MB/s]#015Downloading:  35%|ââââ      | 152M/438M [00:02<00:05, 55.8MB/s]#015Downloading:  36%|ââââ      | 158M/438M [00:03<00:05, 55.9MB/s]#015Downloading:  37%|ââââ      | 164M/438M [00:03<00:04, 56.1MB/s]#015Downloading:  39%|ââââ      | 169M/438M [00:03<00:05, 53.3MB/s]#015Downloading:  40%|ââââ      | 175M/438M [00:03<00:04, 54.0MB/s]#015Downloading:  41%|ââââ      | 180M/438M [00:03<00:04, 54.5MB/s]#015Downloading:  42%|âââââ     | 186M/438M [00:03<00:04, 55.0MB/s]#015Downloading:  44%|âââââ     | 192M/438M [00:03<00:04, 54.7MB/s]#015Downloading:  45%|âââââ     | 197M/438M [00:03<00:04, 53.0MB/s]#015Downloading:  46%|âââââ     | 202M/438M [00:03<00:04, 53.4MB/s]#015Downloading:  48%|âââââ     | 208M/438M [00:03<00:04, 54.2MB/s]#015Downloading:  49%|âââââ     | 214M/438M [00:04<00:04, 54.6MB/s]#015Downloading:  50%|âââââ     | 219M/438M [00:04<00:03, 55.0MB/s]#015Downloading:  51%|ââââââ    | 225M/438M [00:04<00:03, 55.4MB/s]#015Downloading:  53%|ââââââ    | 230M/438M [00:04<00:03, 55.6MB/s]#015Downloading:  54%|ââââââ    | 236M/438M [00:04<00:03, 55.6MB/s]#015Downloading:  55%|ââââââ    | 242M/438M [00:04<00:03, 55.7MB/s]#015Downloading:  56%|ââââââ    | 247M/438M [00:04<00:03, 55.3MB/s]#015Downloading:  58%|ââââââ    | 253M/438M [00:04<00:03, 55.4MB/s]#015Downloading:  59%|ââââââ    | 258M/438M [00:04<00:03, 55.5MB/s]#015Downloading:  60%|ââââââ    | 264M/438M [00:04<00:03, 55.7MB/s]#015Downloading:  62%|âââââââ   | 270M/438M [00:05<00:03, 55.7MB/s]#015Downloading:  63%|âââââââ   | 275M/438M [00:05<00:02, 55.7MB/s]#015Downloading:  64%|âââââââ   | 281M/438M [00:05<00:02, 55.7MB/s]#015Downloading:  65%|âââââââ   | 286M/438M [00:05<00:02, 55.6MB/s]#015Downloading:  67%|âââââââ   | 292M/438M [00:05<00:02, 55.6MB/s]#015Downloading:  68%|âââââââ   | 297M/438M [00:05<00:02, 55.6MB/s]#015Downloading:  69%|âââââââ   | 303M/438M [00:05<00:02, 55.0MB/s]#015Downloading:  70%|âââââââ   | 308M/438M [00:05<00:02, 55.1MB/s]#015Downloading:  72%|ââââââââ  | 314M/438M [00:05<00:02, 55.2MB/s]#015Downloading:  73%|ââââââââ  | 320M/438M [00:05<00:02, 55.3MB/s]#015Downloading:  74%|ââââââââ  | 325M/438M [00:06<00:02, 55.4MB/s]#015Downloading:  76%|ââââââââ  | 331M/438M [00:06<00:01, 55.5MB/s]#015Downloading:  77%|ââââââââ  | 336M/438M [00:06<00:01, 55.6MB/s]#015Downloading:  78%|ââââââââ  | 342M/438M [00:06<00:01, 55.7MB/s]#015Downloading:  79%|ââââââââ  | 347M/438M [00:06<00:01, 51.6MB/s]#015Downloading:  81%|ââââââââ  | 353M/438M [00:06<00:01, 52.2MB/s]#015Downloading:  82%|âââââââââ | 358M/438M [00:06<00:01, 52.8MB/s]#015Downloading:  83%|âââââââââ | 364M/438M [00:06<00:01, 53.5MB/s]#015Downloading:  84%|âââââââââ | 369M/438M [00:06<00:01, 54.1MB/s]#015Downloading:  86%|âââââââââ | 375M/438M [00:06<00:01, 54.5MB/s]#015Downloading:  87%|âââââââââ | 380M/438M [00:07<00:01, 54.7MB/s]#015Downloading:  88%|âââââââââ | 386M/438M [00:07<00:00, 55.0MB/s]#015Downloading:  89%|âââââââââ | 392M/438M [00:07<00:00, 55.2MB/s]#015Downloading:  91%|âââââââââ | 397M/438M [00:07<00:00, 55.2MB/s]#015Downloading:  92%|ââââââââââ| 403M/438M [00:07<00:00, 55.4MB/s]#015Downloading:  93%|ââââââââââ| 408M/438M [00:07<00:00, 55.5MB/s]#015Downloading:  94%|ââââââââââ| 414M/438M [00:07<00:00, 55.1MB/s]#015Downloading:  96%|ââââââââââ| 419M/438M [00:07<00:00, 55.2MB/s]#015Downloading:  97%|ââââââââââ| 425M/438M [00:07<00:00, 55.3MB/s]#015Downloading:  98%|ââââââââââ| 430M/438M [00:07<00:00, 55.5MB/s]#015Downloading: 100%|ââââââââââ| 436M/438M [00:08<00:00, 55.5MB/s]#015Downloading: 100%|ââââââââââ| 438M/438M [00:08<00:00, 54.0MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1305] 2021-01-14 15:51:34,973 >> storing https://huggingface.co/csarron/bert-base-uncased-squad-v1/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/cc49866c357ded9e5e5047656847944e31b4fdbac69bd2ddd8567352acac8973.9113a3a907fc5caecafe526ef30b1b18dd4dcc741d60cb2080ae038c9b3b0cba\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1308] 2021-01-14 15:51:34,973 >> creating metadata file for /root/.cache/huggingface/transformers/cc49866c357ded9e5e5047656847944e31b4fdbac69bd2ddd8567352acac8973.9113a3a907fc5caecafe526ef30b1b18dd4dcc741d60cb2080ae038c9b3b0cba\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:34 - INFO - filelock -   Lock 140187688383208 released on /root/.cache/huggingface/transformers/cc49866c357ded9e5e5047656847944e31b4fdbac69bd2ddd8567352acac8973.9113a3a907fc5caecafe526ef30b1b18dd4dcc741d60cb2080ae038c9b3b0cba.lock\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1024] 2021-01-14 15:51:34,974 >> loading weights file https://huggingface.co/csarron/bert-base-uncased-squad-v1/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/cc49866c357ded9e5e5047656847944e31b4fdbac69bd2ddd8567352acac8973.9113a3a907fc5caecafe526ef30b1b18dd4dcc741d60cb2080ae038c9b3b0cba\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1140] 2021-01-14 15:51:40,493 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1149] 2021-01-14 15:51:40,493 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at csarron/bert-base-uncased-squad-v1.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:43 - WARNING - nn_pruning.examples.xp -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:43 - INFO - nn_pruning.examples.xp -   Training/evaluation parameters\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:43 - INFO - nn_pruning.examples.xp -     Model: ModelArguments(model_name_or_path='bert-base-uncased', config_name=None, tokenizer_name=None, cache_dir=None)\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:43 - INFO - nn_pruning.examples.xp -     Data: QADataTrainingArguments(dataset_name='squad', dataset_config_name=None, train_file=None, validation_file=None, overwrite_cache=0, dataset_cache_dir='dataset_cache', preprocessing_num_workers=None, max_seq_length=384, pad_to_max_length=True, doc_stride=128, version_2_with_negative=False, null_score_diff_threshold=0.0, n_best_size=20, max_answer_length=30)\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:43 - INFO - nn_pruning.examples.xp -     Training: XPTrainingArguments(output_dir='/opt/ml/model', overwrite_output_dir=1, do_train=1, do_eval=1, do_predict=False, model_parallel=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=0.1, max_steps=-1, warmup_steps=5400, logging_dir='/opt/ml/model', logging_first_step=False, logging_steps=100, save_steps=5000, save_total_limit=5, no_cuda=False, seed=17, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=250, dataloader_num_workers=0, past_index=-1, run_name='/opt/ml/model', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fp16_backend='auto', sharded_ddp=False, optimize_model_before_eval='disabled')\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:43 - INFO - nn_pruning.examples.xp -     Sparse: SparseTrainingArguments(mask_scores_learning_rate=0.01, dense_pruning_method='sigmoied_threshold:1d_alt', attention_pruning_method='sigmoied_threshold', ampere_pruning_method='disabled', attention_output_with_dense=0, bias_mask=True, mask_init='constant', mask_scale=0.0, dense_block_rows=1, dense_block_cols=1, attention_block_rows=1, attention_block_cols=1, initial_threshold=0, final_threshold=0.1, initial_warmup=1, final_warmup=10, initial_ampere_temperature=0.0, final_ampere_temperature=20.0, regularization='l1', regularization_final_lambda=10, attention_lambda=1.0, dense_lambda=1.0, distil_teacher_name_or_path='csarron/bert-base-uncased-squad-v1', distil_alpha_ce=0.1, distil_alpha_teacher=0.9, distil_temperature=2.0)\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/2.04k [00:00<?, ?B/s]#015Downloading: 5.24kB [00:00, 4.58MB/s]                   \u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/986 [00:00<?, ?B/s]#015Downloading: 2.19kB [00:00, 2.31MB/s]                 \u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/8.12M [00:00<?, ?B/s]#015Downloading:  57%|ââââââ    | 4.59M/8.12M [00:00<00:00, 45.9MB/s]#015Downloading: 11.5MB [00:00, 51.0MB/s]                            #015Downloading: 18.4MB [00:00, 55.4MB/s]#015Downloading: 25.4MB [00:00, 59.1MB/s]#015Downloading: 30.3MB [00:00, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.05M [00:00<?, ?B/s]#015Downloading: 4.85MB [00:00, 49.6MB/s]                   \u001b[0m\n",
      "\u001b[34m#0150 examples [00:00, ? examples/s]01/14/2021 15:51:46 - INFO - root -   generating examples from = /root/.cache/huggingface/datasets/downloads/b8bb19735e1bb591510a01cc032f4c9f969bc0eeb081ae1b328cd306f3b24008\u001b[0m\n",
      "\u001b[34m#0151 examples [00:00,  1.83 examples/s]#0152197 examples [00:00,  2.62 examples/s]#0154412 examples [00:00,  3.74 examples/s]#0156563 examples [00:00,  5.34 examples/s]#0158798 examples [00:00,  7.63 examples/s]#01510472 examples [00:01, 10.90 examples/s]#01512740 examples [00:01, 15.57 examples/s]#01515001 examples [00:01, 22.24 examples/s]#01517265 examples [00:01, 31.76 examples/s]#01519270 examples [00:01, 45.30 examples/s]#01521116 examples [00:01, 64.65 examples/s]#01523325 examples [00:01, 92.24 examples/s]#01525601 examples [00:01, 131.54 examples/s]#01527868 examples [00:02, 187.44 examples/s]#01530000 examples [00:02, 266.60 examples/s]#01532290 examples [00:02, 378.97 examples/s]#01534583 examples [00:02, 537.58 examples/s]#01536861 examples [00:02, 760.28 examples/s]#01539126 examples [00:02, 1070.71 examples/s]#01541337 examples [00:02, 1493.47 examples/s]#01543617 examples [00:02, 2075.26 examples/s]#01545819 examples [00:02, 2849.54 examples/s]#01548109 examples [00:02, 3864.63 examples/s]#01550320 examples [00:03, 5060.63 examples/s]#01552414 examples [00:03, 5952.37 examples/s]#01554696 examples [00:03, 7648.35 examples/s]#01556666 examples [00:03, 9367.42 examples/s]#01558934 examples [00:03, 11369.42 examples/s]#01560971 examples [00:03, 12799.93 examples/s]#01563249 examples [00:03, 14735.58 examples/s]#01565470 examples [00:03, 16389.52 examples/s]#01567717 examples [00:03, 17835.68 examples/s]#01570000 examples [00:04, 18279.35 examples/s]#01572284 examples [00:04, 19442.53 examples/s]#01574572 examples [00:04, 20358.88 examples/s]#01576861 examples [00:04, 21054.85 examples/s]#01579142 examples [00:04, 21551.32 examples/s]#01581380 examples [00:04, 20875.60 examples/s]#01583530 examples [00:04, 15928.18 examples/s]#01585725 examples [00:04, 17355.82 examples/s]#015                                           #015#0150 examples [00:00, ? examples/s]01/14/2021 15:51:51 - INFO - root -   generating examples from = /root/.cache/huggingface/datasets/downloads/9d5462987ef5f814fe15a369c1724f6ec39a2018b3b6271a9d7d2598686ca2ff\u001b[0m\n",
      "\u001b[34m#015976 examples [00:00, 9759.57 examples/s]#0152822 examples [00:00, 11366.17 examples/s]#0154586 examples [00:00, 12722.26 examples/s]#0156469 examples [00:00, 14092.13 examples/s]#0158327 examples [00:00, 15191.15 examples/s]#01510000 examples [00:00, 14869.65 examples/s]#015                                           #01501/14/2021 15:51:52 - INFO - filelock -   Lock 140187688427472 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170.lock\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1301] 2021-01-14 15:51:52,769 >> https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpt45cvtae\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]#015Downloading: 100%|ââââââââââ| 433/433 [00:00<00:00, 500kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1305] 2021-01-14 15:51:52,983 >> storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1308] 2021-01-14 15:51:52,983 >> creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:52 - INFO - filelock -   Lock 140187688427472 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170.lock\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:431] 2021-01-14 15:51:52,983 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:467] 2021-01-14 15:51:52,984 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:431] 2021-01-14 15:51:53,233 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:467] 2021-01-14 15:51:53,234 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\u001b[0m\n",
      "\u001b[34m2021-01-14 16:09:35,529 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:53 - INFO - filelock -   Lock 140187688710384 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1301] 2021-01-14 15:51:53,464 >> https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpcl29egrp\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading:  16%|ââ        | 36.9k/232k [00:00<00:00, 285kB/s]#015Downloading:  87%|âââââââââ | 201k/232k [00:00<00:00, 376kB/s] #015Downloading: 100%|ââââââââââ| 232k/232k [00:00<00:00, 869kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1305] 2021-01-14 15:51:53,950 >> storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1308] 2021-01-14 15:51:53,950 >> creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:53 - INFO - filelock -   Lock 140187688710384 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:54 - INFO - filelock -   Lock 140187688713352 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1301] 2021-01-14 15:51:54,169 >> https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpkvefxgwn\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading:   8%|â         | 36.9k/466k [00:00<00:01, 287kB/s]#015Downloading:  43%|âââââ     | 201k/466k [00:00<00:00, 378kB/s] #015Downloading: 100%|ââââââââââ| 466k/466k [00:00<00:00, 1.38MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1305] 2021-01-14 15:51:54,726 >> storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1308] 2021-01-14 15:51:54,726 >> creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\u001b[0m\n",
      "\u001b[34m01/14/2021 15:51:54 - INFO - filelock -   Lock 140187688713352 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2021-01-14 15:51:54,726 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2021-01-14 15:51:54,726 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/88 [00:00<?, ?ba/s]#015  1%|          | 1/88 [00:00<00:39,  2.20ba/s]#015  2%|â         | 2/88 [00:00<00:38,  2.21ba/s]#015  3%|â         | 3/88 [00:01<00:36,  2.33ba/s]#015  5%|â         | 4/88 [00:01<00:34,  2.46ba/s]#015  6%|â         | 5/88 [00:02<00:32,  2.53ba/s]#015  7%|â         | 6/88 [00:02<00:32,  2.49ba/s]#015  8%|â         | 7/88 [00:02<00:31,  2.55ba/s]#015  9%|â         | 8/88 [00:03<00:30,  2.65ba/s]#015 10%|â         | 9/88 [00:03<00:31,  2.49ba/s]#015 11%|ââ        | 10/88 [00:03<00:30,  2.60ba/s]#015 12%|ââ        | 11/88 [00:04<00:28,  2.68ba/s]#015 14%|ââ        | 12/88 [00:04<00:27,  2.73ba/s]#015 15%|ââ        | 13/88 [00:05<00:28,  2.61ba/s]#015 16%|ââ        | 14/88 [00:05<00:27,  2.69ba/s]#015 17%|ââ        | 15/88 [00:05<00:26,  2.74ba/s]#015 18%|ââ        | 16/88 [00:06<00:25,  2.83ba/s]#015 19%|ââ        | 17/88 [00:06<00:25,  2.74ba/s]#015 20%|ââ        | 18/88 [00:06<00:24,  2.83ba/s]#015 22%|âââ       | 19/88 [00:07<00:24,  2.84ba/s]#015 23%|âââ       | 20/88 [00:07<00:25,  2.70ba/s]#015 24%|âââ       | 21/88 [00:07<00:24,  2.74ba/s]#015 25%|âââ       | 22/88 [00:08<00:23,  2.81ba/s]#015 26%|âââ       | 23/88 [00:08<00:22,  2.85ba/s]#015 27%|âââ       | 24/88 [00:09<00:23,  2.67ba/s]#015 28%|âââ       | 25/88 [00:09<00:22,  2.75ba/s]#015 30%|âââ       | 26/88 [00:09<00:22,  2.79ba/s]#015 31%|âââ       | 27/88 [00:10<00:22,  2.68ba/s]#015 32%|ââââ      | 28/88 [00:10<00:23,  2.55ba/s]#015 33%|ââââ      | 29/88 [00:10<00:22,  2.57ba/s]#015 34%|ââââ      | 30/88 [00:11<00:22,  2.53ba/s]#015 35%|ââââ      | 31/88 [00:11<00:23,  2.41ba/s]#015 36%|ââââ      | 32/88 [00:12<00:23,  2.43ba/s]#015 38%|ââââ      | 33/88 [00:12<00:22,  2.49ba/s]#015 39%|ââââ      | 34/88 [00:12<00:21,  2.54ba/s]#015 40%|ââââ      | 35/88 [00:13<00:21,  2.44ba/s]#015 41%|ââââ      | 36/88 [00:13<00:21,  2.45ba/s]#015 42%|âââââ     | 37/88 [00:14<00:20,  2.48ba/s]#015 43%|âââââ     | 38/88 [00:14<00:19,  2.51ba/s]#015 44%|âââââ     | 39/88 [00:15<00:20,  2.42ba/s]#015 45%|âââââ     | 40/88 [00:15<00:19,  2.45ba/s]#015 47%|âââââ     | 41/88 [00:15<00:18,  2.50ba/s]#015 48%|âââââ     | 42/88 [00:16<00:19,  2.40ba/s]#015 49%|âââââ     | 43/88 [00:16<00:18,  2.48ba/s]#015 50%|âââââ     | 44/88 [00:16<00:17,  2.54ba/s]#015 51%|âââââ     | 45/88 [00:17<00:16,  2.56ba/s]#015 52%|ââââââ    | 46/88 [00:17<00:17,  2.44ba/s]#015 53%|ââââââ    | 47/88 [00:18<00:16,  2.44ba/s]#015 55%|ââââââ    | 48/88 [00:18<00:15,  2.52ba/s]#015 56%|ââââââ    | 49/88 [00:19<00:15,  2.54ba/s]#015 57%|ââââââ    | 50/88 [00:19<00:15,  2.45ba/s]#015 58%|ââââââ    | 51/88 [00:19<00:14,  2.51ba/s]#015 59%|ââââââ    | 52/88 [00:20<00:14,  2.52ba/s]#015 60%|ââââââ    | 53/88 [00:20<00:14,  2.41ba/s]#015 61%|âââââââ   | 54/88 [00:21<00:13,  2.47ba/s]#015 62%|âââââââ   | 55/88 [00:21<00:13,  2.48ba/s]#015 64%|âââââââ   | 56/88 [00:21<00:12,  2.52ba/s]#015 65%|âââââââ   | 57/88 [00:22<00:12,  2.43ba/s]#015 66%|âââââââ   | 58/88 [00:22<00:12,  2.48ba/s]#015 67%|âââââââ   | 59/88 [00:23<00:11,  2.51ba/s]#015 68%|âââââââ   | 60/88 [00:23<00:10,  2.56ba/s]#015 69%|âââââââ   | 61/88 [00:23<00:11,  2.44ba/s]#015 70%|âââââââ   | 62/88 [00:24<00:10,  2.48ba/s]#015 72%|ââââââââ  | 63/88 [00:24<00:09,  2.52ba/s]#015 73%|ââââââââ  | 64/88 [00:25<00:09,  2.41ba/s]#015 74%|ââââââââ  | 65/88 [00:25<00:09,  2.44ba/s]#015 75%|ââââââââ  | 66/88 [00:25<00:08,  2.45ba/s]#015 76%|ââââââââ  | 67/88 [00:26<00:08,  2.51ba/s]#015 77%|ââââââââ  | 68/88 [00:26<00:08,  2.43ba/s]#015 78%|ââââââââ  | 69/88 [00:27<00:07,  2.46ba/s]#015 80%|ââââââââ  | 70/88 [00:27<00:07,  2.50ba/s]#015 81%|ââââââââ  | 71/88 [00:27<00:06,  2.51ba/s]#015 82%|âââââââââ | 72/88 [00:28<00:06,  2.46ba/s]#015 83%|âââââââââ | 73/88 [00:28<00:05,  2.52ba/s]#015 84%|âââââââââ | 74/88 [00:29<00:05,  2.53ba/s]#015 85%|âââââââââ | 75/88 [00:29<00:05,  2.42ba/s]#015 86%|âââââââââ | 76/88 [00:29<00:04,  2.47ba/s]#015 88%|âââââââââ | 77/88 [00:30<00:04,  2.51ba/s]#015 89%|âââââââââ | 78/88 [00:30<00:03,  2.54ba/s]#015 90%|âââââââââ | 79/88 [00:31<00:03,  2.45ba/s]#015 91%|âââââââââ | 80/88 [00:31<00:03,  2.49ba/s]#015 92%|ââââââââââ| 81/88 [00:31<00:02,  2.56ba/s]#015 93%|ââââââââââ| 82/88 [00:32<00:02,  2.59ba/s]#015 94%|ââââââââââ| 83/88 [00:32<00:02,  2.42ba/s]#015 95%|ââââââââââ| 84/88 [00:33<00:01,  2.48ba/s]#015 97%|ââââââââââ| 85/88 [00:33<00:01,  2.54ba/s]#015 98%|ââââââââââ| 86/88 [00:33<00:00,  2.43ba/s]#015 99%|ââââââââââ| 87/88 [00:34<00:00,  2.44ba/s]#015100%|ââââââââââ| 88/88 [00:34<00:00,  2.79ba/s]#015100%|ââââââââââ| 88/88 [00:34<00:00,  2.54ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/11 [00:00<?, ?ba/s]#015  9%|â         | 1/11 [00:01<00:14,  1.43s/ba]#015 18%|ââ        | 2/11 [00:02<00:12,  1.40s/ba]#015 27%|âââ       | 3/11 [00:04<00:10,  1.35s/ba]#015 36%|ââââ      | 4/11 [00:05<00:09,  1.37s/ba]#015 45%|âââââ     | 5/11 [00:07<00:08,  1.46s/ba]#015 55%|ââââââ    | 6/11 [00:08<00:07,  1.47s/ba]#015 64%|âââââââ   | 7/11 [00:10<00:05,  1.46s/ba]#015 73%|ââââââââ  | 8/11 [00:11<00:04,  1.45s/ba]#015 82%|âââââââââ | 9/11 [00:12<00:02,  1.43s/ba]#015 91%|âââââââââ | 10/11 [00:14<00:01,  1.41s/ba]#015100%|ââââââââââ| 11/11 [00:14<00:00,  1.22s/ba]#015100%|ââââââââââ| 11/11 [00:14<00:00,  1.36s/ba]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.62k [00:00<?, ?B/s]#015Downloading: 4.02kB [00:00, 3.56MB/s]                   \u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]#015Downloading: 3.35kB [00:00, 3.29MB/s]                   \u001b[0m\n",
      "\u001b[34m01/14/2021 15:52:47 - INFO - filelock -   Lock 140187464314496 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1301] 2021-01-14 15:52:47,522 >> https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp72vhflll\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]#015Downloading:   1%|          | 3.09M/440M [00:00<00:14, 30.9MB/s]#015Downloading:   2%|â         | 8.30M/440M [00:00<00:12, 35.2MB/s]#015Downloading:   3%|â         | 13.6M/440M [00:00<00:10, 39.1MB/s]#015Downloading:   4%|â         | 19.0M/440M [00:00<00:09, 42.7MB/s]#015Downloading:   6%|â         | 24.5M/440M [00:00<00:09, 45.7MB/s]#015Downloading:   7%|â         | 30.0M/440M [00:00<00:08, 48.3MB/s]#015Downloading:   8%|â         | 35.6M/440M [00:00<00:08, 50.4MB/s]#015Downloading:   9%|â         | 41.3M/440M [00:00<00:07, 52.0MB/s]#015Downloading:  11%|â         | 46.8M/440M [00:00<00:07, 52.9MB/s]#015Downloading:  12%|ââ        | 52.4M/440M [00:01<00:07, 53.8MB/s]#015Downloading:  13%|ââ        | 58.1M/440M [00:01<00:06, 54.8MB/s]#015Downloading:  14%|ââ        | 63.8M/440M [00:01<00:06, 55.3MB/s]#015Downloading:  16%|ââ        | 69.5M/440M [00:01<00:06, 55.8MB/s]#015Downloading:  17%|ââ        | 75.2M/440M [00:01<00:06, 56.1MB/s]#015Downloading:  18%|ââ        | 80.9M/440M [00:01<00:06, 56.5MB/s]#015Downloading:  20%|ââ        | 86.6M/440M [00:01<00:06, 56.6MB/s]#015Downloading:  21%|ââ        | 92.3M/440M [00:01<00:06, 56.7MB/s]#015Downloading:  22%|âââ       | 98.0M/440M [00:01<00:06, 56.7MB/s]#015Downloading:  24%|âââ       | 104M/440M [00:01<00:05, 56.4MB/s] #015Downloading:  25%|âââ       | 109M/440M [00:02<00:05, 56.4MB/s]#015Downloading:  26%|âââ       | 115M/440M [00:02<00:05, 56.6MB/s]#015Downloading:  27%|âââ       | 121M/440M [00:02<00:05, 56.7MB/s]#015Downloading:  29%|âââ       | 126M/440M [00:02<00:05, 57.0MB/s]#015Downloading:  30%|âââ       | 132M/440M [00:02<00:05, 57.1MB/s]#015Downloading:  31%|ââââ      | 138M/440M [00:02<00:05, 56.9MB/s]#015Downloading:  33%|ââââ      | 144M/440M [00:02<00:05, 56.9MB/s]#015Downloading:  34%|ââââ      | 149M/440M [00:02<00:05, 57.1MB/s]#015Downloading:  35%|ââââ      | 155M/440M [00:02<00:05, 57.0MB/s]#015Downloading:  36%|ââââ      | 161M/440M [00:02<00:04, 56.9MB/s]#015Downloading:  38%|ââââ      | 166M/440M [00:03<00:04, 56.4MB/s]#015Downloading:  39%|ââââ      | 172M/440M [00:03<00:04, 56.2MB/s]#015Downloading:  40%|ââââ      | 178M/440M [00:03<00:04, 56.4MB/s]#015Downloading:  42%|âââââ     | 183M/440M [00:03<00:04, 56.7MB/s]#015Downloading:  43%|âââââ     | 189M/440M [00:03<00:04, 56.9MB/s]#015Downloading:  44%|âââââ     | 195M/440M [00:03<00:04, 55.9MB/s]#015Downloading:  46%|âââââ     | 201M/440M [00:03<00:04, 56.1MB/s]#015Downloading:  47%|âââââ     | 206M/440M [00:03<00:04, 56.1MB/s]#015Downloading:  48%|âââââ     | 212M/440M [00:03<00:04, 56.5MB/s]#015Downloading:  49%|âââââ     | 218M/440M [00:03<00:03, 56.5MB/s]#015Downloading:  51%|âââââ     | 223M/440M [00:04<00:03, 56.0MB/s]#015Downloading:  52%|ââââââ    | 229M/440M [00:04<00:03, 56.3MB/s]#015Downloading:  53%|ââââââ    | 235M/440M [00:04<00:03, 56.5MB/s]#015Downloading:  55%|ââââââ    | 240M/440M [00:04<00:03, 56.4MB/s]#015Downloading:  56%|ââââââ    | 246M/440M [00:04<00:03, 56.8MB/s]#015Downloading:  57%|ââââââ    | 252M/440M [00:04<00:03, 56.9MB/s]#015Downloading:  58%|ââââââ    | 258M/440M [00:04<00:03, 57.1MB/s]#015Downloading:  60%|ââââââ    | 263M/440M [00:04<00:03, 57.0MB/s]#015Downloading:  61%|ââââââ    | 269M/440M [00:04<00:03, 56.9MB/s]#015Downloading:  62%|âââââââ   | 275M/440M [00:04<00:02, 56.9MB/s]#015Downloading:  64%|âââââââ   | 280M/440M [00:05<00:02, 56.3MB/s]#015Downloading:  65%|âââââââ   | 286M/440M [00:05<00:02, 56.3MB/s]#015Downloading:  66%|âââââââ   | 292M/440M [00:05<00:02, 56.3MB/s]#015Downloading:  67%|âââââââ   | 297M/440M [00:05<00:02, 56.5MB/s]#015Downloading:  69%|âââââââ   | 303M/440M [00:05<00:02, 56.2MB/s]#015Downloading:  70%|âââââââ   | 309M/440M [00:05<00:02, 56.3MB/s]#015Downloading:  71%|ââââââââ  | 314M/440M [00:05<00:02, 56.6MB/s]#015Downloading:  73%|ââââââââ  | 320M/440M [00:05<00:02, 56.2MB/s]#015Downloading:  74%|ââââââââ  | 326M/440M [00:05<00:02, 56.4MB/s]#015Downloading:  75%|ââââââââ  | 331M/440M [00:05<00:01, 56.6MB/s]#015Downloading:  77%|ââââââââ  | 337M/440M [00:06<00:01, 56.0MB/s]#015Downloading:  78%|ââââââââ  | 343M/440M [00:06<00:01, 56.2MB/s]#015Downloading:  79%|ââââââââ  | 348M/440M [00:06<00:01, 56.4MB/s]#015Downloading:  80%|ââââââââ  | 354M/440M [00:06<00:01, 56.5MB/s]#015Downloading:  82%|âââââââââ | 360M/440M [00:06<00:01, 56.7MB/s]#015Downloading:  83%|âââââââââ | 365M/440M [00:06<00:01, 56.6MB/s]#015Downloading:  84%|âââââââââ | 371M/440M [00:06<00:01, 56.7MB/s]#015Downloading:  86%|âââââââââ | 377M/440M [00:06<00:01, 56.8MB/s]#015Downloading:  87%|âââââââââ | 383M/440M [00:06<00:01, 56.8MB/s]#015Downloading:  88%|âââââââââ | 388M/440M [00:06<00:00, 56.7MB/s]#015Downloading:  89%|âââââââââ | 394M/440M [00:07<00:00, 56.1MB/s]#015Downloading:  91%|âââââââââ | 400M/440M [00:07<00:00, 56.4MB/s]#015Downloading:  92%|ââââââââââ| 405M/440M [00:07<00:00, 56.6MB/s]#015Downloading:  93%|ââââââââââ| 411M/440M [00:07<00:00, 56.8MB/s]#015Downloading:  95%|ââââââââââ| 417M/440M [00:07<00:00, 56.9MB/s]#015Downloading:  96%|ââââââââââ| 423M/440M [00:07<00:00, 57.1MB/s]#015Downloading:  97%|ââââââââââ| 428M/440M [00:07<00:00, 57.3MB/s]#015Downloading:  99%|ââââââââââ| 434M/440M [00:07<00:00, 57.6MB/s]#015Downloading: 100%|ââââââââââ| 440M/440M [00:07<00:00, 57.8MB/s]#015Downloading: 100%|ââââââââââ| 440M/440M [00:07<00:00, 56.1MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1305] 2021-01-14 15:52:55,445 >> storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1308] 2021-01-14 15:52:55,445 >> creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\u001b[0m\n",
      "\u001b[34m01/14/2021 15:52:55 - INFO - filelock -   Lock 140187464314496 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1024] 2021-01-14 15:52:55,445 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1132] 2021-01-14 15:52:59,776 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1143] 2021-01-14 15:52:59,777 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:388] 2021-01-14 15:52:59,920 >> The following columns in the training set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: .\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:388] 2021-01-14 15:52:59,921 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1024] 2021-01-14 15:53:00,138 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1132] 2021-01-14 15:53:04,446 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1143] 2021-01-14 15:53:04,446 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:703] 2021-01-14 15:53:04,555 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:704] 2021-01-14 15:53:04,555 >>   Num examples = 88524\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:705] 2021-01-14 15:53:04,555 >>   Num Epochs = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:706] 2021-01-14 15:53:04,555 >>   Instantaneous batch size per device = 16\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:707] 2021-01-14 15:53:04,555 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:708] 2021-01-14 15:53:04,555 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:709] 2021-01-14 15:53:04,556 >>   Total optimization steps = 554\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/554 [00:00<?, ?it/s]#015  0%|          | 1/554 [00:02<20:11,  2.19s/it]#015  0%|          | 2/554 [00:02<15:46,  1.71s/it]#015  1%|          | 3/554 [00:03<12:39,  1.38s/it]#015  1%|          | 4/554 [00:03<10:29,  1.14s/it]#015  1%|          | 5/554 [00:04<08:57,  1.02it/s]#015  1%|          | 6/554 [00:05<07:53,  1.16it/s]#015  1%|â         | 7/554 [00:05<07:08,  1.28it/s]#015  1%|â         | 8/554 [00:06<06:36,  1.38it/s]#015  2%|â         | 9/554 [00:06<06:14,  1.45it/s]#015  2%|â         | 10/554 [00:07<05:59,  1.51it/s]#015  2%|â         | 11/554 [00:08<05:48,  1.56it/s]#015  2%|â         | 12/554 [00:08<05:40,  1.59it/s]#015  2%|â         | 13/554 [00:09<05:34,  1.62it/s]#015  3%|â         | 14/554 [00:09<05:29,  1.64it/s]#015  3%|â         | 15/554 [00:10<05:26,  1.65it/s]#015  3%|â         | 16/554 [00:11<05:24,  1.66it/s]#015  3%|â         | 17/554 [00:11<05:22,  1.66it/s]#015  3%|â         | 18/554 [00:12<05:22,  1.66it/s]#015  3%|â         | 19/554 [00:12<05:20,  1.67it/s]#015  4%|â         | 20/554 [00:13<05:19,  1.67it/s]#015  4%|â         | 21/554 [00:14<05:18,  1.67it/s]#015  4%|â         | 22/554 [00:14<05:17,  1.68it/s]#015  4%|â         | 23/554 [00:15<05:16,  1.68it/s]#015  4%|â         | 24/554 [00:15<05:15,  1.68it/s]#015  5%|â         | 25/554 [00:16<05:17,  1.67it/s]#015  5%|â         | 26/554 [00:17<05:19,  1.65it/s]#015  5%|â         | 27/554 [00:17<05:19,  1.65it/s]#015  5%|â         | 28/554 [00:18<05:18,  1.65it/s]#015  5%|â         | 29/554 [00:18<05:17,  1.66it/s]#015  5%|â         | 30/554 [00:19<05:14,  1.66it/s]#015  6%|â         | 31/554 [00:20<05:13,  1.67it/s]#015  6%|â         | 32/554 [00:20<05:11,  1.67it/s]#015  6%|â         | 33/554 [00:21<05:10,  1.68it/s]#015  6%|â         | 34/554 [00:21<05:11,  1.67it/s]#015  6%|â         | 35/554 [00:22<05:10,  1.67it/s]#015  6%|â         | 36/554 [00:23<05:09,  1.68it/s]#015  7%|â         | 37/554 [00:23<05:08,  1.68it/s]#015  7%|â         | 38/554 [00:24<05:07,  1.68it/s]#015  7%|â         | 39/554 [00:24<05:06,  1.68it/s]#015  7%|â         | 40/554 [00:25<05:06,  1.68it/s]#015  7%|â         | 41/554 [00:26<05:05,  1.68it/s]#015  8%|â         | 42/554 [00:26<05:05,  1.68it/s]#015  8%|â         | 43/554 [00:27<05:05,  1.67it/s]#015  8%|â         | 44/554 [00:27<05:04,  1.68it/s]#015  8%|â         | 45/554 [00:28<05:03,  1.68it/s]#015  8%|â         | 46/554 [00:29<05:03,  1.68it/s]#015  8%|â         | 47/554 [00:29<05:01,  1.68it/s]#015  9%|â         | 48/554 [00:30<05:01,  1.68it/s]#015  9%|â         | 49/554 [00:30<05:00,  1.68it/s]#015  9%|â         | 50/554 [00:31<05:00,  1.68it/s]#015  9%|â         | 51/554 [00:32<04:59,  1.68it/s]#015  9%|â         | 52/554 [00:32<04:59,  1.68it/s]#015 10%|â         | 53/554 [00:33<04:58,  1.68it/s]#015 10%|â         | 54/554 [00:33<04:58,  1.68it/s]#015 10%|â         | 55/554 [00:34<04:57,  1.68it/s]#015 10%|â         | 56/554 [00:35<04:57,  1.68it/s]#015 10%|â         | 57/554 [00:35<04:56,  1.68it/s]#015 10%|â         | 58/554 [00:36<04:56,  1.67it/s]#015 11%|â         | 59/554 [00:36<04:55,  1.68it/s]#015 11%|â         | 60/554 [00:37<04:55,  1.67it/s]#015 11%|â         | 61/554 [00:38<04:54,  1.67it/s]#015 11%|â         | 62/554 [00:38<04:53,  1.67it/s]#015 11%|ââ        | 63/554 [00:39<04:53,  1.67it/s]#015 12%|ââ        | 64/554 [00:39<04:52,  1.68it/s]#015 12%|ââ        | 65/554 [00:40<04:51,  1.68it/s]#015 12%|ââ        | 66/554 [00:40<04:50,  1.68it/s]#015 12%|ââ        | 67/554 [00:41<04:50,  1.68it/s]#015 12%|ââ        | 68/554 [00:42<04:49,  1.68it/s]#015 12%|ââ        | 69/554 [00:42<04:49,  1.68it/s]#015 13%|ââ        | 70/554 [00:43<04:48,  1.68it/s]#015 13%|ââ        | 71/554 [00:43<04:48,  1.68it/s]#015 13%|ââ        | 72/554 [00:44<04:47,  1.68it/s]#015 13%|ââ        | 73/554 [00:45<04:46,  1.68it/s]#015 13%|ââ        | 74/554 [00:45<04:46,  1.68it/s]#015 14%|ââ        | 75/554 [00:46<04:45,  1.68it/s]#015 14%|ââ        | 76/554 [00:46<04:45,  1.68it/s]#015 14%|ââ        | 77/554 [00:47<04:45,  1.67it/s]#015 14%|ââ        | 78/554 [00:48<04:44,  1.67it/s]#015 14%|ââ        | 79/554 [00:48<04:44,  1.67it/s]#015 14%|ââ        | 80/554 [00:49<04:43,  1.67it/s]#015 15%|ââ        | 81/554 [00:49<04:42,  1.67it/s]#015 15%|ââ        | 82/554 [00:50<04:41,  1.68it/s]#015 15%|ââ        | 83/554 [00:51<04:40,  1.68it/s]#015 15%|ââ        | 84/554 [00:51<04:40,  1.68it/s]#015 15%|ââ        | 85/554 [00:52<04:39,  1.68it/s]#015 16%|ââ        | 86/554 [00:52<04:39,  1.67it/s]#015 16%|ââ        | 87/554 [00:53<04:38,  1.68it/s]#015 16%|ââ        | 88/554 [00:54<04:38,  1.68it/s]#015 16%|ââ        | 89/554 [00:54<04:37,  1.68it/s]#015 16%|ââ        | 90/554 [00:55<04:37,  1.67it/s]#015 16%|ââ        | 91/554 [00:55<04:36,  1.67it/s]#015 17%|ââ        | 92/554 [00:56<04:35,  1.67it/s]#015 17%|ââ        | 93/554 [00:57<04:35,  1.67it/s]#015 17%|ââ        | 94/554 [00:57<04:35,  1.67it/s]#015 17%|ââ        | 95/554 [00:58<04:35,  1.67it/s]#015 17%|ââ        | 96/554 [00:58<04:34,  1.67it/s]#015 18%|ââ        | 97/554 [00:59<04:33,  1.67it/s]#015 18%|ââ        | 98/554 [01:00<04:33,  1.67it/s]#015 18%|ââ        | 99/554 [01:00<04:32,  1.67it/s]#015 18%|ââ        | 100/554 [01:01<04:31,  1.67it/s]#015                                                 #015#015 18%|ââ        | 100/554 [01:01<04:31,  1.67it/s]#015 18%|ââ        | 101/554 [01:01<04:31,  1.67it/s]#015 18%|ââ        | 102/554 [01:02<04:31,  1.66it/s]#015 19%|ââ        | 103/554 [01:03<04:31,  1.66it/s]#015 19%|ââ        | 104/554 [01:03<04:30,  1.66it/s]#015 19%|ââ        | 105/554 [01:04<04:30,  1.66it/s]#015 19%|ââ        | 106/554 [01:04<04:29,  1.66it/s]#015 19%|ââ        | 107/554 [01:05<04:28,  1.66it/s]#015 19%|ââ        | 108/554 [01:06<04:28,  1.66it/s]#015 20%|ââ        | 109/554 [01:06<04:27,  1.67it/s]#015 20%|ââ        | 110/554 [01:07<04:26,  1.67it/s]#015 20%|ââ        | 111/554 [01:07<04:25,  1.67it/s]#015 20%|ââ        | 112/554 [01:08<04:24,  1.67it/s]#015 20%|ââ        | 113/554 [01:09<04:23,  1.67it/s]#015 21%|ââ        | 114/554 [01:09<04:22,  1.68it/s]#015 21%|ââ        | 115/554 [01:10<04:23,  1.67it/s]#015 21%|ââ        | 116/554 [01:10<04:22,  1.67it/s]#015 21%|ââ        | 117/554 [01:11<04:22,  1.67it/s]#015 21%|âââ       | 118/554 [01:12<04:21,  1.67it/s]#015 21%|âââ       | 119/554 [01:12<04:20,  1.67it/s]#015 22%|âââ       | 120/554 [01:13<04:19,  1.67it/s]#015 22%|âââ       | 121/554 [01:13<04:18,  1.67it/s]#015 22%|âââ       | 122/554 [01:14<04:17,  1.67it/s]#015 22%|âââ       | 123/554 [01:15<04:17,  1.68it/s]#015 22%|âââ       | 124/554 [01:15<04:16,  1.68it/s]#015 23%|âââ       | 125/554 [01:16<04:15,  1.68it/s]#015 23%|âââ       | 126/554 [01:16<04:14,  1.68it/s]#015 23%|âââ       | 127/554 [01:17<04:15,  1.67it/s]#015 23%|âââ       | 128/554 [01:18<04:14,  1.67it/s]#015 23%|âââ       | 129/554 [01:18<04:13,  1.68it/s]#015 23%|âââ       | 130/554 [01:19<04:12,  1.68it/s]#015 24%|âââ       | 131/554 [01:19<04:11,  1.68it/s]#015 24%|âââ       | 132/554 [01:20<04:11,  1.68it/s]#015 24%|âââ       | 133/554 [01:21<04:11,  1.68it/s]#015 24%|âââ       | 134/554 [01:21<04:10,  1.67it/s]#015 24%|âââ       | 135/554 [01:22<04:10,  1.67it/s]#015 25%|âââ       | 136/554 [01:22<04:10,  1.67it/s]#015 25%|âââ       | 137/554 [01:23<04:09,  1.67it/s]#015 25%|âââ       | 138/554 [01:24<04:09,  1.67it/s]#015 25%|âââ       | 139/554 [01:24<04:08,  1.67it/s]#015 25%|âââ       | 140/554 [01:25<04:08,  1.67it/s]#015 25%|âââ       | 141/554 [01:25<04:07,  1.67it/s]#015 26%|âââ       | 142/554 [01:26<04:07,  1.67it/s]#015 26%|âââ       | 143/554 [01:27<04:07,  1.66it/s]#015 26%|âââ       | 144/554 [01:27<04:07,  1.66it/s]#015 26%|âââ       | 145/554 [01:28<04:07,  1.65it/s]#015 26%|âââ       | 146/554 [01:28<04:06,  1.66it/s]#015 27%|âââ       | 147/554 [01:29<04:05,  1.66it/s]#015 27%|âââ       | 148/554 [01:30<04:03,  1.66it/s]#015 27%|âââ       | 149/554 [01:30<04:03,  1.67it/s]#015 27%|âââ       | 150/554 [01:31<04:02,  1.67it/s]#015 27%|âââ       | 151/554 [01:31<04:01,  1.67it/s]#015 27%|âââ       | 152/554 [01:32<04:00,  1.67it/s]#015 28%|âââ       | 153/554 [01:33<04:00,  1.67it/s]#015 28%|âââ       | 154/554 [01:33<03:59,  1.67it/s]#015 28%|âââ       | 155/554 [01:34<03:58,  1.67it/s]#015 28%|âââ       | 156/554 [01:34<03:58,  1.67it/s]#015 28%|âââ       | 157/554 [01:35<03:57,  1.67it/s]#015 29%|âââ       | 158/554 [01:36<03:57,  1.67it/s]#015 29%|âââ       | 159/554 [01:36<03:56,  1.67it/s]#015 29%|âââ       | 160/554 [01:37<03:55,  1.67it/s]#015 29%|âââ       | 161/554 [01:37<03:55,  1.67it/s]#015 29%|âââ       | 162/554 [01:38<03:54,  1.67it/s]#015 29%|âââ       | 163/554 [01:39<03:53,  1.67it/s]#015 30%|âââ       | 164/554 [01:39<03:53,  1.67it/s]#015 30%|âââ       | 165/554 [01:40<03:52,  1.67it/s]#015 30%|âââ       | 166/554 [01:40<03:51,  1.67it/s]#015 30%|âââ       | 167/554 [01:41<03:51,  1.67it/s]#015 30%|âââ       | 168/554 [01:42<03:50,  1.67it/s]#015 31%|âââ       | 169/554 [01:42<03:49,  1.67it/s]#015 31%|âââ       | 170/554 [01:43<03:49,  1.67it/s]#015 31%|âââ       | 171/554 [01:43<03:48,  1.67it/s]#015 31%|âââ       | 172/554 [01:44<03:48,  1.67it/s]#015 31%|âââ       | 173/554 [01:45<03:47,  1.67it/s]#015 31%|ââââ      | 174/554 [01:45<03:46,  1.67it/s]#015 32%|ââââ      | 175/554 [01:46<03:46,  1.67it/s]#015 32%|ââââ      | 176/554 [01:46<03:46,  1.67it/s]#015 32%|ââââ      | 177/554 [01:47<03:45,  1.67it/s]#015 32%|ââââ      | 178/554 [01:48<03:44,  1.67it/s]#015 32%|ââââ      | 179/554 [01:48<03:44,  1.67it/s]#015 32%|ââââ      | 180/554 [01:49<03:43,  1.67it/s]#015 33%|ââââ      | 181/554 [01:49<03:43,  1.67it/s]#015 33%|ââââ      | 182/554 [01:50<03:42,  1.67it/s]#015 33%|ââââ      | 183/554 [01:51<03:41,  1.67it/s]#015 33%|ââââ      | 184/554 [01:51<03:41,  1.67it/s]#015 33%|ââââ      | 185/554 [01:52<03:40,  1.67it/s]#015 34%|ââââ      | 186/554 [01:52<03:40,  1.67it/s]#015 34%|ââââ      | 187/554 [01:53<03:39,  1.67it/s]#015 34%|ââââ      | 188/554 [01:54<03:39,  1.67it/s]#015 34%|ââââ      | 189/554 [01:54<03:38,  1.67it/s]#015 34%|ââââ      | 190/554 [01:55<03:37,  1.67it/s]#015 34%|ââââ      | 191/554 [01:55<03:37,  1.67it/s]#015 35%|ââââ      | 192/554 [01:56<03:36,  1.67it/s]#015 35%|ââââ      | 193/554 [01:57<03:35,  1.67it/s]#015 35%|ââââ      | 194/554 [01:57<03:36,  1.66it/s]#015 35%|ââââ      | 195/554 [01:58<03:36,  1.66it/s]#015 35%|ââââ      | 196/554 [01:58<03:35,  1.66it/s]#015 36%|ââââ      | 197/554 [01:59<03:34,  1.66it/s]#015 36%|ââââ      | 198/554 [02:00<03:33,  1.67it/s]#015 36%|ââââ      | 199/554 [02:00<03:32,  1.67it/s]#015 36%|ââââ      | 200/554 [02:01<03:32,  1.67it/s]#015                                                 #015#015 36%|ââââ      | 200/554 [02:01<03:32,  1.67it/s]#015 36%|ââââ      | 201/554 [02:01<03:31,  1.67it/s]#015 36%|ââââ      | 202/554 [02:02<03:30,  1.67it/s]#015 37%|ââââ      | 203/554 [02:03<03:30,  1.67it/s]#015 37%|ââââ      | 204/554 [02:03<03:29,  1.67it/s]#015 37%|ââââ      | 205/554 [02:04<03:29,  1.67it/s]#015 37%|ââââ      | 206/554 [02:04<03:28,  1.67it/s]#015 37%|ââââ      | 207/554 [02:05<03:27,  1.67it/s]#015 38%|ââââ      | 208/554 [02:06<03:27,  1.67it/s]#015 38%|ââââ      | 209/554 [02:06<03:27,  1.67it/s]#015 38%|ââââ      | 210/554 [02:07<03:26,  1.66it/s]#015 38%|ââââ      | 211/554 [02:07<03:26,  1.66it/s]#015 38%|ââââ      | 212/554 [02:08<03:26,  1.66it/s]#015 38%|ââââ      | 213/554 [02:09<03:25,  1.66it/s]#015 39%|ââââ      | 214/554 [02:09<03:24,  1.66it/s]#015 39%|ââââ      | 215/554 [02:10<03:23,  1.66it/s]#015 39%|ââââ      | 216/554 [02:10<03:23,  1.66it/s]#015 39%|ââââ      | 217/554 [02:11<03:22,  1.66it/s]#015 39%|ââââ      | 218/554 [02:12<03:22,  1.66it/s]#015 40%|ââââ      | 219/554 [02:12<03:21,  1.66it/s]#015 40%|ââââ      | 220/554 [02:13<03:20,  1.66it/s]#015 40%|ââââ      | 221/554 [02:13<03:19,  1.67it/s]#015 40%|ââââ      | 222/554 [02:14<03:19,  1.67it/s]#015 40%|ââââ      | 223/554 [02:15<03:18,  1.67it/s]#015 40%|ââââ      | 224/554 [02:15<03:17,  1.67it/s]#015 41%|ââââ      | 225/554 [02:16<03:17,  1.67it/s]#015 41%|ââââ      | 226/554 [02:16<03:16,  1.67it/s]#015 41%|ââââ      | 227/554 [02:17<03:16,  1.67it/s]#015 41%|ââââ      | 228/554 [02:18<03:15,  1.67it/s]#015 41%|âââââ     | 229/554 [02:18<03:14,  1.67it/s]#015 42%|âââââ     | 230/554 [02:19<03:13,  1.67it/s]#015 42%|âââââ     | 231/554 [02:19<03:13,  1.67it/s]#015 42%|âââââ     | 232/554 [02:20<03:12,  1.67it/s]#015 42%|âââââ     | 233/554 [02:21<03:12,  1.67it/s]#015 42%|âââââ     | 234/554 [02:21<03:11,  1.67it/s]#015 42%|âââââ     | 235/554 [02:22<03:10,  1.67it/s]#015 43%|âââââ     | 236/554 [02:22<03:10,  1.67it/s]#015 43%|âââââ     | 237/554 [02:23<03:09,  1.67it/s]#015 43%|âââââ     | 238/554 [02:24<03:09,  1.67it/s]#015 43%|âââââ     | 239/554 [02:24<03:08,  1.67it/s]#015 43%|âââââ     | 240/554 [02:25<03:08,  1.67it/s]#015 44%|âââââ     | 241/554 [02:25<03:08,  1.66it/s]#015 44%|âââââ     | 242/554 [02:26<03:07,  1.66it/s]#015 44%|âââââ     | 243/554 [02:27<03:07,  1.66it/s]#015 44%|âââââ     | 244/554 [02:27<03:06,  1.66it/s]#015 44%|âââââ     | 245/554 [02:28<03:05,  1.66it/s]#015 44%|âââââ     | 246/554 [02:28<03:04,  1.67it/s]#015 45%|âââââ     | 247/554 [02:29<03:03,  1.67it/s]#015 45%|âââââ     | 248/554 [02:30<03:03,  1.67it/s]#015 45%|âââââ     | 249/554 [02:30<03:02,  1.67it/s]#015 45%|âââââ     | 250/554 [02:31<03:02,  1.67it/s][INFO|trainer.py:388] 2021-01-14 15:55:35,778 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1412] 2021-01-14 15:55:35,779 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1413] 2021-01-14 15:55:35,780 >>   Num examples = 10784\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1414] 2021-01-14 15:55:35,780 >>   Batch size = 8\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1348 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 2/1348 [00:00<01:24, 15.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 3/1348 [00:00<01:49, 12.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 4/1348 [00:00<02:07, 10.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 5/1348 [00:00<02:18,  9.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 6/1348 [00:00<02:27,  9.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 7/1348 [00:00<02:33,  8.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 8/1348 [00:00<02:36,  8.54it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 9/1348 [00:00<02:39,  8.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 10/1348 [00:01<02:41,  8.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 11/1348 [00:01<02:42,  8.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 12/1348 [00:01<02:43,  8.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 13/1348 [00:01<02:43,  8.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 14/1348 [00:01<02:43,  8.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 15/1348 [00:01<02:43,  8.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 16/1348 [00:01<02:44,  8.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 17/1348 [00:01<02:44,  8.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 18/1348 [00:02<02:44,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 19/1348 [00:02<02:44,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 20/1348 [00:02<02:44,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 21/1348 [00:02<02:44,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 22/1348 [00:02<02:44,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 23/1348 [00:02<02:44,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 24/1348 [00:02<02:45,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 25/1348 [00:02<02:45,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 26/1348 [00:03<02:45,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 27/1348 [00:03<02:45,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 28/1348 [00:03<02:46,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 29/1348 [00:03<02:46,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 30/1348 [00:03<02:46,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 31/1348 [00:03<02:46,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 32/1348 [00:03<02:47,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 33/1348 [00:03<02:47,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 34/1348 [00:04<02:47,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 35/1348 [00:04<02:47,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 36/1348 [00:04<02:46,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 37/1348 [00:04<02:46,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 38/1348 [00:04<02:45,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 39/1348 [00:04<02:45,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 40/1348 [00:04<02:45,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 41/1348 [00:05<02:44,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 42/1348 [00:05<02:43,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 43/1348 [00:05<02:42,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 44/1348 [00:05<02:42,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 45/1348 [00:05<02:41,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 46/1348 [00:05<02:41,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 47/1348 [00:05<02:40,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 48/1348 [00:05<02:41,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 49/1348 [00:05<02:41,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 50/1348 [00:06<02:41,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 51/1348 [00:06<02:40,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 52/1348 [00:06<02:41,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 53/1348 [00:06<02:42,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 54/1348 [00:06<02:42,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 55/1348 [00:06<02:41,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 56/1348 [00:06<02:41,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 57/1348 [00:06<02:40,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 58/1348 [00:07<02:41,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 59/1348 [00:07<02:40,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 60/1348 [00:07<02:40,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 61/1348 [00:07<02:40,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 62/1348 [00:07<02:40,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 63/1348 [00:07<02:39,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 64/1348 [00:07<02:39,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 65/1348 [00:07<02:39,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 66/1348 [00:08<02:38,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 67/1348 [00:08<02:38,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 68/1348 [00:08<02:38,  8.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 69/1348 [00:08<02:38,  8.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 70/1348 [00:08<02:38,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 71/1348 [00:08<02:38,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 72/1348 [00:08<02:39,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 73/1348 [00:08<02:39,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 74/1348 [00:09<02:38,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 75/1348 [00:09<02:38,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 76/1348 [00:09<02:38,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 77/1348 [00:09<02:38,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 78/1348 [00:09<02:38,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 79/1348 [00:09<02:37,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 80/1348 [00:09<02:37,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 81/1348 [00:09<02:37,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 82/1348 [00:10<02:37,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 83/1348 [00:10<02:37,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 84/1348 [00:10<02:37,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 85/1348 [00:10<02:37,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 86/1348 [00:10<02:36,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 87/1348 [00:10<02:36,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 88/1348 [00:10<02:36,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 89/1348 [00:10<02:36,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 90/1348 [00:11<02:37,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 91/1348 [00:11<02:36,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 92/1348 [00:11<02:36,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 93/1348 [00:11<02:37,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 94/1348 [00:11<02:36,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 95/1348 [00:11<02:36,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 96/1348 [00:11<02:36,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 97/1348 [00:11<02:37,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 98/1348 [00:12<02:36,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 99/1348 [00:12<02:37,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 100/1348 [00:12<02:36,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 101/1348 [00:12<02:37,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 102/1348 [00:12<02:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 103/1348 [00:12<02:37,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 104/1348 [00:12<02:37,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 105/1348 [00:12<02:38,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 106/1348 [00:13<02:37,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 107/1348 [00:13<02:36,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 108/1348 [00:13<02:35,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 109/1348 [00:13<02:35,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 110/1348 [00:13<02:34,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 111/1348 [00:13<02:34,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 112/1348 [00:13<02:33,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 113/1348 [00:13<02:34,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 114/1348 [00:14<02:34,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 115/1348 [00:14<02:34,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 116/1348 [00:14<02:34,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 117/1348 [00:14<02:34,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 118/1348 [00:14<02:34,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 119/1348 [00:14<02:34,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 120/1348 [00:14<02:33,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 121/1348 [00:14<02:34,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 122/1348 [00:15<02:33,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 123/1348 [00:15<02:33,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 124/1348 [00:15<02:33,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 125/1348 [00:15<02:33,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 126/1348 [00:15<02:33,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 127/1348 [00:15<02:33,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 128/1348 [00:15<02:33,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 129/1348 [00:16<02:33,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 130/1348 [00:16<02:33,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 131/1348 [00:16<02:32,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 132/1348 [00:16<02:33,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 133/1348 [00:16<02:32,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 134/1348 [00:16<02:32,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 135/1348 [00:16<02:32,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 136/1348 [00:16<02:32,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 137/1348 [00:17<02:32,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 138/1348 [00:17<02:32,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 139/1348 [00:17<02:31,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 140/1348 [00:17<02:32,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 141/1348 [00:17<02:31,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 142/1348 [00:17<02:31,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 143/1348 [00:17<02:31,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 144/1348 [00:17<02:30,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 145/1348 [00:18<02:30,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 146/1348 [00:18<02:30,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 147/1348 [00:18<02:29,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 148/1348 [00:18<02:29,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 149/1348 [00:18<02:29,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 150/1348 [00:18<02:28,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 151/1348 [00:18<02:28,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 152/1348 [00:18<02:28,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 153/1348 [00:19<02:29,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 154/1348 [00:19<02:28,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 155/1348 [00:19<02:28,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 156/1348 [00:19<02:28,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 157/1348 [00:19<02:27,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 158/1348 [00:19<02:27,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 159/1348 [00:19<02:27,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 160/1348 [00:19<02:28,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 161/1348 [00:20<02:28,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 162/1348 [00:20<02:28,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 163/1348 [00:20<02:27,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 164/1348 [00:20<02:27,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 165/1348 [00:20<02:26,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 166/1348 [00:20<02:26,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 167/1348 [00:20<02:26,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 168/1348 [00:20<02:26,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 169/1348 [00:20<02:26,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 170/1348 [00:21<02:27,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 171/1348 [00:21<02:26,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 172/1348 [00:21<02:26,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 173/1348 [00:21<02:26,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 174/1348 [00:21<02:25,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 175/1348 [00:21<02:26,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 176/1348 [00:21<02:26,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 177/1348 [00:21<02:26,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 178/1348 [00:22<02:27,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 179/1348 [00:22<02:26,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 180/1348 [00:22<02:25,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 181/1348 [00:22<02:26,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 182/1348 [00:22<02:25,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 183/1348 [00:22<02:25,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 184/1348 [00:22<02:24,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 185/1348 [00:22<02:24,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 186/1348 [00:23<02:25,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 187/1348 [00:23<02:24,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 188/1348 [00:23<02:24,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 189/1348 [00:23<02:24,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 190/1348 [00:23<02:23,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 191/1348 [00:23<02:23,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 192/1348 [00:23<02:23,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 193/1348 [00:23<02:23,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 194/1348 [00:24<02:24,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 195/1348 [00:24<02:24,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 196/1348 [00:24<02:23,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 197/1348 [00:24<02:23,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 198/1348 [00:24<02:22,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 199/1348 [00:24<02:22,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 200/1348 [00:24<02:22,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 201/1348 [00:24<02:22,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 202/1348 [00:25<02:23,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 203/1348 [00:25<02:22,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 204/1348 [00:25<02:22,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 205/1348 [00:25<02:22,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 206/1348 [00:25<02:22,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 207/1348 [00:25<02:22,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 208/1348 [00:25<02:21,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 209/1348 [00:25<02:24,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 210/1348 [00:26<02:23,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 211/1348 [00:26<02:24,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 212/1348 [00:26<02:23,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 213/1348 [00:26<02:22,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 214/1348 [00:26<02:22,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 215/1348 [00:26<02:21,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 216/1348 [00:26<02:21,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 217/1348 [00:26<02:21,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 218/1348 [00:27<02:21,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 219/1348 [00:27<02:21,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 220/1348 [00:27<02:21,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 221/1348 [00:27<02:20,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 222/1348 [00:27<02:20,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 223/1348 [00:27<02:19,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 224/1348 [00:27<02:19,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 225/1348 [00:27<02:19,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 226/1348 [00:28<02:19,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 227/1348 [00:28<02:19,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 228/1348 [00:28<02:19,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 229/1348 [00:28<02:19,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 230/1348 [00:28<02:19,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 231/1348 [00:28<02:19,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 232/1348 [00:28<02:18,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 233/1348 [00:28<02:19,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 234/1348 [00:29<02:19,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 235/1348 [00:29<02:19,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 236/1348 [00:29<02:18,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 237/1348 [00:29<02:18,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 238/1348 [00:29<02:18,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 239/1348 [00:29<02:17,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 240/1348 [00:29<02:16,  8.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 241/1348 [00:29<02:16,  8.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 242/1348 [00:30<02:16,  8.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 243/1348 [00:30<02:16,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 244/1348 [00:30<02:16,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 245/1348 [00:30<02:17,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 246/1348 [00:30<02:16,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 247/1348 [00:30<02:16,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 248/1348 [00:30<02:16,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 249/1348 [00:30<02:15,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 250/1348 [00:31<02:15,  8.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 251/1348 [00:31<02:23,  7.64it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 252/1348 [00:31<02:21,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 253/1348 [00:31<02:20,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 254/1348 [00:31<02:18,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 255/1348 [00:31<02:17,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 256/1348 [00:31<02:17,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 257/1348 [00:31<02:16,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 258/1348 [00:32<02:16,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 259/1348 [00:32<02:16,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 260/1348 [00:32<02:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 261/1348 [00:32<02:15,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 262/1348 [00:32<02:15,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 263/1348 [00:32<02:14,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 264/1348 [00:32<02:14,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 265/1348 [00:32<02:14,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 266/1348 [00:33<02:14,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 267/1348 [00:33<02:14,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 268/1348 [00:33<02:14,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 269/1348 [00:33<02:15,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 270/1348 [00:33<02:15,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 271/1348 [00:33<02:15,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 272/1348 [00:33<02:14,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 273/1348 [00:33<02:14,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 274/1348 [00:34<02:13,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 275/1348 [00:34<02:14,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 276/1348 [00:34<02:14,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 277/1348 [00:34<02:15,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 278/1348 [00:34<02:14,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 279/1348 [00:34<02:13,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 280/1348 [00:34<02:13,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 281/1348 [00:34<02:12,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 282/1348 [00:35<02:12,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 283/1348 [00:35<02:12,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 284/1348 [00:35<02:12,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 285/1348 [00:35<02:12,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 286/1348 [00:35<02:12,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|âââ       | 287/1348 [00:35<02:12,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|âââ       | 288/1348 [00:35<02:12,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|âââ       | 289/1348 [00:35<02:11,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 290/1348 [00:36<02:11,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 291/1348 [00:36<02:11,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 292/1348 [00:36<02:11,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 293/1348 [00:36<02:11,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 294/1348 [00:36<02:11,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 295/1348 [00:36<02:10,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 296/1348 [00:36<02:10,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 297/1348 [00:36<02:10,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 298/1348 [00:37<02:10,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 299/1348 [00:37<02:10,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 300/1348 [00:37<02:10,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 301/1348 [00:37<02:11,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 302/1348 [00:37<02:11,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 303/1348 [00:37<02:10,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 304/1348 [00:37<02:10,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 305/1348 [00:37<02:10,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 306/1348 [00:38<02:09,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 307/1348 [00:38<02:10,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 308/1348 [00:38<02:10,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 309/1348 [00:38<02:09,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 310/1348 [00:38<02:10,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 311/1348 [00:38<02:10,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 312/1348 [00:38<02:09,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 313/1348 [00:38<02:09,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 314/1348 [00:39<02:09,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 315/1348 [00:39<02:09,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 316/1348 [00:39<02:09,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 317/1348 [00:39<02:10,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 318/1348 [00:39<02:09,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 319/1348 [00:39<02:09,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 320/1348 [00:39<02:09,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 321/1348 [00:39<02:08,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 322/1348 [00:40<02:09,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 323/1348 [00:40<02:09,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 324/1348 [00:40<02:10,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 325/1348 [00:40<02:10,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 326/1348 [00:40<02:09,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 327/1348 [00:40<02:08,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 328/1348 [00:40<02:08,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 329/1348 [00:40<02:07,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 330/1348 [00:41<02:07,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 331/1348 [00:41<02:06,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 332/1348 [00:41<02:06,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 333/1348 [00:41<02:06,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 334/1348 [00:41<02:05,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 335/1348 [00:41<02:05,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 336/1348 [00:41<02:05,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 337/1348 [00:41<02:05,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 338/1348 [00:42<02:06,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 339/1348 [00:42<02:06,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 340/1348 [00:42<02:06,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 341/1348 [00:42<02:06,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 342/1348 [00:42<02:05,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 343/1348 [00:42<02:05,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 344/1348 [00:42<02:04,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 345/1348 [00:42<02:04,  8.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 346/1348 [00:43<02:04,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 347/1348 [00:43<02:04,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 348/1348 [00:43<02:04,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 349/1348 [00:43<02:03,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 350/1348 [00:43<02:03,  8.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 351/1348 [00:43<02:03,  8.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 352/1348 [00:43<02:02,  8.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 353/1348 [00:43<02:03,  8.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 354/1348 [00:44<02:02,  8.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 355/1348 [00:44<02:02,  8.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 356/1348 [00:44<02:02,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 357/1348 [00:44<02:03,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 358/1348 [00:44<02:03,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 359/1348 [00:44<02:03,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 360/1348 [00:44<02:03,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 361/1348 [00:44<02:03,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 362/1348 [00:45<02:02,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 363/1348 [00:45<02:02,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 364/1348 [00:45<02:03,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 365/1348 [00:45<02:03,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 366/1348 [00:45<02:02,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 367/1348 [00:45<02:02,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 368/1348 [00:45<02:02,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 369/1348 [00:45<02:02,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 370/1348 [00:46<02:01,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 371/1348 [00:46<02:01,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 372/1348 [00:46<02:01,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 373/1348 [00:46<02:01,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 374/1348 [00:46<02:01,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 375/1348 [00:46<02:01,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 376/1348 [00:46<02:01,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 377/1348 [00:46<02:01,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 378/1348 [00:47<02:00,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 379/1348 [00:47<02:03,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 380/1348 [00:47<02:02,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 381/1348 [00:47<02:02,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 382/1348 [00:47<02:01,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 383/1348 [00:47<02:00,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 384/1348 [00:47<02:00,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 385/1348 [00:47<02:00,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 386/1348 [00:48<02:00,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 387/1348 [00:48<02:00,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 388/1348 [00:48<02:00,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 389/1348 [00:48<02:00,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 390/1348 [00:48<01:59,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 391/1348 [00:48<01:59,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 392/1348 [00:48<01:59,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 393/1348 [00:48<01:59,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 394/1348 [00:49<01:59,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 395/1348 [00:49<01:58,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 396/1348 [00:49<01:58,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 397/1348 [00:49<01:59,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 398/1348 [00:49<01:59,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 399/1348 [00:49<01:59,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 400/1348 [00:49<01:58,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 401/1348 [00:49<01:58,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 402/1348 [00:50<01:58,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 403/1348 [00:50<01:58,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 404/1348 [00:50<01:58,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 405/1348 [00:50<01:58,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 406/1348 [00:50<01:57,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 407/1348 [00:50<01:57,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 408/1348 [00:50<01:58,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 409/1348 [00:50<01:57,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 410/1348 [00:51<01:57,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 411/1348 [00:51<01:57,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 412/1348 [00:51<01:57,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 413/1348 [00:51<01:57,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 414/1348 [00:51<01:57,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 415/1348 [00:51<01:57,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 416/1348 [00:51<01:56,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 417/1348 [00:51<01:56,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 418/1348 [00:52<01:56,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 419/1348 [00:52<01:58,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 420/1348 [00:52<01:57,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 421/1348 [00:52<01:57,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|ââââ      | 422/1348 [00:52<01:56,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|ââââ      | 423/1348 [00:52<01:56,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|ââââ      | 424/1348 [00:52<01:55,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 425/1348 [00:52<01:56,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 426/1348 [00:53<01:55,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 427/1348 [00:53<01:55,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 428/1348 [00:53<01:54,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 429/1348 [00:53<01:55,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 430/1348 [00:53<01:55,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 431/1348 [00:53<01:54,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 432/1348 [00:53<01:55,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 433/1348 [00:54<01:55,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 434/1348 [00:54<01:54,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 435/1348 [00:54<01:54,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 436/1348 [00:54<01:53,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 437/1348 [00:54<01:54,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 438/1348 [00:54<01:54,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 439/1348 [00:54<01:54,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 440/1348 [00:54<01:54,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 441/1348 [00:55<01:54,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 442/1348 [00:55<01:53,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 443/1348 [00:55<01:53,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 444/1348 [00:55<01:53,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 445/1348 [00:55<01:53,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 446/1348 [00:55<01:52,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 447/1348 [00:55<01:52,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 448/1348 [00:55<01:52,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 449/1348 [00:56<01:52,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 450/1348 [00:56<01:52,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 451/1348 [00:56<01:52,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 452/1348 [00:56<01:53,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 453/1348 [00:56<01:54,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 454/1348 [00:56<01:53,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 455/1348 [00:56<01:53,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 456/1348 [00:56<01:52,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 457/1348 [00:57<01:52,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 458/1348 [00:57<01:51,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 459/1348 [00:57<01:52,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 460/1348 [00:57<01:51,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 461/1348 [00:57<01:51,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 462/1348 [00:57<01:51,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 463/1348 [00:57<01:51,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 464/1348 [00:57<01:50,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 465/1348 [00:58<01:50,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 466/1348 [00:58<01:50,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 467/1348 [00:58<01:50,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 468/1348 [00:58<01:50,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 469/1348 [00:58<01:50,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 470/1348 [00:58<01:50,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 471/1348 [00:58<01:50,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 472/1348 [00:58<01:50,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 473/1348 [00:59<01:50,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 474/1348 [00:59<01:49,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 475/1348 [00:59<01:49,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 476/1348 [00:59<01:48,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 477/1348 [00:59<01:48,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 478/1348 [00:59<01:48,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 479/1348 [00:59<01:49,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 480/1348 [00:59<01:48,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 481/1348 [01:00<01:48,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 482/1348 [01:00<01:48,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 483/1348 [01:00<01:48,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 484/1348 [01:00<01:47,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 485/1348 [01:00<01:48,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 486/1348 [01:00<01:47,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 487/1348 [01:00<01:47,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 488/1348 [01:00<01:47,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 489/1348 [01:01<01:47,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 490/1348 [01:01<01:47,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 491/1348 [01:01<01:47,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 492/1348 [01:01<01:46,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 493/1348 [01:01<01:47,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 494/1348 [01:01<01:47,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 495/1348 [01:01<01:46,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 496/1348 [01:01<01:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 497/1348 [01:02<01:47,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 498/1348 [01:02<01:47,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 499/1348 [01:02<01:46,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 500/1348 [01:02<01:47,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 501/1348 [01:02<01:46,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 502/1348 [01:02<01:46,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 503/1348 [01:02<01:45,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 504/1348 [01:02<01:46,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 505/1348 [01:03<01:46,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 506/1348 [01:03<01:45,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 507/1348 [01:03<01:45,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 508/1348 [01:03<01:45,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 509/1348 [01:03<01:45,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 510/1348 [01:03<01:45,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 511/1348 [01:03<01:44,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 512/1348 [01:03<01:44,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 513/1348 [01:04<01:44,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 514/1348 [01:04<01:44,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 515/1348 [01:04<01:43,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 516/1348 [01:04<01:43,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 517/1348 [01:04<01:45,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 518/1348 [01:04<01:46,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 519/1348 [01:04<01:46,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 520/1348 [01:04<01:46,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 521/1348 [01:05<01:46,  7.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 522/1348 [01:05<01:45,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 523/1348 [01:05<01:45,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 524/1348 [01:05<01:45,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 525/1348 [01:05<01:45,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 526/1348 [01:05<01:45,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 527/1348 [01:05<01:45,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 528/1348 [01:05<01:44,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 529/1348 [01:06<01:45,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 530/1348 [01:06<01:44,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 531/1348 [01:06<01:44,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 532/1348 [01:06<01:44,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 533/1348 [01:06<01:44,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 534/1348 [01:06<01:44,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 535/1348 [01:06<01:44,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 536/1348 [01:06<01:44,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 537/1348 [01:07<01:43,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 538/1348 [01:07<01:42,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 539/1348 [01:07<01:43,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 540/1348 [01:07<01:42,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 541/1348 [01:07<01:43,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 542/1348 [01:07<01:43,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 543/1348 [01:07<01:43,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 544/1348 [01:08<01:43,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 545/1348 [01:08<01:42,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 546/1348 [01:08<01:42,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 547/1348 [01:08<01:42,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 548/1348 [01:08<01:42,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 549/1348 [01:08<01:42,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 550/1348 [01:08<01:42,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 551/1348 [01:08<01:41,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 552/1348 [01:09<01:41,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 553/1348 [01:09<01:41,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 554/1348 [01:09<01:41,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 555/1348 [01:09<01:41,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 556/1348 [01:09<01:41,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 557/1348 [01:09<01:42,  7.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 558/1348 [01:09<01:41,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 559/1348 [01:09<01:40,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 560/1348 [01:10<01:39,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 561/1348 [01:10<01:38,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 562/1348 [01:10<01:38,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 563/1348 [01:10<01:38,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 564/1348 [01:10<01:38,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 565/1348 [01:10<01:38,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 566/1348 [01:10<01:38,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 567/1348 [01:10<01:37,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 568/1348 [01:11<01:37,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 569/1348 [01:11<01:37,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 570/1348 [01:11<01:36,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 571/1348 [01:11<01:36,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 572/1348 [01:11<01:36,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 573/1348 [01:11<01:36,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 574/1348 [01:11<01:36,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 575/1348 [01:11<01:36,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 576/1348 [01:12<01:36,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 577/1348 [01:12<01:35,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 578/1348 [01:12<01:35,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 579/1348 [01:12<01:37,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 580/1348 [01:12<01:37,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 581/1348 [01:12<01:37,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 582/1348 [01:12<01:37,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 583/1348 [01:12<01:37,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 584/1348 [01:13<01:36,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 585/1348 [01:13<01:36,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 586/1348 [01:13<01:36,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 587/1348 [01:13<01:35,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 588/1348 [01:13<01:35,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 589/1348 [01:13<01:35,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 590/1348 [01:13<01:35,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 591/1348 [01:13<01:35,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 592/1348 [01:14<01:35,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 593/1348 [01:14<01:35,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 594/1348 [01:14<01:34,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 595/1348 [01:14<01:34,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 596/1348 [01:14<01:34,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 597/1348 [01:14<01:34,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 598/1348 [01:14<01:34,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 599/1348 [01:14<01:34,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 600/1348 [01:15<01:34,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 601/1348 [01:15<01:34,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 602/1348 [01:15<01:34,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 603/1348 [01:15<01:34,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 604/1348 [01:15<01:33,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 605/1348 [01:15<01:33,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 606/1348 [01:15<01:32,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 607/1348 [01:15<01:32,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 608/1348 [01:16<01:32,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 609/1348 [01:16<01:32,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 610/1348 [01:16<01:32,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 611/1348 [01:16<01:32,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 612/1348 [01:16<01:32,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 613/1348 [01:16<01:32,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 614/1348 [01:16<01:32,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 615/1348 [01:16<01:32,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 616/1348 [01:17<01:32,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 617/1348 [01:17<01:32,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 618/1348 [01:17<01:32,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 619/1348 [01:17<01:32,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 620/1348 [01:17<01:32,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 621/1348 [01:17<01:32,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 622/1348 [01:17<01:31,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 623/1348 [01:17<01:31,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 624/1348 [01:18<01:30,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 625/1348 [01:18<01:30,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 626/1348 [01:18<01:31,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 627/1348 [01:18<01:31,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 628/1348 [01:18<01:30,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 629/1348 [01:18<01:30,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 630/1348 [01:18<01:30,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 631/1348 [01:18<01:30,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 632/1348 [01:19<01:29,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 633/1348 [01:19<01:29,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 634/1348 [01:19<01:29,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 635/1348 [01:19<01:29,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 636/1348 [01:19<01:29,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 637/1348 [01:19<01:29,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 638/1348 [01:19<01:29,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 639/1348 [01:19<01:29,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 640/1348 [01:20<01:28,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 641/1348 [01:20<01:28,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 642/1348 [01:20<01:28,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 643/1348 [01:20<01:28,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 644/1348 [01:20<01:28,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 645/1348 [01:20<01:28,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 646/1348 [01:20<01:28,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 647/1348 [01:20<01:28,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 648/1348 [01:21<01:28,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 649/1348 [01:21<01:27,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 650/1348 [01:21<01:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 651/1348 [01:21<01:27,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 652/1348 [01:21<01:27,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 653/1348 [01:21<01:26,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 654/1348 [01:21<01:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 655/1348 [01:21<01:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 656/1348 [01:22<01:27,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 657/1348 [01:22<01:26,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 658/1348 [01:22<01:26,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 659/1348 [01:22<01:26,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 660/1348 [01:22<01:26,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 661/1348 [01:22<01:26,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 662/1348 [01:22<01:26,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 663/1348 [01:23<01:26,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 664/1348 [01:23<01:26,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 665/1348 [01:23<01:25,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 666/1348 [01:23<01:25,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 667/1348 [01:23<01:25,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 668/1348 [01:23<01:25,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 669/1348 [01:23<01:25,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 670/1348 [01:23<01:25,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 671/1348 [01:24<01:25,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 672/1348 [01:24<01:25,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 673/1348 [01:24<01:24,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 674/1348 [01:24<01:24,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 675/1348 [01:24<01:24,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 676/1348 [01:24<01:24,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 677/1348 [01:24<01:24,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 678/1348 [01:24<01:24,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 679/1348 [01:25<01:24,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 680/1348 [01:25<01:23,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 681/1348 [01:25<01:23,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 682/1348 [01:25<01:23,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 683/1348 [01:25<01:22,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 684/1348 [01:25<01:23,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 685/1348 [01:25<01:23,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 686/1348 [01:25<01:23,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 687/1348 [01:26<01:23,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 688/1348 [01:26<01:23,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 689/1348 [01:26<01:23,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 690/1348 [01:26<01:22,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 691/1348 [01:26<01:22,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 692/1348 [01:26<01:22,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 693/1348 [01:26<01:22,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 694/1348 [01:26<01:22,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 695/1348 [01:27<01:22,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 696/1348 [01:27<01:21,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 697/1348 [01:27<01:21,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 698/1348 [01:27<01:21,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 699/1348 [01:27<01:21,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 700/1348 [01:27<01:21,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 701/1348 [01:27<01:21,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 702/1348 [01:27<01:22,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 703/1348 [01:28<01:21,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 704/1348 [01:28<01:21,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 705/1348 [01:28<01:21,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 706/1348 [01:28<01:21,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 707/1348 [01:28<01:21,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 708/1348 [01:28<01:20,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 709/1348 [01:28<01:20,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 710/1348 [01:28<01:20,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 711/1348 [01:29<01:20,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 712/1348 [01:29<01:20,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 713/1348 [01:29<01:20,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 714/1348 [01:29<01:19,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 715/1348 [01:29<01:19,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 716/1348 [01:29<01:19,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 717/1348 [01:29<01:19,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 718/1348 [01:29<01:19,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 719/1348 [01:30<01:19,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 720/1348 [01:30<01:19,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 721/1348 [01:30<01:18,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 722/1348 [01:30<01:18,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 723/1348 [01:30<01:18,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 724/1348 [01:30<01:18,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 725/1348 [01:30<01:18,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 726/1348 [01:30<01:18,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 727/1348 [01:31<01:18,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 728/1348 [01:31<01:18,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 729/1348 [01:31<01:18,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 730/1348 [01:31<01:17,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 731/1348 [01:31<01:17,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 732/1348 [01:31<01:17,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 733/1348 [01:31<01:16,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 734/1348 [01:31<01:17,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 735/1348 [01:32<01:16,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 736/1348 [01:32<01:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 737/1348 [01:32<01:16,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 738/1348 [01:32<01:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 739/1348 [01:32<01:16,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 740/1348 [01:32<01:17,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 741/1348 [01:32<01:16,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 742/1348 [01:32<01:16,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 743/1348 [01:33<01:16,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 744/1348 [01:33<01:16,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 745/1348 [01:33<01:16,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 746/1348 [01:33<01:16,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 747/1348 [01:33<01:15,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 748/1348 [01:33<01:15,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 749/1348 [01:33<01:15,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 750/1348 [01:33<01:15,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 751/1348 [01:34<01:19,  7.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 752/1348 [01:34<01:17,  7.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 753/1348 [01:34<01:17,  7.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 754/1348 [01:34<01:16,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 755/1348 [01:34<01:15,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 756/1348 [01:34<01:15,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 757/1348 [01:34<01:14,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 758/1348 [01:34<01:14,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 759/1348 [01:35<01:14,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 760/1348 [01:35<01:14,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 761/1348 [01:35<01:13,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 762/1348 [01:35<01:13,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 763/1348 [01:35<01:13,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 764/1348 [01:35<01:13,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 765/1348 [01:35<01:12,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 766/1348 [01:35<01:13,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 767/1348 [01:36<01:12,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 768/1348 [01:36<01:12,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 769/1348 [01:36<01:12,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 770/1348 [01:36<01:12,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 771/1348 [01:36<01:12,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 772/1348 [01:36<01:12,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 773/1348 [01:36<01:12,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 774/1348 [01:36<01:12,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 775/1348 [01:37<01:12,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 776/1348 [01:37<01:11,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 777/1348 [01:37<01:11,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 778/1348 [01:37<01:11,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 779/1348 [01:37<01:11,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 780/1348 [01:37<01:13,  7.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 781/1348 [01:37<01:12,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 782/1348 [01:38<01:12,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 783/1348 [01:38<01:11,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 784/1348 [01:38<01:11,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 785/1348 [01:38<01:11,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 786/1348 [01:38<01:10,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 787/1348 [01:38<01:10,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 788/1348 [01:38<01:10,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 789/1348 [01:38<01:09,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 790/1348 [01:39<01:09,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 791/1348 [01:39<01:09,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 792/1348 [01:39<01:09,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 793/1348 [01:39<01:09,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 794/1348 [01:39<01:09,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 795/1348 [01:39<01:09,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 796/1348 [01:39<01:09,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 797/1348 [01:39<01:09,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 798/1348 [01:40<01:09,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 799/1348 [01:40<01:09,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 800/1348 [01:40<01:08,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 801/1348 [01:40<01:08,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 802/1348 [01:40<01:08,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 803/1348 [01:40<01:08,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 804/1348 [01:40<01:08,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 805/1348 [01:40<01:08,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 806/1348 [01:41<01:08,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 807/1348 [01:41<01:07,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 808/1348 [01:41<01:07,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 809/1348 [01:41<01:07,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 810/1348 [01:41<01:07,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 811/1348 [01:41<01:06,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 812/1348 [01:41<01:06,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 813/1348 [01:41<01:06,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 814/1348 [01:42<01:06,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 815/1348 [01:42<01:07,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 816/1348 [01:42<01:06,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 817/1348 [01:42<01:06,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 818/1348 [01:42<01:06,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 819/1348 [01:42<01:06,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 820/1348 [01:42<01:06,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 821/1348 [01:42<01:06,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 822/1348 [01:43<01:06,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 823/1348 [01:43<01:06,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 824/1348 [01:43<01:05,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 825/1348 [01:43<01:05,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 826/1348 [01:43<01:05,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 827/1348 [01:43<01:05,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 828/1348 [01:43<01:04,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 829/1348 [01:43<01:04,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 830/1348 [01:44<01:04,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 831/1348 [01:44<01:04,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 832/1348 [01:44<01:04,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 833/1348 [01:44<01:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 834/1348 [01:44<01:04,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 835/1348 [01:44<01:04,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 836/1348 [01:44<01:04,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 837/1348 [01:44<01:04,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 838/1348 [01:45<01:04,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 839/1348 [01:45<01:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 840/1348 [01:45<01:03,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 841/1348 [01:45<01:03,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 842/1348 [01:45<01:03,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 843/1348 [01:45<01:03,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 844/1348 [01:45<01:03,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 845/1348 [01:45<01:03,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 846/1348 [01:46<01:02,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 847/1348 [01:46<01:03,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 848/1348 [01:46<01:03,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 849/1348 [01:46<01:02,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 850/1348 [01:46<01:02,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 851/1348 [01:46<01:02,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 852/1348 [01:46<01:01,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 853/1348 [01:46<01:01,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 854/1348 [01:47<01:01,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 855/1348 [01:47<01:02,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 856/1348 [01:47<01:01,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 857/1348 [01:47<01:01,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 858/1348 [01:47<01:01,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 859/1348 [01:47<01:01,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 860/1348 [01:47<01:01,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 861/1348 [01:47<01:01,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 862/1348 [01:48<01:01,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 863/1348 [01:48<01:01,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 864/1348 [01:48<01:01,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 865/1348 [01:48<01:01,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 866/1348 [01:48<01:00,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 867/1348 [01:48<01:00,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 868/1348 [01:48<01:00,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 869/1348 [01:48<00:59,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 870/1348 [01:49<00:59,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 871/1348 [01:49<01:00,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 872/1348 [01:49<00:59,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 873/1348 [01:49<00:59,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 874/1348 [01:49<00:59,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 875/1348 [01:49<00:59,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 876/1348 [01:49<00:59,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 877/1348 [01:49<00:59,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 878/1348 [01:50<00:59,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 879/1348 [01:50<00:59,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 880/1348 [01:50<00:58,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 881/1348 [01:50<00:58,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 882/1348 [01:50<00:58,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 883/1348 [01:50<00:58,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 884/1348 [01:50<00:58,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 885/1348 [01:50<00:58,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 886/1348 [01:51<00:58,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 887/1348 [01:51<00:58,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 888/1348 [01:51<00:57,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 889/1348 [01:51<00:57,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 890/1348 [01:51<00:57,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 891/1348 [01:51<00:57,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 892/1348 [01:51<00:56,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 893/1348 [01:51<00:56,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 894/1348 [01:52<00:56,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 895/1348 [01:52<00:56,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 896/1348 [01:52<00:56,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 897/1348 [01:52<00:56,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 898/1348 [01:52<00:56,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 899/1348 [01:52<00:56,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 900/1348 [01:52<00:55,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 901/1348 [01:52<00:56,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 902/1348 [01:53<00:56,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 903/1348 [01:53<00:56,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 904/1348 [01:53<00:56,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 905/1348 [01:53<00:55,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 906/1348 [01:53<00:55,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 907/1348 [01:53<00:55,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 908/1348 [01:53<00:55,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 909/1348 [01:53<00:55,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 910/1348 [01:54<00:54,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 911/1348 [01:54<00:55,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 912/1348 [01:54<00:54,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 913/1348 [01:54<00:54,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 914/1348 [01:54<00:54,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 915/1348 [01:54<00:54,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 916/1348 [01:54<00:54,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 917/1348 [01:54<00:54,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 918/1348 [01:55<00:53,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 919/1348 [01:55<00:53,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 920/1348 [01:55<00:53,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 921/1348 [01:55<00:53,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 922/1348 [01:55<00:53,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 923/1348 [01:55<00:53,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 924/1348 [01:55<00:53,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 925/1348 [01:55<00:53,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 926/1348 [01:56<00:52,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 927/1348 [01:56<00:53,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 928/1348 [01:56<00:52,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 929/1348 [01:56<00:52,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 930/1348 [01:56<00:52,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 931/1348 [01:56<00:53,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 932/1348 [01:56<00:52,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 933/1348 [01:56<00:52,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 934/1348 [01:57<00:52,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 935/1348 [01:57<00:52,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 936/1348 [01:57<00:51,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 937/1348 [01:57<00:51,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 938/1348 [01:57<00:51,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 939/1348 [01:57<00:51,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 940/1348 [01:57<00:51,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 941/1348 [01:57<00:52,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 942/1348 [01:58<00:51,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 943/1348 [01:58<00:51,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 944/1348 [01:58<00:51,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 945/1348 [01:58<00:50,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 946/1348 [01:58<00:50,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 947/1348 [01:58<00:50,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 948/1348 [01:58<00:50,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 949/1348 [01:59<00:50,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 950/1348 [01:59<00:49,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 951/1348 [01:59<00:49,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 952/1348 [01:59<00:49,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 953/1348 [01:59<00:49,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 954/1348 [01:59<00:49,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 955/1348 [01:59<00:49,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 956/1348 [01:59<00:48,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 957/1348 [02:00<00:49,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 958/1348 [02:00<00:48,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 959/1348 [02:00<00:48,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 960/1348 [02:00<00:48,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|ââââââââ  | 961/1348 [02:00<00:48,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|ââââââââ  | 962/1348 [02:00<00:48,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|ââââââââ  | 963/1348 [02:00<00:48,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 964/1348 [02:00<00:47,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 965/1348 [02:01<00:47,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 966/1348 [02:01<00:47,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 967/1348 [02:01<00:47,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 968/1348 [02:01<00:47,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 969/1348 [02:01<00:47,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 970/1348 [02:01<00:47,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 971/1348 [02:01<00:47,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 972/1348 [02:01<00:46,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 973/1348 [02:02<00:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 974/1348 [02:02<00:46,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 975/1348 [02:02<00:46,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 976/1348 [02:02<00:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 977/1348 [02:02<00:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 978/1348 [02:02<00:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 979/1348 [02:02<00:46,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 980/1348 [02:02<00:45,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 981/1348 [02:03<00:46,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 982/1348 [02:03<00:46,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 983/1348 [02:03<00:46,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 984/1348 [02:03<00:46,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 985/1348 [02:03<00:45,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 986/1348 [02:03<00:45,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 987/1348 [02:03<00:45,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 988/1348 [02:03<00:45,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 989/1348 [02:04<00:45,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 990/1348 [02:04<00:44,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 991/1348 [02:04<00:44,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 992/1348 [02:04<00:44,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 993/1348 [02:04<00:44,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 994/1348 [02:04<00:44,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 995/1348 [02:04<00:44,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 996/1348 [02:04<00:44,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 997/1348 [02:05<00:44,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 998/1348 [02:05<00:44,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 999/1348 [02:05<00:44,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1000/1348 [02:05<00:43,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1001/1348 [02:05<00:43,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1002/1348 [02:05<00:43,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1003/1348 [02:05<00:43,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1004/1348 [02:05<00:43,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1005/1348 [02:06<00:43,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1006/1348 [02:06<00:42,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1007/1348 [02:06<00:42,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1008/1348 [02:06<00:42,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1009/1348 [02:06<00:42,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1010/1348 [02:06<00:42,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1011/1348 [02:06<00:42,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1012/1348 [02:06<00:42,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1013/1348 [02:07<00:42,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1014/1348 [02:07<00:41,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1015/1348 [02:07<00:41,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1016/1348 [02:07<00:41,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1017/1348 [02:07<00:41,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1018/1348 [02:07<00:41,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1019/1348 [02:07<00:41,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1020/1348 [02:07<00:41,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1021/1348 [02:08<00:41,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1022/1348 [02:08<00:41,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1023/1348 [02:08<00:40,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1024/1348 [02:08<00:40,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1025/1348 [02:08<00:40,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1026/1348 [02:08<00:40,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1027/1348 [02:08<00:40,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1028/1348 [02:08<00:40,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1029/1348 [02:09<00:39,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1030/1348 [02:09<00:39,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1031/1348 [02:09<00:39,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1032/1348 [02:09<00:40,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1033/1348 [02:09<00:39,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1034/1348 [02:09<00:39,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1035/1348 [02:09<00:39,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1036/1348 [02:09<00:39,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1037/1348 [02:10<00:38,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1038/1348 [02:10<00:38,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1039/1348 [02:10<00:38,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1040/1348 [02:10<00:38,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1041/1348 [02:10<00:38,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1042/1348 [02:10<00:38,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1043/1348 [02:10<00:38,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1044/1348 [02:10<00:38,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1045/1348 [02:11<00:38,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1046/1348 [02:11<00:38,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1047/1348 [02:11<00:37,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1048/1348 [02:11<00:37,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1049/1348 [02:11<00:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1050/1348 [02:11<00:37,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1051/1348 [02:11<00:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1052/1348 [02:11<00:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1053/1348 [02:12<00:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1054/1348 [02:12<00:37,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1055/1348 [02:12<00:36,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1056/1348 [02:12<00:36,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1057/1348 [02:12<00:36,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1058/1348 [02:12<00:36,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1059/1348 [02:12<00:36,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1060/1348 [02:12<00:36,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1061/1348 [02:13<00:36,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1062/1348 [02:13<00:36,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1063/1348 [02:13<00:36,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1064/1348 [02:13<00:35,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1065/1348 [02:13<00:35,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1066/1348 [02:13<00:35,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1067/1348 [02:13<00:35,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1068/1348 [02:13<00:35,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1069/1348 [02:14<00:35,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1070/1348 [02:14<00:34,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1071/1348 [02:14<00:34,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1072/1348 [02:14<00:34,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1073/1348 [02:14<00:34,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1074/1348 [02:14<00:34,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1075/1348 [02:14<00:34,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1076/1348 [02:14<00:33,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1077/1348 [02:15<00:33,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1078/1348 [02:15<00:33,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1079/1348 [02:15<00:33,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1080/1348 [02:15<00:33,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1081/1348 [02:15<00:33,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1082/1348 [02:15<00:33,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1083/1348 [02:15<00:32,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1084/1348 [02:15<00:32,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1085/1348 [02:16<00:32,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1086/1348 [02:16<00:32,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1087/1348 [02:16<00:32,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1088/1348 [02:16<00:32,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1089/1348 [02:16<00:32,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1090/1348 [02:16<00:32,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1091/1348 [02:16<00:32,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1092/1348 [02:16<00:32,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1093/1348 [02:17<00:31,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1094/1348 [02:17<00:31,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1095/1348 [02:17<00:31,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|âââââââââ | 1096/1348 [02:17<00:31,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|âââââââââ | 1097/1348 [02:17<00:31,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|âââââââââ | 1098/1348 [02:17<00:31,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1099/1348 [02:17<00:31,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1100/1348 [02:17<00:31,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1101/1348 [02:18<00:31,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1102/1348 [02:18<00:30,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1103/1348 [02:18<00:30,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1104/1348 [02:18<00:30,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1105/1348 [02:18<00:30,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1106/1348 [02:18<00:30,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1107/1348 [02:18<00:30,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1108/1348 [02:18<00:30,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1109/1348 [02:19<00:30,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1110/1348 [02:19<00:29,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1111/1348 [02:19<00:29,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1112/1348 [02:19<00:29,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1113/1348 [02:19<00:29,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1114/1348 [02:19<00:29,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1115/1348 [02:19<00:29,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1116/1348 [02:19<00:29,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1117/1348 [02:20<00:29,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1118/1348 [02:20<00:28,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1119/1348 [02:20<00:28,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1120/1348 [02:20<00:28,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1121/1348 [02:20<00:28,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1122/1348 [02:20<00:28,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1123/1348 [02:20<00:28,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1124/1348 [02:20<00:28,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1125/1348 [02:21<00:28,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1126/1348 [02:21<00:27,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1127/1348 [02:21<00:27,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1128/1348 [02:21<00:27,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1129/1348 [02:21<00:27,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1130/1348 [02:21<00:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1131/1348 [02:21<00:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1132/1348 [02:21<00:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1133/1348 [02:22<00:26,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1134/1348 [02:22<00:26,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1135/1348 [02:22<00:26,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1136/1348 [02:22<00:26,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1137/1348 [02:22<00:26,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1138/1348 [02:22<00:26,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1139/1348 [02:22<00:26,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1140/1348 [02:22<00:26,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1141/1348 [02:23<00:25,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1142/1348 [02:23<00:26,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1143/1348 [02:23<00:26,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1144/1348 [02:23<00:25,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1145/1348 [02:23<00:25,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1146/1348 [02:23<00:25,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1147/1348 [02:23<00:25,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1148/1348 [02:24<00:25,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1149/1348 [02:24<00:24,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1150/1348 [02:24<00:24,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1151/1348 [02:24<00:24,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1152/1348 [02:24<00:24,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1153/1348 [02:24<00:24,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1154/1348 [02:24<00:24,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1155/1348 [02:24<00:24,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1156/1348 [02:25<00:24,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1157/1348 [02:25<00:24,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1158/1348 [02:25<00:23,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1159/1348 [02:25<00:23,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1160/1348 [02:25<00:23,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1161/1348 [02:25<00:23,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1162/1348 [02:25<00:23,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1163/1348 [02:25<00:23,  7.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1164/1348 [02:26<00:23,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1165/1348 [02:26<00:23,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1166/1348 [02:26<00:23,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1167/1348 [02:26<00:22,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1168/1348 [02:26<00:22,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1169/1348 [02:26<00:22,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1170/1348 [02:26<00:22,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1171/1348 [02:26<00:22,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1172/1348 [02:27<00:22,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1173/1348 [02:27<00:22,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1174/1348 [02:27<00:21,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1175/1348 [02:27<00:21,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1176/1348 [02:27<00:21,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1177/1348 [02:27<00:21,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1178/1348 [02:27<00:21,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1179/1348 [02:27<00:21,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1180/1348 [02:28<00:21,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1181/1348 [02:28<00:20,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1182/1348 [02:28<00:20,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1183/1348 [02:28<00:20,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1184/1348 [02:28<00:20,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1185/1348 [02:28<00:20,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1186/1348 [02:28<00:20,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1187/1348 [02:28<00:20,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1188/1348 [02:29<00:20,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1189/1348 [02:29<00:20,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1190/1348 [02:29<00:19,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1191/1348 [02:29<00:19,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1192/1348 [02:29<00:19,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1193/1348 [02:29<00:19,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1194/1348 [02:29<00:19,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1195/1348 [02:29<00:19,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1196/1348 [02:30<00:19,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1197/1348 [02:30<00:18,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1198/1348 [02:30<00:18,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1199/1348 [02:30<00:18,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1200/1348 [02:30<00:18,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1201/1348 [02:30<00:18,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1202/1348 [02:30<00:18,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1203/1348 [02:30<00:18,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1204/1348 [02:31<00:18,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1205/1348 [02:31<00:17,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1206/1348 [02:31<00:17,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1207/1348 [02:31<00:17,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1208/1348 [02:31<00:17,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1209/1348 [02:31<00:17,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1210/1348 [02:31<00:17,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1211/1348 [02:31<00:17,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1212/1348 [02:32<00:17,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1213/1348 [02:32<00:16,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1214/1348 [02:32<00:16,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1215/1348 [02:32<00:16,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1216/1348 [02:32<00:16,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1217/1348 [02:32<00:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1218/1348 [02:32<00:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1219/1348 [02:32<00:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1220/1348 [02:33<00:15,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1221/1348 [02:33<00:15,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1222/1348 [02:33<00:15,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1223/1348 [02:33<00:15,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1224/1348 [02:33<00:15,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1225/1348 [02:33<00:15,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1226/1348 [02:33<00:15,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1227/1348 [02:33<00:15,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1228/1348 [02:34<00:15,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1229/1348 [02:34<00:14,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1230/1348 [02:34<00:14,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 1231/1348 [02:34<00:14,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 1232/1348 [02:34<00:14,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 1233/1348 [02:34<00:14,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1234/1348 [02:34<00:14,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1235/1348 [02:34<00:14,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1236/1348 [02:35<00:14,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1237/1348 [02:35<00:13,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1238/1348 [02:35<00:13,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1239/1348 [02:35<00:13,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1240/1348 [02:35<00:13,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1241/1348 [02:35<00:13,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1242/1348 [02:35<00:13,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1243/1348 [02:35<00:13,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1244/1348 [02:36<00:13,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1245/1348 [02:36<00:12,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1246/1348 [02:36<00:12,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1247/1348 [02:36<00:12,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1248/1348 [02:36<00:12,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1249/1348 [02:36<00:12,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1250/1348 [02:36<00:12,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1251/1348 [02:36<00:12,  7.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1252/1348 [02:37<00:12,  7.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1253/1348 [02:37<00:12,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1254/1348 [02:37<00:11,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1255/1348 [02:37<00:11,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1256/1348 [02:37<00:11,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1257/1348 [02:37<00:11,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1258/1348 [02:37<00:11,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1259/1348 [02:37<00:11,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1260/1348 [02:38<00:11,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1261/1348 [02:38<00:10,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1262/1348 [02:38<00:10,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1263/1348 [02:38<00:10,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1264/1348 [02:38<00:10,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1265/1348 [02:38<00:10,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1266/1348 [02:38<00:10,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1267/1348 [02:38<00:10,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1268/1348 [02:39<00:10,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1269/1348 [02:39<00:09,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1270/1348 [02:39<00:09,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1271/1348 [02:39<00:09,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1272/1348 [02:39<00:09,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1273/1348 [02:39<00:09,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1274/1348 [02:39<00:09,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1275/1348 [02:40<00:09,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1276/1348 [02:40<00:09,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1277/1348 [02:40<00:08,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1278/1348 [02:40<00:08,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1279/1348 [02:40<00:08,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1280/1348 [02:40<00:08,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1281/1348 [02:40<00:08,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1282/1348 [02:40<00:08,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1283/1348 [02:40<00:08,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1284/1348 [02:41<00:08,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1285/1348 [02:41<00:07,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1286/1348 [02:41<00:07,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1287/1348 [02:41<00:07,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1288/1348 [02:41<00:07,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1289/1348 [02:41<00:07,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1290/1348 [02:41<00:07,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1291/1348 [02:41<00:07,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1292/1348 [02:42<00:06,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1293/1348 [02:42<00:06,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1294/1348 [02:42<00:06,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1295/1348 [02:42<00:06,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1296/1348 [02:42<00:06,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1297/1348 [02:42<00:06,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1298/1348 [02:42<00:06,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1299/1348 [02:43<00:06,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1300/1348 [02:43<00:05,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1301/1348 [02:43<00:05,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1302/1348 [02:43<00:05,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1303/1348 [02:43<00:05,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1304/1348 [02:43<00:05,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1305/1348 [02:43<00:05,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1306/1348 [02:43<00:05,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1307/1348 [02:44<00:05,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1308/1348 [02:44<00:05,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1309/1348 [02:44<00:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1310/1348 [02:44<00:04,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1311/1348 [02:44<00:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1312/1348 [02:44<00:04,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1313/1348 [02:44<00:04,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1314/1348 [02:44<00:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1315/1348 [02:45<00:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1316/1348 [02:45<00:04,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1317/1348 [02:45<00:03,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1318/1348 [02:45<00:03,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1319/1348 [02:45<00:03,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1320/1348 [02:45<00:03,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1321/1348 [02:45<00:03,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1322/1348 [02:45<00:03,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1323/1348 [02:46<00:03,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1324/1348 [02:46<00:03,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1325/1348 [02:46<00:02,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1326/1348 [02:46<00:02,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1327/1348 [02:46<00:02,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1328/1348 [02:46<00:02,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1329/1348 [02:46<00:02,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1330/1348 [02:46<00:02,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1331/1348 [02:47<00:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1332/1348 [02:47<00:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1333/1348 [02:47<00:01,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1334/1348 [02:47<00:01,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1335/1348 [02:47<00:01,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1336/1348 [02:47<00:01,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1337/1348 [02:47<00:01,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1338/1348 [02:47<00:01,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1339/1348 [02:48<00:01,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1340/1348 [02:48<00:01,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1341/1348 [02:48<00:00,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1342/1348 [02:48<00:00,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1343/1348 [02:48<00:00,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1344/1348 [02:48<00:00,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1345/1348 [02:48<00:00,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1346/1348 [02:48<00:00,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1347/1348 [02:49<00:00,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1348/1348 [02:49<00:00,  7.98it/s]#033[A01/14/2021 15:58:25 - INFO - nn_pruning.examples.question_answering.qa_train -     Evaluation done in total 169.298433 secs (0.015699 sec per example)\u001b[0m\n",
      "\u001b[34m01/14/2021 15:58:36 - INFO - nn_pruning.examples.question_answering.qa_utils -   Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/10570 [00:00<?, ?it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 37/10570 [00:00<00:29, 362.87it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  1%|          | 77/10570 [00:00<00:28, 372.43it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  1%|          | 117/10570 [00:00<00:27, 380.24it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 157/10570 [00:00<00:27, 384.29it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 196/10570 [00:00<00:26, 385.03it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 229/10570 [00:00<00:28, 364.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 262/10570 [00:00<00:33, 311.35it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 292/10570 [00:00<00:34, 294.55it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 332/10570 [00:00<00:32, 317.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 373/10570 [00:01<00:29, 340.36it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 410/10570 [00:01<00:29, 346.48it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 447/10570 [00:01<00:28, 351.97it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 486/10570 [00:01<00:27, 360.75it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 527/10570 [00:01<00:26, 372.58it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 565/10570 [00:01<00:26, 371.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 603/10570 [00:01<00:26, 373.83it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 643/10570 [00:01<00:26, 378.49it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 682/10570 [00:01<00:25, 381.78it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 721/10570 [00:01<00:26, 376.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 759/10570 [00:02<00:26, 368.36it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 796/10570 [00:02<00:27, 357.40it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 832/10570 [00:02<00:28, 342.85it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 870/10570 [00:02<00:27, 352.07it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 907/10570 [00:02<00:27, 354.96it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 943/10570 [00:02<00:27, 354.85it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 979/10570 [00:02<00:26, 355.40it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1015/10570 [00:02<00:28, 338.86it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1050/10570 [00:02<00:27, 341.97it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1086/10570 [00:03<00:27, 346.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 1121/10570 [00:03<00:27, 342.30it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 1160/10570 [00:03<00:26, 353.85it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 1198/10570 [00:03<00:26, 358.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 1237/10570 [00:03<00:25, 366.19it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 1274/10570 [00:03<00:25, 363.82it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 1314/10570 [00:03<00:24, 371.76it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 1353/10570 [00:03<00:24, 375.18it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 1391/10570 [00:03<00:24, 370.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1429/10570 [00:03<00:25, 365.45it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1467/10570 [00:04<00:24, 368.74it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1506/10570 [00:04<00:24, 374.57it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1545/10570 [00:04<00:23, 376.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1583/10570 [00:04<00:24, 373.76it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1622/10570 [00:04<00:23, 375.37it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 1662/10570 [00:04<00:23, 381.96it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 1702/10570 [00:04<00:22, 386.53it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 1741/10570 [00:04<00:23, 382.61it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 1781/10570 [00:04<00:22, 385.32it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 1820/10570 [00:04<00:22, 386.09it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1859/10570 [00:05<00:22, 382.71it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1900/10570 [00:05<00:22, 390.27it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1940/10570 [00:05<00:22, 389.12it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 1980/10570 [00:05<00:21, 391.77it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 2020/10570 [00:05<00:22, 386.05it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 2060/10570 [00:05<00:21, 388.46it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 2100/10570 [00:05<00:21, 391.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 2140/10570 [00:05<00:23, 354.73it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 2177/10570 [00:05<00:23, 355.43it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 2217/10570 [00:06<00:22, 366.40it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 21%|âââ       | 2255/10570 [00:06<00:22, 368.79it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2293/10570 [00:06<00:22, 371.62it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2331/10570 [00:06<00:22, 367.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2368/10570 [00:06<00:22, 367.72it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2405/10570 [00:06<00:22, 360.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2442/10570 [00:06<00:22, 362.60it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2479/10570 [00:06<00:22, 359.75it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2516/10570 [00:06<00:23, 339.58it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2551/10570 [00:07<00:23, 336.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2586/10570 [00:07<00:23, 338.25it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 2625/10570 [00:07<00:22, 350.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 2664/10570 [00:07<00:21, 359.67it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2701/10570 [00:07<00:22, 357.41it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2741/10570 [00:07<00:21, 367.84it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2782/10570 [00:07<00:20, 379.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 2821/10570 [00:07<00:20, 381.18it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 2860/10570 [00:07<00:21, 366.60it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 2897/10570 [00:07<00:21, 362.97it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 2935/10570 [00:08<00:20, 366.35it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 2972/10570 [00:08<00:20, 366.68it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 3009/10570 [00:08<00:20, 367.48it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 3046/10570 [00:08<00:20, 364.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 3083/10570 [00:08<00:20, 363.79it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3120/10570 [00:08<00:20, 365.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3157/10570 [00:08<00:20, 362.22it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3194/10570 [00:08<00:20, 359.64it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 3230/10570 [00:08<00:20, 356.72it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 3266/10570 [00:08<00:20, 357.54it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 3303/10570 [00:09<00:20, 359.45it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3341/10570 [00:09<00:19, 364.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3378/10570 [00:09<00:19, 364.68it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3415/10570 [00:09<00:19, 359.87it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3453/10570 [00:09<00:19, 363.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3490/10570 [00:09<00:19, 359.35it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3528/10570 [00:09<00:19, 363.30it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3565/10570 [00:09<00:19, 362.25it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3602/10570 [00:09<00:19, 358.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3640/10570 [00:09<00:19, 362.07it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3677/10570 [00:10<00:18, 364.05it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3714/10570 [00:10<00:18, 362.79it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3751/10570 [00:10<00:18, 361.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 3788/10570 [00:10<00:18, 362.61it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 3825/10570 [00:10<00:18, 358.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3863/10570 [00:10<00:18, 362.60it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3900/10570 [00:10<00:18, 361.19it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3937/10570 [00:10<00:18, 361.72it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 3974/10570 [00:10<00:18, 363.05it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 4011/10570 [00:11<00:18, 362.08it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 4048/10570 [00:11<00:17, 363.79it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4087/10570 [00:11<00:17, 369.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4124/10570 [00:11<00:18, 351.62it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4160/10570 [00:11<00:22, 284.67it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4191/10570 [00:11<00:24, 258.37it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4219/10570 [00:11<00:25, 251.31it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4253/10570 [00:11<00:23, 272.60it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4282/10570 [00:12<00:30, 205.66it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4307/10570 [00:12<00:32, 191.13it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4343/10570 [00:12<00:28, 221.75it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 4378/10570 [00:12<00:24, 248.81it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4414/10570 [00:12<00:22, 273.48it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4452/10570 [00:12<00:20, 296.85it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4491/10570 [00:12<00:19, 317.70it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4526/10570 [00:12<00:19, 307.65it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4561/10570 [00:12<00:18, 318.29it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4595/10570 [00:13<00:18, 322.88it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4629/10570 [00:13<00:18, 318.55it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4662/10570 [00:13<00:19, 309.70it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4697/10570 [00:13<00:18, 319.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4735/10570 [00:13<00:17, 333.06it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4769/10570 [00:13<00:18, 317.26it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4804/10570 [00:13<00:17, 325.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4842/10570 [00:13<00:16, 339.55it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4877/10570 [00:13<00:17, 318.09it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4914/10570 [00:14<00:17, 329.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 4950/10570 [00:14<00:16, 337.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 4986/10570 [00:14<00:16, 342.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5021/10570 [00:14<00:16, 336.25it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5056/10570 [00:14<00:16, 337.97it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5091/10570 [00:14<00:16, 339.48it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5128/10570 [00:14<00:15, 347.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5164/10570 [00:14<00:15, 350.73it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5200/10570 [00:14<00:15, 352.38it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5236/10570 [00:14<00:15, 353.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5272/10570 [00:15<00:14, 353.61it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5310/10570 [00:15<00:14, 359.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 5347/10570 [00:15<00:14, 358.40it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 5384/10570 [00:15<00:14, 359.92it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 5421/10570 [00:15<00:14, 355.44it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5457/10570 [00:15<00:15, 334.30it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5491/10570 [00:15<00:15, 318.79it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5525/10570 [00:15<00:15, 322.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5560/10570 [00:15<00:15, 327.94it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5596/10570 [00:16<00:14, 335.91it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5630/10570 [00:16<00:14, 333.49it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5664/10570 [00:16<00:15, 321.26it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5701/10570 [00:16<00:14, 332.68it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5736/10570 [00:16<00:14, 334.83it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5770/10570 [00:16<00:14, 336.02it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5805/10570 [00:16<00:14, 338.54it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5841/10570 [00:16<00:13, 343.36it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5876/10570 [00:16<00:13, 344.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5912/10570 [00:16<00:13, 346.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5948/10570 [00:17<00:13, 348.78it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 5985/10570 [00:17<00:12, 353.44it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 6021/10570 [00:17<00:12, 350.47it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 6057/10570 [00:17<00:13, 343.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6092/10570 [00:17<00:13, 338.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6128/10570 [00:17<00:12, 344.33it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6164/10570 [00:17<00:12, 348.15it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6199/10570 [00:17<00:12, 348.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6234/10570 [00:17<00:13, 326.49it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6268/10570 [00:18<00:13, 328.78it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6305/10570 [00:18<00:12, 340.01it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6341/10570 [00:18<00:12, 342.93it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6376/10570 [00:18<00:12, 335.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 6411/10570 [00:18<00:12, 337.71it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 6448/10570 [00:18<00:11, 344.67it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 6484/10570 [00:18<00:11, 349.11it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6520/10570 [00:18<00:11, 348.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6556/10570 [00:18<00:11, 351.65it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6592/10570 [00:18<00:11, 347.77it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6629/10570 [00:19<00:11, 352.87it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6666/10570 [00:19<00:11, 354.81it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6702/10570 [00:19<00:11, 349.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6737/10570 [00:19<00:11, 347.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6775/10570 [00:19<00:10, 354.22it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6811/10570 [00:19<00:10, 344.41it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6846/10570 [00:19<00:11, 335.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6880/10570 [00:19<00:10, 336.62it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6915/10570 [00:19<00:10, 339.15it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 6953/10570 [00:19<00:10, 348.79it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 6991/10570 [00:20<00:10, 356.17it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 7029/10570 [00:20<00:09, 361.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 7066/10570 [00:20<00:09, 359.61it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 7103/10570 [00:20<00:09, 359.96it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7140/10570 [00:20<00:09, 358.39it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7177/10570 [00:20<00:09, 359.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7214/10570 [00:20<00:09, 356.55it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7250/10570 [00:20<00:09, 353.14it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7286/10570 [00:20<00:09, 351.19it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7322/10570 [00:21<00:09, 353.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7358/10570 [00:21<00:09, 322.45it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7393/10570 [00:21<00:09, 327.84it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7430/10570 [00:21<00:09, 336.85it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 7465/10570 [00:21<00:09, 337.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 7501/10570 [00:21<00:08, 342.14it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 71%|ââââââââ  | 7538/10570 [00:21<00:08, 348.30it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7575/10570 [00:21<00:08, 352.60it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7612/10570 [00:21<00:08, 356.18it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7648/10570 [00:21<00:08, 357.25it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7684/10570 [00:22<00:08, 344.53it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7720/10570 [00:22<00:08, 346.75it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7755/10570 [00:22<00:08, 335.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7789/10570 [00:22<00:08, 333.93it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7823/10570 [00:22<00:08, 335.70it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7857/10570 [00:22<00:08, 336.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7893/10570 [00:22<00:07, 342.52it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7930/10570 [00:22<00:07, 350.32it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7966/10570 [00:22<00:07, 352.30it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 8002/10570 [00:23<00:07, 342.57it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 8038/10570 [00:23<00:07, 346.29it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 8073/10570 [00:23<00:07, 343.88it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8110/10570 [00:23<00:07, 349.65it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8146/10570 [00:23<00:07, 344.91it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8181/10570 [00:23<00:07, 337.02it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8215/10570 [00:23<00:07, 333.08it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8249/10570 [00:23<00:06, 333.83it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8283/10570 [00:23<00:07, 314.47it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8319/10570 [00:23<00:06, 325.37it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8354/10570 [00:24<00:06, 331.46it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8390/10570 [00:24<00:06, 338.95it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8427/10570 [00:24<00:06, 346.01it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8465/10570 [00:24<00:05, 354.39it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8501/10570 [00:24<00:05, 354.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 8537/10570 [00:24<00:05, 352.44it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 8573/10570 [00:24<00:05, 351.19it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 81%|âââââââââ | 8610/10570 [00:24<00:05, 355.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8646/10570 [00:24<00:05, 356.50it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8682/10570 [00:24<00:05, 353.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8718/10570 [00:25<00:05, 346.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8753/10570 [00:25<00:05, 324.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8786/10570 [00:25<00:05, 325.58it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8821/10570 [00:25<00:05, 331.94it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8857/10570 [00:25<00:05, 338.87it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8892/10570 [00:25<00:04, 338.78it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8928/10570 [00:25<00:04, 343.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 8964/10570 [00:25<00:04, 346.71it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 9001/10570 [00:25<00:04, 353.04it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 9037/10570 [00:26<00:04, 350.96it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 9073/10570 [00:26<00:04, 352.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 9109/10570 [00:26<00:04, 352.74it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9145/10570 [00:26<00:04, 351.03it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9181/10570 [00:26<00:03, 348.86it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9217/10570 [00:26<00:03, 349.37it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9253/10570 [00:26<00:03, 352.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9289/10570 [00:26<00:03, 353.78it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9325/10570 [00:26<00:03, 351.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9361/10570 [00:26<00:03, 351.14it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9397/10570 [00:27<00:03, 351.44it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9433/10570 [00:27<00:03, 353.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9471/10570 [00:27<00:03, 358.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9507/10570 [00:27<00:02, 356.11it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9545/10570 [00:27<00:02, 361.03it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 9582/10570 [00:27<00:02, 361.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 9619/10570 [00:27<00:02, 359.59it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 9656/10570 [00:27<00:02, 360.39it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9694/10570 [00:27<00:02, 365.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9732/10570 [00:27<00:02, 368.75it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9769/10570 [00:28<00:02, 360.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9806/10570 [00:28<00:02, 358.32it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9842/10570 [00:28<00:02, 350.46it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9879/10570 [00:28<00:01, 354.59it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9915/10570 [00:28<00:01, 353.51it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9951/10570 [00:28<00:01, 351.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9987/10570 [00:28<00:01, 346.21it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 10024/10570 [00:28<00:01, 352.54it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 10061/10570 [00:28<00:01, 356.18it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10097/10570 [00:29<00:01, 354.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10134/10570 [00:29<00:01, 357.74it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10170/10570 [00:29<00:01, 346.75it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10207/10570 [00:29<00:01, 350.93it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10244/10570 [00:29<00:00, 355.33it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10280/10570 [00:29<00:00, 353.85it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10316/10570 [00:29<00:00, 352.36it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10352/10570 [00:29<00:00, 353.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10388/10570 [00:29<00:00, 350.75it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10424/10570 [00:29<00:00, 350.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10460/10570 [00:30<00:00, 346.79it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10495/10570 [00:30<00:00, 345.37it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 10533/10570 [00:30<00:00, 352.24it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 10570/10570 [00:30<00:00, 356.63it/s]#033[A#033[A#015100%|ââââââââââ| 10570/10570 [00:30<00:00, 348.12it/s]\u001b[0m\n",
      "\u001b[34m01/14/2021 15:59:07 - INFO - nn_pruning.examples.question_answering.qa_utils -   Saving predictions to /opt/ml/model/checkpoint-250/predictions.json.\u001b[0m\n",
      "\u001b[34m01/14/2021 15:59:07 - INFO - nn_pruning.examples.question_answering.qa_utils -   Saving nbest_preds to /opt/ml/model/checkpoint-250/nbest_predictions.json.\u001b[0m\n",
      "\u001b[34m01/14/2021 15:59:13 - INFO - /opt/conda/lib/python3.6/site-packages/datasets/metric.py -   Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m#015                                                 #015\u001b[0m\n",
      "\u001b[34m#015                                                   #015#033[A#015 45%|âââââ     | 250/554 [06:08<03:02,  1.67it/s]\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1348/1348 [03:37<00:00,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                                   #033[A01/14/2021 15:59:13 - INFO - nn_pruning.examples.question_answering.qa_train -   ***** Eval results *****\u001b[0m\n",
      "\u001b[34m01/14/2021 15:59:13 - INFO - nn_pruning.examples.question_answering.qa_train -     exact_match = 1.315042573320719\u001b[0m\n",
      "\u001b[34m01/14/2021 15:59:13 - INFO - nn_pruning.examples.question_answering.qa_train -     f1 = 9.593677739438615\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 251/554 [06:09<5:32:53, 65.92s/it]#015 45%|âââââ     | 252/554 [06:10<3:53:09, 46.32s/it]#015 46%|âââââ     | 253/554 [06:10<2:43:34, 32.61s/it]#015 46%|âââââ     | 254/554 [06:11<1:55:01, 23.00s/it]#015 46%|âââââ     | 255/554 [06:11<1:21:08, 16.28s/it]#015 46%|âââââ     | 256/554 [06:12<57:29, 11.58s/it]  #015 46%|âââââ     | 257/554 [06:13<40:59,  8.28s/it]#015 47%|âââââ     | 258/554 [06:13<29:29,  5.98s/it]#015 47%|âââââ     | 259/554 [06:14<21:27,  4.36s/it]#015 47%|âââââ     | 260/554 [06:14<15:50,  3.23s/it]#015 47%|âââââ     | 261/554 [06:15<11:55,  2.44s/it]#015 47%|âââââ     | 262/554 [06:16<09:11,  1.89s/it]#015 47%|âââââ     | 263/554 [06:16<07:16,  1.50s/it]#015 48%|âââââ     | 264/554 [06:17<05:56,  1.23s/it]#015 48%|âââââ     | 265/554 [06:17<05:00,  1.04s/it]#015 48%|âââââ     | 266/554 [06:18<04:20,  1.10it/s]#015 48%|âââââ     | 267/554 [06:19<03:53,  1.23it/s]#015 48%|âââââ     | 268/554 [06:19<03:34,  1.34it/s]#015 49%|âââââ     | 269/554 [06:20<03:20,  1.42it/s]#015 49%|âââââ     | 270/554 [06:20<03:10,  1.49it/s]#015 49%|âââââ     | 271/554 [06:21<03:03,  1.54it/s]#015 49%|âââââ     | 272/554 [06:22<02:58,  1.58it/s]#015 49%|âââââ     | 273/554 [06:22<02:54,  1.61it/s]#015 49%|âââââ     | 274/554 [06:23<02:52,  1.63it/s]#015 50%|âââââ     | 275/554 [06:23<02:50,  1.64it/s]#015 50%|âââââ     | 276/554 [06:24<02:48,  1.65it/s]#015 50%|âââââ     | 277/554 [06:25<02:47,  1.65it/s]#015 50%|âââââ     | 278/554 [06:25<02:46,  1.66it/s]#015 50%|âââââ     | 279/554 [06:26<02:45,  1.66it/s]#015 51%|âââââ     | 280/554 [06:26<02:44,  1.67it/s]#015 51%|âââââ     | 281/554 [06:27<02:43,  1.67it/s]#015 51%|âââââ     | 282/554 [06:28<02:42,  1.67it/s]#015 51%|âââââ     | 283/554 [06:28<02:42,  1.67it/s]#015 51%|ââââââ    | 284/554 [06:29<02:41,  1.67it/s]#015 51%|ââââââ    | 285/554 [06:29<02:40,  1.67it/s]#015 52%|ââââââ    | 286/554 [06:30<02:40,  1.67it/s]#015 52%|ââââââ    | 287/554 [06:31<02:40,  1.66it/s]#015 52%|ââââââ    | 288/554 [06:31<02:39,  1.67it/s]#015 52%|ââââââ    | 289/554 [06:32<02:38,  1.67it/s]#015 52%|ââââââ    | 290/554 [06:32<02:38,  1.67it/s]#015 53%|ââââââ    | 291/554 [06:33<02:37,  1.67it/s]#015 53%|ââââââ    | 292/554 [06:34<02:36,  1.67it/s]#015 53%|ââââââ    | 293/554 [06:34<02:35,  1.67it/s]#015 53%|ââââââ    | 294/554 [06:35<02:35,  1.67it/s]#015 53%|ââââââ    | 295/554 [06:35<02:34,  1.67it/s]#015 53%|ââââââ    | 296/554 [06:36<02:34,  1.67it/s]#015 54%|ââââââ    | 297/554 [06:37<02:33,  1.67it/s]#015 54%|ââââââ    | 298/554 [06:37<02:32,  1.67it/s]#015 54%|ââââââ    | 299/554 [06:38<02:32,  1.67it/s]#015 54%|ââââââ    | 300/554 [06:38<02:31,  1.67it/s]#015                                                 #015#015 54%|ââââââ    | 300/554 [06:38<02:31,  1.67it/s]#015 54%|ââââââ    | 301/554 [06:39<02:31,  1.67it/s]#015 55%|ââââââ    | 302/554 [06:40<02:30,  1.67it/s]#015 55%|ââââââ    | 303/554 [06:40<02:30,  1.66it/s]#015 55%|ââââââ    | 304/554 [06:41<02:29,  1.67it/s]#015 55%|ââââââ    | 305/554 [06:41<02:29,  1.67it/s]#015 55%|ââââââ    | 306/554 [06:42<02:28,  1.67it/s]#015 55%|ââââââ    | 307/554 [06:43<02:28,  1.67it/s]#015 56%|ââââââ    | 308/554 [06:43<02:27,  1.67it/s]#015 56%|ââââââ    | 309/554 [06:44<02:26,  1.67it/s]#015 56%|ââââââ    | 310/554 [06:44<02:25,  1.67it/s]#015 56%|ââââââ    | 311/554 [06:45<02:25,  1.67it/s]#015 56%|ââââââ    | 312/554 [06:46<02:24,  1.67it/s]#015 56%|ââââââ    | 313/554 [06:46<02:24,  1.67it/s]#015 57%|ââââââ    | 314/554 [06:47<02:23,  1.67it/s]#015 57%|ââââââ    | 315/554 [06:47<02:22,  1.67it/s]#015 57%|ââââââ    | 316/554 [06:48<02:22,  1.67it/s]#015 57%|ââââââ    | 317/554 [06:49<02:21,  1.67it/s]#015 57%|ââââââ    | 318/554 [06:49<02:21,  1.67it/s]#015 58%|ââââââ    | 319/554 [06:50<02:20,  1.67it/s]#015 58%|ââââââ    | 320/554 [06:50<02:19,  1.67it/s]#015 58%|ââââââ    | 321/554 [06:51<02:19,  1.67it/s]#015 58%|ââââââ    | 322/554 [06:52<02:18,  1.67it/s]#015 58%|ââââââ    | 323/554 [06:52<02:18,  1.67it/s]#015 58%|ââââââ    | 324/554 [06:53<02:17,  1.67it/s]#015 59%|ââââââ    | 325/554 [06:53<02:17,  1.67it/s]#015 59%|ââââââ    | 326/554 [06:54<02:16,  1.67it/s]#015 59%|ââââââ    | 327/554 [06:55<02:16,  1.67it/s]#015 59%|ââââââ    | 328/554 [06:55<02:15,  1.66it/s]#015 59%|ââââââ    | 329/554 [06:56<02:15,  1.66it/s]#015 60%|ââââââ    | 330/554 [06:56<02:14,  1.66it/s]#015 60%|ââââââ    | 331/554 [06:57<02:14,  1.66it/s]#015 60%|ââââââ    | 332/554 [06:58<02:14,  1.65it/s]#015 60%|ââââââ    | 333/554 [06:58<02:13,  1.66it/s]#015 60%|ââââââ    | 334/554 [06:59<02:12,  1.66it/s]#015 60%|ââââââ    | 335/554 [06:59<02:11,  1.66it/s]#015 61%|ââââââ    | 336/554 [07:00<02:10,  1.67it/s]#015 61%|ââââââ    | 337/554 [07:01<02:10,  1.67it/s]#015 61%|ââââââ    | 338/554 [07:01<02:09,  1.67it/s]#015 61%|ââââââ    | 339/554 [07:02<02:08,  1.67it/s]#015 61%|âââââââ   | 340/554 [07:02<02:08,  1.67it/s]#015 62%|âââââââ   | 341/554 [07:03<02:07,  1.67it/s]#015 62%|âââââââ   | 342/554 [07:04<02:06,  1.67it/s]#015 62%|âââââââ   | 343/554 [07:04<02:06,  1.67it/s]#015 62%|âââââââ   | 344/554 [07:05<02:05,  1.67it/s]#015 62%|âââââââ   | 345/554 [07:05<02:05,  1.67it/s]#015 62%|âââââââ   | 346/554 [07:06<02:05,  1.66it/s]#015 63%|âââââââ   | 347/554 [07:07<02:04,  1.66it/s]#015 63%|âââââââ   | 348/554 [07:07<02:03,  1.66it/s]#015 63%|âââââââ   | 349/554 [07:08<02:03,  1.67it/s]#015 63%|âââââââ   | 350/554 [07:08<02:02,  1.66it/s]#015 63%|âââââââ   | 351/554 [07:09<02:01,  1.67it/s]#015 64%|âââââââ   | 352/554 [07:10<02:01,  1.67it/s]#015 64%|âââââââ   | 353/554 [07:10<02:00,  1.67it/s]#015 64%|âââââââ   | 354/554 [07:11<01:59,  1.67it/s]#015 64%|âââââââ   | 355/554 [07:11<01:59,  1.67it/s]#015 64%|âââââââ   | 356/554 [07:12<01:58,  1.67it/s]#015 64%|âââââââ   | 357/554 [07:13<01:58,  1.67it/s]#015 65%|âââââââ   | 358/554 [07:13<01:57,  1.67it/s]#015 65%|âââââââ   | 359/554 [07:14<01:56,  1.67it/s]#015 65%|âââââââ   | 360/554 [07:14<01:56,  1.67it/s]#015 65%|âââââââ   | 361/554 [07:15<01:55,  1.67it/s]#015 65%|âââââââ   | 362/554 [07:16<01:54,  1.67it/s]#015 66%|âââââââ   | 363/554 [07:16<01:54,  1.67it/s]#015 66%|âââââââ   | 364/554 [07:17<01:53,  1.67it/s]#015 66%|âââââââ   | 365/554 [07:17<01:52,  1.67it/s]#015 66%|âââââââ   | 366/554 [07:18<01:52,  1.67it/s]#015 66%|âââââââ   | 367/554 [07:18<01:51,  1.67it/s]#015 66%|âââââââ   | 368/554 [07:19<01:51,  1.67it/s]#015 67%|âââââââ   | 369/554 [07:20<01:50,  1.67it/s]#015 67%|âââââââ   | 370/554 [07:20<01:50,  1.67it/s]#015 67%|âââââââ   | 371/554 [07:21<01:49,  1.67it/s]#015 67%|âââââââ   | 372/554 [07:21<01:48,  1.67it/s]#015 67%|âââââââ   | 373/554 [07:22<01:48,  1.67it/s]#015 68%|âââââââ   | 374/554 [07:23<01:47,  1.67it/s]#015 68%|âââââââ   | 375/554 [07:23<01:46,  1.67it/s]#015 68%|âââââââ   | 376/554 [07:24<01:46,  1.67it/s]#015 68%|âââââââ   | 377/554 [07:24<01:46,  1.67it/s]#015 68%|âââââââ   | 378/554 [07:25<01:45,  1.66it/s]#015 68%|âââââââ   | 379/554 [07:26<01:45,  1.67it/s]#015 69%|âââââââ   | 380/554 [07:26<01:44,  1.66it/s]#015 69%|âââââââ   | 381/554 [07:27<01:44,  1.66it/s]#015 69%|âââââââ   | 382/554 [07:27<01:43,  1.66it/s]#015 69%|âââââââ   | 383/554 [07:28<01:42,  1.67it/s]#015 69%|âââââââ   | 384/554 [07:29<01:42,  1.66it/s]#015 69%|âââââââ   | 385/554 [07:29<01:41,  1.67it/s]#015 70%|âââââââ   | 386/554 [07:30<01:40,  1.67it/s]#015 70%|âââââââ   | 387/554 [07:30<01:39,  1.67it/s]#015 70%|âââââââ   | 388/554 [07:31<01:39,  1.67it/s]#015 70%|âââââââ   | 389/554 [07:32<01:38,  1.67it/s]#015 70%|âââââââ   | 390/554 [07:32<01:37,  1.67it/s]#015 71%|âââââââ   | 391/554 [07:33<01:37,  1.67it/s]#015 71%|âââââââ   | 392/554 [07:33<01:36,  1.67it/s]#015 71%|âââââââ   | 393/554 [07:34<01:36,  1.67it/s]#015 71%|âââââââ   | 394/554 [07:35<01:35,  1.67it/s]#015 71%|ââââââââ  | 395/554 [07:35<01:34,  1.67it/s]#015 71%|ââââââââ  | 396/554 [07:36<01:34,  1.67it/s]#015 72%|ââââââââ  | 397/554 [07:36<01:33,  1.67it/s]#015 72%|ââââââââ  | 398/554 [07:37<01:33,  1.67it/s]#015 72%|ââââââââ  | 399/554 [07:38<01:32,  1.67it/s]#015 72%|ââââââââ  | 400/554 [07:38<01:32,  1.67it/s]#015                                                 #015#015 72%|ââââââââ  | 400/554 [07:38<01:32,  1.67it/s]#015 72%|ââââââââ  | 401/554 [07:39<01:31,  1.67it/s]#015 73%|ââââââââ  | 402/554 [07:39<01:30,  1.67it/s]#015 73%|ââââââââ  | 403/554 [07:40<01:30,  1.67it/s]#015 73%|ââââââââ  | 404/554 [07:41<01:29,  1.67it/s]#015 73%|ââââââââ  | 405/554 [07:41<01:29,  1.67it/s]#015 73%|ââââââââ  | 406/554 [07:42<01:28,  1.67it/s]#015 73%|ââââââââ  | 407/554 [07:42<01:28,  1.67it/s]#015 74%|ââââââââ  | 408/554 [07:43<01:27,  1.66it/s]#015 74%|ââââââââ  | 409/554 [07:44<01:26,  1.67it/s]#015 74%|ââââââââ  | 410/554 [07:44<01:26,  1.67it/s]#015 74%|ââââââââ  | 411/554 [07:45<01:25,  1.67it/s]#015 74%|ââââââââ  | 412/554 [07:45<01:24,  1.67it/s]#015 75%|ââââââââ  | 413/554 [07:46<01:24,  1.67it/s]#015 75%|ââââââââ  | 414/554 [07:47<01:23,  1.67it/s]#015 75%|ââââââââ  | 415/554 [07:47<01:23,  1.67it/s]#015 75%|ââââââââ  | 416/554 [07:48<01:22,  1.67it/s]#015 75%|ââââââââ  | 417/554 [07:48<01:21,  1.67it/s]#015 75%|ââââââââ  | 418/554 [07:49<01:21,  1.67it/s]#015 76%|ââââââââ  | 419/554 [07:50<01:20,  1.67it/s]#015 76%|ââââââââ  | 420/554 [07:50<01:20,  1.67it/s]#015 76%|ââââââââ  | 421/554 [07:51<01:19,  1.67it/s]#015 76%|ââââââââ  | 422/554 [07:51<01:18,  1.67it/s]#015 76%|ââââââââ  | 423/554 [07:52<01:18,  1.67it/s]#015 77%|ââââââââ  | 424/554 [07:53<01:17,  1.67it/s]#015 77%|ââââââââ  | 425/554 [07:53<01:17,  1.67it/s]#015 77%|ââââââââ  | 426/554 [07:54<01:16,  1.67it/s]#015 77%|ââââââââ  | 427/554 [07:54<01:16,  1.67it/s]#015 77%|ââââââââ  | 428/554 [07:55<01:15,  1.67it/s]#015 77%|ââââââââ  | 429/554 [07:56<01:14,  1.67it/s]#015 78%|ââââââââ  | 430/554 [07:56<01:14,  1.66it/s]#015 78%|ââââââââ  | 431/554 [07:57<01:14,  1.66it/s]#015 78%|ââââââââ  | 432/554 [07:57<01:13,  1.66it/s]#015 78%|ââââââââ  | 433/554 [07:58<01:12,  1.66it/s]#015 78%|ââââââââ  | 434/554 [07:59<01:11,  1.67it/s]#015 79%|ââââââââ  | 435/554 [07:59<01:11,  1.66it/s]#015 79%|ââââââââ  | 436/554 [08:00<01:10,  1.66it/s]#015 79%|ââââââââ  | 437/554 [08:00<01:10,  1.67it/s]#015 79%|ââââââââ  | 438/554 [08:01<01:09,  1.67it/s]#015 79%|ââââââââ  | 439/554 [08:02<01:08,  1.67it/s]#015 79%|ââââââââ  | 440/554 [08:02<01:08,  1.67it/s]#015 80%|ââââââââ  | 441/554 [08:03<01:07,  1.67it/s]#015 80%|ââââââââ  | 442/554 [08:03<01:07,  1.67it/s]#015 80%|ââââââââ  | 443/554 [08:04<01:06,  1.67it/s]#015 80%|ââââââââ  | 444/554 [08:05<01:05,  1.67it/s]#015 80%|ââââââââ  | 445/554 [08:05<01:05,  1.67it/s]#015 81%|ââââââââ  | 446/554 [08:06<01:04,  1.67it/s]#015 81%|ââââââââ  | 447/554 [08:06<01:04,  1.67it/s]#015 81%|ââââââââ  | 448/554 [08:07<01:03,  1.67it/s]#015 81%|ââââââââ  | 449/554 [08:08<01:02,  1.67it/s]#015 81%|ââââââââ  | 450/554 [08:08<01:02,  1.67it/s]#015 81%|âââââââââ | 451/554 [08:09<01:01,  1.67it/s]#015 82%|âââââââââ | 452/554 [08:09<01:01,  1.67it/s]#015 82%|âââââââââ | 453/554 [08:10<01:00,  1.67it/s]#015 82%|âââââââââ | 454/554 [08:11<00:59,  1.67it/s]#015 82%|âââââââââ | 455/554 [08:11<00:59,  1.67it/s]#015 82%|âââââââââ | 456/554 [08:12<00:58,  1.67it/s]#015 82%|âââââââââ | 457/554 [08:12<00:58,  1.67it/s]#015 83%|âââââââââ | 458/554 [08:13<00:57,  1.67it/s]#015 83%|âââââââââ | 459/554 [08:14<00:57,  1.67it/s]#015 83%|âââââââââ | 460/554 [08:14<00:56,  1.66it/s]#015 83%|âââââââââ | 461/554 [08:15<00:55,  1.66it/s]#015 83%|âââââââââ | 462/554 [08:15<00:55,  1.66it/s]#015 84%|âââââââââ | 463/554 [08:16<00:54,  1.66it/s]#015 84%|âââââââââ | 464/554 [08:17<00:54,  1.66it/s]#015 84%|âââââââââ | 465/554 [08:17<00:53,  1.66it/s]#015 84%|âââââââââ | 466/554 [08:18<00:52,  1.66it/s]#015 84%|âââââââââ | 467/554 [08:18<00:52,  1.66it/s]#015 84%|âââââââââ | 468/554 [08:19<00:51,  1.66it/s]#015 85%|âââââââââ | 469/554 [08:20<00:51,  1.66it/s]#015 85%|âââââââââ | 470/554 [08:20<00:50,  1.66it/s]#015 85%|âââââââââ | 471/554 [08:21<00:49,  1.66it/s]#015 85%|âââââââââ | 472/554 [08:21<00:49,  1.66it/s]#015 85%|âââââââââ | 473/554 [08:22<00:48,  1.66it/s]#015 86%|âââââââââ | 474/554 [08:23<00:48,  1.66it/s]#015 86%|âââââââââ | 475/554 [08:23<00:47,  1.66it/s]#015 86%|âââââââââ | 476/554 [08:24<00:46,  1.66it/s]#015 86%|âââââââââ | 477/554 [08:24<00:46,  1.66it/s]#015 86%|âââââââââ | 478/554 [08:25<00:45,  1.66it/s]#015 86%|âââââââââ | 479/554 [08:26<00:45,  1.66it/s]#015 87%|âââââââââ | 480/554 [08:26<00:44,  1.66it/s]#015 87%|âââââââââ | 481/554 [08:27<00:43,  1.66it/s]#015 87%|âââââââââ | 482/554 [08:27<00:43,  1.66it/s]#015 87%|âââââââââ | 483/554 [08:28<00:42,  1.66it/s]#015 87%|âââââââââ | 484/554 [08:29<00:42,  1.66it/s]#015 88%|âââââââââ | 485/554 [08:29<00:41,  1.65it/s]#015 88%|âââââââââ | 486/554 [08:30<00:41,  1.66it/s]#015 88%|âââââââââ | 487/554 [08:30<00:40,  1.66it/s]#015 88%|âââââââââ | 488/554 [08:31<00:39,  1.66it/s]#015 88%|âââââââââ | 489/554 [08:32<00:39,  1.65it/s]#015 88%|âââââââââ | 490/554 [08:32<00:38,  1.65it/s]#015 89%|âââââââââ | 491/554 [08:33<00:37,  1.66it/s]#015 89%|âââââââââ | 492/554 [08:34<00:37,  1.66it/s]#015 89%|âââââââââ | 493/554 [08:34<00:36,  1.66it/s]#015 89%|âââââââââ | 494/554 [08:35<00:36,  1.66it/s]#015 89%|âââââââââ | 495/554 [08:35<00:35,  1.67it/s]#015 90%|âââââââââ | 496/554 [08:36<00:34,  1.66it/s]#015 90%|âââââââââ | 497/554 [08:37<00:34,  1.66it/s]#015 90%|âââââââââ | 498/554 [08:37<00:33,  1.66it/s]#015 90%|âââââââââ | 499/554 [08:38<00:33,  1.66it/s]#015 90%|âââââââââ | 500/554 [08:38<00:32,  1.66it/s]#015                                                 #015#015 90%|âââââï¿½\u001b[0m\n",
      "\u001b[34mï¿½âââ | 500/554 [08:38<00:32,  1.66it/s][INFO|trainer.py:388] 2021-01-14 16:01:43,370 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1412] 2021-01-14 16:01:43,370 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1413] 2021-01-14 16:01:43,370 >>   Num examples = 10784\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1414] 2021-01-14 16:01:43,370 >>   Batch size = 8\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1348 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 2/1348 [00:00<01:24, 15.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 3/1348 [00:00<01:50, 12.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 4/1348 [00:00<02:08, 10.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 5/1348 [00:00<02:20,  9.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 6/1348 [00:00<02:28,  9.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 7/1348 [00:00<02:34,  8.68it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 8/1348 [00:00<02:38,  8.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 9/1348 [00:01<02:41,  8.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 10/1348 [00:01<02:43,  8.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 11/1348 [00:01<02:44,  8.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 12/1348 [00:01<02:44,  8.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 13/1348 [00:01<02:45,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 14/1348 [00:01<02:45,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 15/1348 [00:01<02:45,  8.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 16/1348 [00:01<02:45,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 17/1348 [00:02<02:45,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 18/1348 [00:02<02:46,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 19/1348 [00:02<02:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 20/1348 [00:02<02:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 21/1348 [00:02<02:45,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 22/1348 [00:02<02:45,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 23/1348 [00:02<02:46,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 24/1348 [00:02<02:47,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 25/1348 [00:03<02:47,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 26/1348 [00:03<02:47,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 27/1348 [00:03<02:48,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 28/1348 [00:03<02:48,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 29/1348 [00:03<02:49,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 30/1348 [00:03<02:49,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 31/1348 [00:03<02:48,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 32/1348 [00:03<02:49,  7.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 33/1348 [00:04<02:49,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 34/1348 [00:04<02:49,  7.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 35/1348 [00:04<02:49,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 36/1348 [00:04<02:49,  7.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 37/1348 [00:04<02:48,  7.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 38/1348 [00:04<02:48,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 39/1348 [00:04<02:47,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 40/1348 [00:04<02:47,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 41/1348 [00:05<02:46,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 42/1348 [00:05<02:45,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 43/1348 [00:05<02:44,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 44/1348 [00:05<02:44,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 45/1348 [00:05<02:43,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 46/1348 [00:05<02:43,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 47/1348 [00:05<02:42,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 48/1348 [00:05<02:43,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 49/1348 [00:06<02:43,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 50/1348 [00:06<02:42,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 51/1348 [00:06<02:42,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 52/1348 [00:06<02:42,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 53/1348 [00:06<02:43,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 54/1348 [00:06<02:43,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 55/1348 [00:06<02:43,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 56/1348 [00:06<02:42,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 57/1348 [00:07<02:42,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 58/1348 [00:07<02:42,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 59/1348 [00:07<02:42,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 60/1348 [00:07<02:42,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 61/1348 [00:07<02:41,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 62/1348 [00:07<02:41,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 63/1348 [00:07<02:42,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 64/1348 [00:07<02:42,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 65/1348 [00:08<02:41,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 66/1348 [00:08<02:41,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 67/1348 [00:08<02:40,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 68/1348 [00:08<02:40,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 69/1348 [00:08<02:40,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 70/1348 [00:08<02:40,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 71/1348 [00:08<02:40,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 72/1348 [00:08<02:41,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 73/1348 [00:09<02:41,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 74/1348 [00:09<02:40,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 75/1348 [00:09<02:40,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 76/1348 [00:09<02:40,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 77/1348 [00:09<02:40,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 78/1348 [00:09<02:40,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 79/1348 [00:09<02:39,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 80/1348 [00:09<02:39,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 81/1348 [00:10<02:39,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 82/1348 [00:10<02:39,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 83/1348 [00:10<02:39,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 84/1348 [00:10<02:39,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 85/1348 [00:10<02:38,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 86/1348 [00:10<02:38,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 87/1348 [00:10<02:37,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 88/1348 [00:10<02:37,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 89/1348 [00:11<02:39,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 90/1348 [00:11<02:39,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 91/1348 [00:11<02:38,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 92/1348 [00:11<02:38,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 93/1348 [00:11<02:38,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 94/1348 [00:11<02:38,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 95/1348 [00:11<02:38,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 96/1348 [00:11<02:38,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 97/1348 [00:12<02:39,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 98/1348 [00:12<02:38,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 99/1348 [00:12<02:38,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 100/1348 [00:12<02:38,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 101/1348 [00:12<02:38,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 102/1348 [00:12<02:38,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 103/1348 [00:12<02:40,  7.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 104/1348 [00:13<02:41,  7.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 105/1348 [00:13<02:40,  7.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 106/1348 [00:13<02:39,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 107/1348 [00:13<02:38,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 108/1348 [00:13<02:38,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 109/1348 [00:13<02:37,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 110/1348 [00:13<02:37,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 111/1348 [00:13<02:36,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 112/1348 [00:14<02:36,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 113/1348 [00:14<02:36,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 114/1348 [00:14<02:35,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 115/1348 [00:14<02:35,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 116/1348 [00:14<02:36,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 117/1348 [00:14<02:36,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 118/1348 [00:14<02:36,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 119/1348 [00:14<02:35,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 120/1348 [00:15<02:36,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 121/1348 [00:15<02:35,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 122/1348 [00:15<02:35,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 123/1348 [00:15<02:35,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 124/1348 [00:15<02:35,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 125/1348 [00:15<02:34,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 126/1348 [00:15<02:34,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 127/1348 [00:15<02:34,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 128/1348 [00:16<02:34,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 129/1348 [00:16<02:34,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 130/1348 [00:16<02:34,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 131/1348 [00:16<02:34,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 132/1348 [00:16<02:34,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 133/1348 [00:16<02:34,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 134/1348 [00:16<02:34,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 135/1348 [00:16<02:33,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 136/1348 [00:17<02:34,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 137/1348 [00:17<02:34,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 138/1348 [00:17<02:33,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 139/1348 [00:17<02:33,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 140/1348 [00:17<02:33,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 141/1348 [00:17<02:32,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 142/1348 [00:17<02:33,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 143/1348 [00:17<02:36,  7.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 144/1348 [00:18<02:35,  7.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 145/1348 [00:18<02:34,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 146/1348 [00:18<02:34,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 147/1348 [00:18<02:33,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 148/1348 [00:18<02:32,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 149/1348 [00:18<02:32,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 150/1348 [00:18<02:31,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 151/1348 [00:18<02:31,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 152/1348 [00:19<02:31,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 153/1348 [00:19<02:39,  7.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 154/1348 [00:19<02:36,  7.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 155/1348 [00:19<02:34,  7.71it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 156/1348 [00:19<02:33,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 157/1348 [00:19<02:31,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 158/1348 [00:19<02:30,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 159/1348 [00:20<02:30,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 160/1348 [00:20<02:31,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 161/1348 [00:20<02:30,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 162/1348 [00:20<02:29,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 163/1348 [00:20<02:29,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 164/1348 [00:20<02:32,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 165/1348 [00:20<02:31,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 166/1348 [00:20<02:30,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 167/1348 [00:21<02:29,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 168/1348 [00:21<02:29,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 169/1348 [00:21<02:29,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 170/1348 [00:21<02:28,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 171/1348 [00:21<02:28,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 172/1348 [00:21<02:28,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 173/1348 [00:21<02:27,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 174/1348 [00:21<02:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 175/1348 [00:22<02:28,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 176/1348 [00:22<02:28,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 177/1348 [00:22<02:28,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 178/1348 [00:22<02:28,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 179/1348 [00:22<02:27,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 180/1348 [00:22<02:26,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 181/1348 [00:22<02:27,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 182/1348 [00:22<02:27,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 183/1348 [00:23<02:27,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 184/1348 [00:23<02:27,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 185/1348 [00:23<02:26,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 186/1348 [00:23<02:26,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 187/1348 [00:23<02:26,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 188/1348 [00:23<02:26,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 189/1348 [00:23<02:26,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 190/1348 [00:23<02:25,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 191/1348 [00:24<02:25,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 192/1348 [00:24<02:26,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 193/1348 [00:24<02:25,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 194/1348 [00:24<02:25,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 195/1348 [00:24<02:24,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 196/1348 [00:24<02:24,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 197/1348 [00:24<02:24,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 198/1348 [00:24<02:24,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 199/1348 [00:25<02:23,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 200/1348 [00:25<02:24,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 201/1348 [00:25<02:24,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 202/1348 [00:25<02:24,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 203/1348 [00:25<02:23,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 204/1348 [00:25<02:23,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 205/1348 [00:25<02:23,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 206/1348 [00:25<02:23,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 207/1348 [00:26<02:23,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 208/1348 [00:26<02:23,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 209/1348 [00:26<02:23,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 210/1348 [00:26<02:22,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 211/1348 [00:26<02:21,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 212/1348 [00:26<02:21,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 213/1348 [00:26<02:21,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 214/1348 [00:26<02:21,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 215/1348 [00:27<02:21,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 216/1348 [00:27<02:22,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 217/1348 [00:27<02:22,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 218/1348 [00:27<02:22,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 219/1348 [00:27<02:21,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 220/1348 [00:27<02:22,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 221/1348 [00:27<02:21,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 222/1348 [00:27<02:24,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 223/1348 [00:28<02:24,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 224/1348 [00:28<02:24,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 225/1348 [00:28<02:22,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 226/1348 [00:28<02:22,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 227/1348 [00:28<02:21,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 228/1348 [00:28<02:21,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 229/1348 [00:28<02:20,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 230/1348 [00:28<02:20,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 231/1348 [00:29<02:20,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 232/1348 [00:29<02:20,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 233/1348 [00:29<02:20,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 234/1348 [00:29<02:20,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 235/1348 [00:29<02:20,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 236/1348 [00:29<02:19,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 237/1348 [00:29<02:19,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 238/1348 [00:29<02:19,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 239/1348 [00:30<02:18,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 240/1348 [00:30<02:18,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 241/1348 [00:30<02:18,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 242/1348 [00:30<02:18,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 243/1348 [00:30<02:18,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 244/1348 [00:30<02:18,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 245/1348 [00:30<02:18,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 246/1348 [00:30<02:18,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 247/1348 [00:31<02:17,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 248/1348 [00:31<02:17,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 249/1348 [00:31<02:18,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 250/1348 [00:31<02:17,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 251/1348 [00:31<02:17,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 252/1348 [00:31<02:17,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 253/1348 [00:31<02:17,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 254/1348 [00:31<02:17,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 255/1348 [00:32<02:17,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 256/1348 [00:32<02:17,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 257/1348 [00:32<02:18,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 258/1348 [00:32<02:17,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 259/1348 [00:32<02:16,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 260/1348 [00:32<02:16,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 261/1348 [00:32<02:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 262/1348 [00:33<02:17,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 263/1348 [00:33<02:21,  7.69it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 264/1348 [00:33<02:19,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 265/1348 [00:33<02:18,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 266/1348 [00:33<02:17,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 267/1348 [00:33<02:16,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 268/1348 [00:33<02:16,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 269/1348 [00:33<02:16,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 270/1348 [00:34<02:17,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 271/1348 [00:34<02:16,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 272/1348 [00:34<02:15,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 273/1348 [00:34<02:16,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 274/1348 [00:34<02:16,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 275/1348 [00:34<02:15,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 276/1348 [00:34<02:15,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 277/1348 [00:34<02:15,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 278/1348 [00:35<02:14,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 279/1348 [00:35<02:14,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 280/1348 [00:35<02:14,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 281/1348 [00:35<02:14,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 282/1348 [00:35<02:14,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 283/1348 [00:35<02:13,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 284/1348 [00:35<02:13,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 285/1348 [00:35<02:13,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 286/1348 [00:36<02:14,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|âââ       | 287/1348 [00:36<02:14,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|âââ       | 288/1348 [00:36<02:13,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|âââ       | 289/1348 [00:36<02:13,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 290/1348 [00:36<02:13,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 291/1348 [00:36<02:13,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 292/1348 [00:36<02:13,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 293/1348 [00:36<02:13,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 294/1348 [00:37<02:13,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 295/1348 [00:37<02:12,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 296/1348 [00:37<02:12,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 297/1348 [00:37<02:13,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 298/1348 [00:37<02:12,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 299/1348 [00:37<02:12,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 300/1348 [00:37<02:12,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 301/1348 [00:37<02:12,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 302/1348 [00:38<02:13,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 303/1348 [00:38<02:13,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 304/1348 [00:38<02:12,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 305/1348 [00:38<02:13,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 306/1348 [00:38<02:12,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 307/1348 [00:38<02:11,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 308/1348 [00:38<02:11,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 309/1348 [00:38<02:11,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 310/1348 [00:39<02:11,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 311/1348 [00:39<02:11,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 312/1348 [00:39<02:11,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 313/1348 [00:39<02:12,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 314/1348 [00:39<02:11,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 315/1348 [00:39<02:10,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 316/1348 [00:39<02:10,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 317/1348 [00:39<02:10,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 318/1348 [00:40<02:10,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 319/1348 [00:40<02:10,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 320/1348 [00:40<02:10,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 321/1348 [00:40<02:10,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 322/1348 [00:40<02:10,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 323/1348 [00:40<02:11,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 324/1348 [00:40<02:10,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 325/1348 [00:40<02:10,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 326/1348 [00:41<02:10,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 327/1348 [00:41<02:09,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 328/1348 [00:41<02:09,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 329/1348 [00:41<02:09,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 330/1348 [00:41<02:08,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 331/1348 [00:41<02:08,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 332/1348 [00:41<02:08,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 333/1348 [00:41<02:07,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 334/1348 [00:42<02:07,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 335/1348 [00:42<02:07,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 336/1348 [00:42<02:06,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 337/1348 [00:42<02:07,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 338/1348 [00:42<02:07,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 339/1348 [00:42<02:07,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 340/1348 [00:42<02:07,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 341/1348 [00:43<02:06,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 342/1348 [00:43<02:07,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 343/1348 [00:43<02:07,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 344/1348 [00:43<02:06,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 345/1348 [00:43<02:07,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 346/1348 [00:43<02:06,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 347/1348 [00:43<02:06,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 348/1348 [00:43<02:05,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 349/1348 [00:44<02:05,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 350/1348 [00:44<02:05,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 351/1348 [00:44<02:04,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 352/1348 [00:44<02:04,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 353/1348 [00:44<02:05,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 354/1348 [00:44<02:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 355/1348 [00:44<02:04,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 356/1348 [00:44<02:04,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 357/1348 [00:45<02:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 358/1348 [00:45<02:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 359/1348 [00:45<02:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 360/1348 [00:45<02:04,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 361/1348 [00:45<02:04,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 362/1348 [00:45<02:04,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 363/1348 [00:45<02:04,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 364/1348 [00:45<02:04,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 365/1348 [00:46<02:04,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 366/1348 [00:46<02:04,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 367/1348 [00:46<02:03,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 368/1348 [00:46<02:03,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 369/1348 [00:46<02:03,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 370/1348 [00:46<02:03,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 371/1348 [00:46<02:03,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 372/1348 [00:46<02:02,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 373/1348 [00:47<02:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 374/1348 [00:47<02:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 375/1348 [00:47<02:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 376/1348 [00:47<02:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 377/1348 [00:47<02:02,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 378/1348 [00:47<02:02,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 379/1348 [00:47<02:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 380/1348 [00:47<02:01,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 381/1348 [00:48<02:01,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 382/1348 [00:48<02:02,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 383/1348 [00:48<02:01,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 384/1348 [00:48<02:01,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 385/1348 [00:48<02:01,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 386/1348 [00:48<02:01,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 387/1348 [00:48<02:01,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 388/1348 [00:48<02:01,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 389/1348 [00:49<02:01,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 390/1348 [00:49<02:00,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 391/1348 [00:49<02:00,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 392/1348 [00:49<02:00,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 393/1348 [00:49<02:00,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 394/1348 [00:49<02:00,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 395/1348 [00:49<02:00,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 396/1348 [00:49<01:59,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 397/1348 [00:50<01:59,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 398/1348 [00:50<02:00,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 399/1348 [00:50<01:59,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 400/1348 [00:50<01:59,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 401/1348 [00:50<01:59,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 402/1348 [00:50<01:59,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 403/1348 [00:50<02:01,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 404/1348 [00:50<02:01,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 405/1348 [00:51<02:00,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 406/1348 [00:51<01:59,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 407/1348 [00:51<01:59,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 408/1348 [00:51<01:59,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 409/1348 [00:51<01:59,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 410/1348 [00:51<01:59,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 411/1348 [00:51<01:59,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 412/1348 [00:51<01:58,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 413/1348 [00:52<01:58,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 414/1348 [00:52<01:57,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 415/1348 [00:52<01:58,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 416/1348 [00:52<01:57,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 417/1348 [00:52<01:57,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 418/1348 [00:52<01:57,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 419/1348 [00:52<01:57,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 420/1348 [00:52<01:56,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 421/1348 [00:53<01:56,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|ââââ      | 422/1348 [00:53<01:58,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|ââââ      | 423/1348 [00:53<01:57,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|ââââ      | 424/1348 [00:53<01:57,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 425/1348 [00:53<01:57,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 426/1348 [00:53<01:56,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 427/1348 [00:53<01:56,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 428/1348 [00:53<01:56,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 429/1348 [00:54<01:56,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 430/1348 [00:54<01:55,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 431/1348 [00:54<01:55,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 432/1348 [00:54<01:55,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 433/1348 [00:54<01:56,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 434/1348 [00:54<01:55,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 435/1348 [00:54<01:55,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 436/1348 [00:55<01:55,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 437/1348 [00:55<01:55,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 438/1348 [00:55<01:55,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 439/1348 [00:55<01:55,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 440/1348 [00:55<01:54,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 441/1348 [00:55<01:55,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 442/1348 [00:55<01:54,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 443/1348 [00:55<01:54,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 444/1348 [00:56<01:54,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 445/1348 [00:56<01:53,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 446/1348 [00:56<01:53,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 447/1348 [00:56<01:53,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 448/1348 [00:56<01:53,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 449/1348 [00:56<01:53,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 450/1348 [00:56<01:53,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 451/1348 [00:56<01:53,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 452/1348 [00:57<01:53,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 453/1348 [00:57<01:53,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 454/1348 [00:57<01:53,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 455/1348 [00:57<01:53,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 456/1348 [00:57<01:53,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 457/1348 [00:57<01:53,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 458/1348 [00:57<01:52,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 459/1348 [00:57<01:52,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 460/1348 [00:58<01:52,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 461/1348 [00:58<01:51,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 462/1348 [00:58<01:52,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 463/1348 [00:58<01:52,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 464/1348 [00:58<01:51,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 465/1348 [00:58<01:51,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 466/1348 [00:58<01:51,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 467/1348 [00:58<01:51,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 468/1348 [00:59<01:51,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 469/1348 [00:59<01:50,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 470/1348 [00:59<01:50,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 471/1348 [00:59<01:50,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 472/1348 [00:59<01:50,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 473/1348 [00:59<01:51,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 474/1348 [00:59<01:50,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 475/1348 [00:59<01:50,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 476/1348 [01:00<01:49,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 477/1348 [01:00<01:49,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 478/1348 [01:00<01:49,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 479/1348 [01:00<01:49,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 480/1348 [01:00<01:49,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 481/1348 [01:00<01:49,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 482/1348 [01:00<01:49,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 483/1348 [01:00<01:49,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 484/1348 [01:01<01:48,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 485/1348 [01:01<01:48,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 486/1348 [01:01<01:48,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 487/1348 [01:01<01:48,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 488/1348 [01:01<01:48,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 489/1348 [01:01<01:48,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 490/1348 [01:01<01:48,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 491/1348 [01:01<01:48,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 492/1348 [01:02<01:48,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 493/1348 [01:02<01:48,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 494/1348 [01:02<01:47,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 495/1348 [01:02<01:47,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 496/1348 [01:02<01:47,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 497/1348 [01:02<01:48,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 498/1348 [01:02<01:47,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 499/1348 [01:02<01:47,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 500/1348 [01:03<01:47,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 501/1348 [01:03<01:47,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 502/1348 [01:03<01:48,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 503/1348 [01:03<01:47,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 504/1348 [01:03<01:47,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 505/1348 [01:03<01:47,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 506/1348 [01:03<01:47,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 507/1348 [01:03<01:46,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 508/1348 [01:04<01:46,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 509/1348 [01:04<01:46,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 510/1348 [01:04<01:45,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 511/1348 [01:04<01:45,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 512/1348 [01:04<01:45,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 513/1348 [01:04<01:45,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 514/1348 [01:04<01:45,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 515/1348 [01:04<01:44,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 516/1348 [01:05<01:44,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 517/1348 [01:05<01:45,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 518/1348 [01:05<01:45,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 519/1348 [01:05<01:45,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 520/1348 [01:05<01:45,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 521/1348 [01:05<01:46,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 522/1348 [01:05<01:46,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 523/1348 [01:06<01:46,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 524/1348 [01:06<01:46,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 525/1348 [01:06<01:45,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 526/1348 [01:06<01:45,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 527/1348 [01:06<01:45,  7.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 528/1348 [01:06<01:45,  7.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 529/1348 [01:06<01:46,  7.69it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 530/1348 [01:06<01:46,  7.69it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 531/1348 [01:07<01:46,  7.68it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 532/1348 [01:07<01:45,  7.71it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 533/1348 [01:07<01:45,  7.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 534/1348 [01:07<01:45,  7.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 535/1348 [01:07<01:45,  7.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 536/1348 [01:07<01:45,  7.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 537/1348 [01:07<01:44,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 538/1348 [01:07<01:43,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 539/1348 [01:08<01:43,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 540/1348 [01:08<01:42,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 541/1348 [01:08<01:43,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 542/1348 [01:08<01:45,  7.64it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 543/1348 [01:08<01:44,  7.68it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 544/1348 [01:08<01:44,  7.69it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 545/1348 [01:08<01:44,  7.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 546/1348 [01:08<01:43,  7.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 547/1348 [01:09<01:43,  7.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 548/1348 [01:09<01:43,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 549/1348 [01:09<01:43,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 550/1348 [01:09<01:42,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 551/1348 [01:09<01:42,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 552/1348 [01:09<01:42,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 553/1348 [01:09<01:42,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 554/1348 [01:10<01:42,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 555/1348 [01:10<01:42,  7.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 556/1348 [01:10<01:42,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 557/1348 [01:10<01:41,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 558/1348 [01:10<01:40,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 559/1348 [01:10<01:40,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 560/1348 [01:10<01:40,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 561/1348 [01:10<01:39,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 562/1348 [01:11<01:39,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 563/1348 [01:11<01:39,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 564/1348 [01:11<01:39,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 565/1348 [01:11<01:39,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 566/1348 [01:11<01:39,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 567/1348 [01:11<01:39,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 568/1348 [01:11<01:39,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 569/1348 [01:11<01:38,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 570/1348 [01:12<01:38,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 571/1348 [01:12<01:38,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 572/1348 [01:12<01:37,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 573/1348 [01:12<01:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 574/1348 [01:12<01:37,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 575/1348 [01:12<01:37,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 576/1348 [01:12<01:37,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 577/1348 [01:12<01:37,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 578/1348 [01:13<01:36,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 579/1348 [01:13<01:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 580/1348 [01:13<01:37,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 581/1348 [01:13<01:39,  7.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 582/1348 [01:13<01:38,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 583/1348 [01:13<01:38,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 584/1348 [01:13<01:38,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 585/1348 [01:13<01:37,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 586/1348 [01:14<01:37,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 587/1348 [01:14<01:37,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 588/1348 [01:14<01:36,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 589/1348 [01:14<01:36,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 590/1348 [01:14<01:36,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 591/1348 [01:14<01:36,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 592/1348 [01:14<01:36,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 593/1348 [01:14<01:36,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 594/1348 [01:15<01:35,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 595/1348 [01:15<01:35,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 596/1348 [01:15<01:35,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 597/1348 [01:15<01:34,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 598/1348 [01:15<01:34,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 599/1348 [01:15<01:35,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 600/1348 [01:15<01:35,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 601/1348 [01:16<01:35,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 602/1348 [01:16<01:35,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 603/1348 [01:16<01:34,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 604/1348 [01:16<01:34,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 605/1348 [01:16<01:34,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 606/1348 [01:16<01:34,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 607/1348 [01:16<01:33,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 608/1348 [01:16<01:33,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 609/1348 [01:17<01:33,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 610/1348 [01:17<01:33,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 611/1348 [01:17<01:33,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 612/1348 [01:17<01:33,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 613/1348 [01:17<01:33,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 614/1348 [01:17<01:33,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 615/1348 [01:17<01:33,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 616/1348 [01:17<01:33,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 617/1348 [01:18<01:33,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 618/1348 [01:18<01:33,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 619/1348 [01:18<01:32,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 620/1348 [01:18<01:32,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 621/1348 [01:18<01:34,  7.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 622/1348 [01:18<01:33,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 623/1348 [01:18<01:32,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 624/1348 [01:18<01:32,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 625/1348 [01:19<01:32,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 626/1348 [01:19<01:32,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 627/1348 [01:19<01:32,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 628/1348 [01:19<01:31,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 629/1348 [01:19<01:31,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 630/1348 [01:19<01:31,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 631/1348 [01:19<01:31,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 632/1348 [01:19<01:30,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 633/1348 [01:20<01:30,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 634/1348 [01:20<01:30,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 635/1348 [01:20<01:30,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 636/1348 [01:20<01:29,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 637/1348 [01:20<01:29,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 638/1348 [01:20<01:29,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 639/1348 [01:20<01:29,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 640/1348 [01:20<01:31,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 641/1348 [01:21<01:31,  7.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 642/1348 [01:21<01:30,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 643/1348 [01:21<01:29,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 644/1348 [01:21<01:30,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 645/1348 [01:21<01:30,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 646/1348 [01:21<01:29,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 647/1348 [01:21<01:29,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 648/1348 [01:21<01:29,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 649/1348 [01:22<01:29,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 650/1348 [01:22<01:28,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 651/1348 [01:22<01:28,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 652/1348 [01:22<01:27,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 653/1348 [01:22<01:32,  7.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 654/1348 [01:22<01:31,  7.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 655/1348 [01:22<01:30,  7.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 656/1348 [01:23<01:29,  7.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 657/1348 [01:23<01:28,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 658/1348 [01:23<01:28,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 659/1348 [01:23<01:27,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 660/1348 [01:23<01:29,  7.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 661/1348 [01:23<01:28,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 662/1348 [01:23<01:27,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 663/1348 [01:23<01:27,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 664/1348 [01:24<01:27,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 665/1348 [01:24<01:26,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 666/1348 [01:24<01:26,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 667/1348 [01:24<01:26,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 668/1348 [01:24<01:26,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 669/1348 [01:24<01:25,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 670/1348 [01:24<01:25,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 671/1348 [01:24<01:25,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 672/1348 [01:25<01:25,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 673/1348 [01:25<01:25,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 674/1348 [01:25<01:25,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 675/1348 [01:25<01:25,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 676/1348 [01:25<01:25,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 677/1348 [01:25<01:24,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 678/1348 [01:25<01:24,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 679/1348 [01:25<01:24,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 680/1348 [01:26<01:24,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 681/1348 [01:26<01:24,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 682/1348 [01:26<01:23,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 683/1348 [01:26<01:23,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 684/1348 [01:26<01:23,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 685/1348 [01:26<01:23,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 686/1348 [01:26<01:23,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 687/1348 [01:26<01:23,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 688/1348 [01:27<01:23,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 689/1348 [01:27<01:23,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 690/1348 [01:27<01:23,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 691/1348 [01:27<01:23,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 692/1348 [01:27<01:22,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 693/1348 [01:27<01:22,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 694/1348 [01:27<01:22,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 695/1348 [01:27<01:22,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 696/1348 [01:28<01:22,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 697/1348 [01:28<01:22,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 698/1348 [01:28<01:22,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 699/1348 [01:28<01:21,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 700/1348 [01:28<01:23,  7.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 701/1348 [01:28<01:23,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 702/1348 [01:28<01:22,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 703/1348 [01:28<01:22,  7.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 704/1348 [01:29<01:22,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 705/1348 [01:29<01:22,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 706/1348 [01:29<01:22,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 707/1348 [01:29<01:21,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 708/1348 [01:29<01:21,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 709/1348 [01:29<01:21,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 710/1348 [01:29<01:21,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 711/1348 [01:30<01:21,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 712/1348 [01:30<01:21,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 713/1348 [01:30<01:21,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 714/1348 [01:30<01:20,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 715/1348 [01:30<01:20,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 716/1348 [01:30<01:20,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 717/1348 [01:30<01:20,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 718/1348 [01:30<01:19,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 719/1348 [01:31<01:20,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 720/1348 [01:31<01:19,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 721/1348 [01:31<01:19,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 722/1348 [01:31<01:19,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 723/1348 [01:31<01:19,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 724/1348 [01:31<01:19,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 725/1348 [01:31<01:19,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 726/1348 [01:31<01:19,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 727/1348 [01:32<01:19,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 728/1348 [01:32<01:18,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 729/1348 [01:32<01:19,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 730/1348 [01:32<01:18,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 731/1348 [01:32<01:18,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 732/1348 [01:32<01:18,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 733/1348 [01:32<01:17,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 734/1348 [01:32<01:17,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 735/1348 [01:33<01:18,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 736/1348 [01:33<01:19,  7.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 737/1348 [01:33<01:18,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 738/1348 [01:33<01:17,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 739/1348 [01:33<01:17,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 740/1348 [01:33<01:18,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 741/1348 [01:33<01:17,  7.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 742/1348 [01:33<01:17,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 743/1348 [01:34<01:17,  7.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 744/1348 [01:34<01:16,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 745/1348 [01:34<01:16,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 746/1348 [01:34<01:16,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 747/1348 [01:34<01:16,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 748/1348 [01:34<01:15,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 749/1348 [01:34<01:15,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 750/1348 [01:34<01:15,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 751/1348 [01:35<01:15,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 752/1348 [01:35<01:15,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 753/1348 [01:35<01:15,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 754/1348 [01:35<01:15,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 755/1348 [01:35<01:14,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 756/1348 [01:35<01:14,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 757/1348 [01:35<01:14,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 758/1348 [01:35<01:13,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 759/1348 [01:36<01:14,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 760/1348 [01:36<01:14,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 761/1348 [01:36<01:13,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 762/1348 [01:36<01:13,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 763/1348 [01:36<01:13,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 764/1348 [01:36<01:13,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 765/1348 [01:36<01:13,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 766/1348 [01:36<01:12,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 767/1348 [01:37<01:13,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 768/1348 [01:37<01:12,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 769/1348 [01:37<01:12,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 770/1348 [01:37<01:12,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 771/1348 [01:37<01:12,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 772/1348 [01:37<01:12,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 773/1348 [01:37<01:12,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 774/1348 [01:37<01:12,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 775/1348 [01:38<01:12,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 776/1348 [01:38<01:12,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 777/1348 [01:38<01:12,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 778/1348 [01:38<01:12,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 779/1348 [01:38<01:12,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 780/1348 [01:38<01:13,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 781/1348 [01:38<01:12,  7.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 782/1348 [01:39<01:11,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 783/1348 [01:39<01:12,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 784/1348 [01:39<01:11,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 785/1348 [01:39<01:11,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 786/1348 [01:39<01:10,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 787/1348 [01:39<01:10,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 788/1348 [01:39<01:10,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 789/1348 [01:39<01:10,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 790/1348 [01:40<01:09,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 791/1348 [01:40<01:10,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 792/1348 [01:40<01:10,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 793/1348 [01:40<01:09,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 794/1348 [01:40<01:09,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 795/1348 [01:40<01:09,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 796/1348 [01:40<01:09,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 797/1348 [01:40<01:09,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 798/1348 [01:41<01:09,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 799/1348 [01:41<01:09,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 800/1348 [01:41<01:09,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 801/1348 [01:41<01:09,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 802/1348 [01:41<01:09,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 803/1348 [01:41<01:08,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 804/1348 [01:41<01:08,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 805/1348 [01:41<01:08,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 806/1348 [01:42<01:08,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 807/1348 [01:42<01:08,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 808/1348 [01:42<01:07,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 809/1348 [01:42<01:07,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 810/1348 [01:42<01:07,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 811/1348 [01:42<01:07,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 812/1348 [01:42<01:07,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 813/1348 [01:42<01:07,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 814/1348 [01:43<01:07,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 815/1348 [01:43<01:07,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 816/1348 [01:43<01:07,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 817/1348 [01:43<01:06,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 818/1348 [01:43<01:06,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 819/1348 [01:43<01:06,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 820/1348 [01:43<01:08,  7.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 821/1348 [01:43<01:07,  7.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 822/1348 [01:44<01:07,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 823/1348 [01:44<01:06,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 824/1348 [01:44<01:06,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 825/1348 [01:44<01:05,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 826/1348 [01:44<01:05,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 827/1348 [01:44<01:05,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 828/1348 [01:44<01:05,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|âââââââ   | 829/1348 [01:44<01:05,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 830/1348 [01:45<01:04,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 831/1348 [01:45<01:04,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 832/1348 [01:45<01:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 833/1348 [01:45<01:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 834/1348 [01:45<01:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 835/1348 [01:45<01:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 836/1348 [01:45<01:04,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 837/1348 [01:45<01:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 838/1348 [01:46<01:04,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 839/1348 [01:46<01:03,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 840/1348 [01:46<01:04,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 841/1348 [01:46<01:03,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 842/1348 [01:46<01:03,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 843/1348 [01:46<01:03,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 844/1348 [01:46<01:03,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 845/1348 [01:46<01:03,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 846/1348 [01:47<01:03,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 847/1348 [01:47<01:03,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 848/1348 [01:47<01:03,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 849/1348 [01:47<01:03,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 850/1348 [01:47<01:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 851/1348 [01:47<01:02,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 852/1348 [01:47<01:02,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 853/1348 [01:47<01:02,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 854/1348 [01:48<01:01,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 855/1348 [01:48<01:01,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 856/1348 [01:48<01:02,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 857/1348 [01:48<01:01,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 858/1348 [01:48<01:01,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 859/1348 [01:48<01:01,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 860/1348 [01:48<01:02,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 861/1348 [01:48<01:01,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 862/1348 [01:49<01:01,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 863/1348 [01:49<01:01,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 864/1348 [01:49<01:01,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 865/1348 [01:49<01:01,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 866/1348 [01:49<01:00,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 867/1348 [01:49<01:00,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 868/1348 [01:49<01:00,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 869/1348 [01:49<01:00,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 870/1348 [01:50<00:59,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 871/1348 [01:50<01:00,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 872/1348 [01:50<01:00,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 873/1348 [01:50<01:00,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 874/1348 [01:50<00:59,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 875/1348 [01:50<00:59,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 876/1348 [01:50<00:59,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 877/1348 [01:50<00:59,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 878/1348 [01:51<00:59,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 879/1348 [01:51<00:59,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 880/1348 [01:51<00:59,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 881/1348 [01:51<00:59,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 882/1348 [01:51<00:59,  7.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 883/1348 [01:51<00:59,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 884/1348 [01:51<00:58,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 885/1348 [01:51<00:58,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 886/1348 [01:52<00:58,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 887/1348 [01:52<00:58,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 888/1348 [01:52<00:58,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 889/1348 [01:52<00:57,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 890/1348 [01:52<00:57,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 891/1348 [01:52<00:57,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 892/1348 [01:52<00:57,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 893/1348 [01:53<00:57,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 894/1348 [01:53<00:56,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 895/1348 [01:53<00:56,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 896/1348 [01:53<00:56,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 897/1348 [01:53<00:56,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 898/1348 [01:53<00:56,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 899/1348 [01:53<00:56,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 900/1348 [01:53<00:56,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 901/1348 [01:54<00:56,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 902/1348 [01:54<00:56,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 903/1348 [01:54<00:55,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 904/1348 [01:54<00:55,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 905/1348 [01:54<00:55,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 906/1348 [01:54<00:55,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 907/1348 [01:54<00:55,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 908/1348 [01:54<00:55,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 909/1348 [01:55<00:55,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 910/1348 [01:55<00:54,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 911/1348 [01:55<00:54,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 912/1348 [01:55<00:54,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 913/1348 [01:55<00:54,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 914/1348 [01:55<00:54,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 915/1348 [01:55<00:54,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 916/1348 [01:55<00:54,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 917/1348 [01:56<00:53,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 918/1348 [01:56<00:53,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 919/1348 [01:56<00:53,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 920/1348 [01:56<00:53,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 921/1348 [01:56<00:53,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 922/1348 [01:56<00:53,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 923/1348 [01:56<00:53,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 924/1348 [01:56<00:53,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 925/1348 [01:57<00:53,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 926/1348 [01:57<00:52,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 927/1348 [01:57<00:52,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 928/1348 [01:57<00:52,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 929/1348 [01:57<00:52,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 930/1348 [01:57<00:52,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 931/1348 [01:57<00:52,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 932/1348 [01:57<00:52,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 933/1348 [01:58<00:52,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 934/1348 [01:58<00:51,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 935/1348 [01:58<00:51,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 936/1348 [01:58<00:51,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 937/1348 [01:58<00:51,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 938/1348 [01:58<00:51,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 939/1348 [01:58<00:51,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 940/1348 [01:58<00:51,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 941/1348 [01:59<00:51,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 942/1348 [01:59<00:51,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 943/1348 [01:59<00:51,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 944/1348 [01:59<00:51,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 945/1348 [01:59<00:50,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 946/1348 [01:59<00:50,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 947/1348 [01:59<00:50,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 948/1348 [01:59<00:50,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 949/1348 [02:00<00:50,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 950/1348 [02:00<00:49,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 951/1348 [02:00<00:49,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 952/1348 [02:00<00:49,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 953/1348 [02:00<00:49,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 954/1348 [02:00<00:49,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 955/1348 [02:00<00:49,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 956/1348 [02:00<00:49,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 957/1348 [02:01<00:49,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 958/1348 [02:01<00:48,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 959/1348 [02:01<00:48,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 960/1348 [02:01<00:48,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|ââââââââ  | 961/1348 [02:01<00:48,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|ââââââââ  | 962/1348 [02:01<00:48,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|ââââââââ  | 963/1348 [02:01<00:48,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 964/1348 [02:01<00:48,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 965/1348 [02:02<00:47,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 966/1348 [02:02<00:47,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 967/1348 [02:02<00:47,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 968/1348 [02:02<00:47,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 969/1348 [02:02<00:47,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 970/1348 [02:02<00:47,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 971/1348 [02:02<00:47,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 972/1348 [02:02<00:46,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 973/1348 [02:03<00:46,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 974/1348 [02:03<00:46,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 975/1348 [02:03<00:46,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 976/1348 [02:03<00:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 977/1348 [02:03<00:46,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 978/1348 [02:03<00:46,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 979/1348 [02:03<00:46,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 980/1348 [02:03<00:46,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 981/1348 [02:04<00:46,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 982/1348 [02:04<00:46,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 983/1348 [02:04<00:45,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 984/1348 [02:04<00:45,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 985/1348 [02:04<00:45,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 986/1348 [02:04<00:45,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 987/1348 [02:04<00:45,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 988/1348 [02:04<00:45,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 989/1348 [02:05<00:44,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 990/1348 [02:05<00:44,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 991/1348 [02:05<00:44,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 992/1348 [02:05<00:44,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 993/1348 [02:05<00:44,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 994/1348 [02:05<00:44,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 995/1348 [02:05<00:44,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 996/1348 [02:05<00:44,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 997/1348 [02:06<00:44,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 998/1348 [02:06<00:44,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 999/1348 [02:06<00:43,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1000/1348 [02:06<00:43,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1001/1348 [02:06<00:44,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1002/1348 [02:06<00:43,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1003/1348 [02:06<00:43,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 1004/1348 [02:06<00:43,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1005/1348 [02:07<00:43,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1006/1348 [02:07<00:43,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1007/1348 [02:07<00:42,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1008/1348 [02:07<00:42,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1009/1348 [02:07<00:42,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1010/1348 [02:07<00:42,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1011/1348 [02:07<00:42,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1012/1348 [02:07<00:42,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1013/1348 [02:08<00:41,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1014/1348 [02:08<00:41,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1015/1348 [02:08<00:41,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1016/1348 [02:08<00:41,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 1017/1348 [02:08<00:41,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1018/1348 [02:08<00:41,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1019/1348 [02:08<00:41,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1020/1348 [02:08<00:40,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1021/1348 [02:09<00:41,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1022/1348 [02:09<00:41,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1023/1348 [02:09<00:41,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1024/1348 [02:09<00:40,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1025/1348 [02:09<00:40,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1026/1348 [02:09<00:40,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1027/1348 [02:09<00:40,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1028/1348 [02:09<00:40,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1029/1348 [02:10<00:40,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1030/1348 [02:10<00:39,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 1031/1348 [02:10<00:39,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1032/1348 [02:10<00:39,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1033/1348 [02:10<00:39,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1034/1348 [02:10<00:39,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1035/1348 [02:10<00:39,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1036/1348 [02:10<00:39,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1037/1348 [02:11<00:38,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1038/1348 [02:11<00:38,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1039/1348 [02:11<00:38,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1040/1348 [02:11<00:38,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1041/1348 [02:11<00:38,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1042/1348 [02:11<00:38,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1043/1348 [02:11<00:38,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 1044/1348 [02:11<00:38,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1045/1348 [02:12<00:38,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1046/1348 [02:12<00:38,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1047/1348 [02:12<00:37,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1048/1348 [02:12<00:37,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1049/1348 [02:12<00:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1050/1348 [02:12<00:37,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1051/1348 [02:12<00:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1052/1348 [02:12<00:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1053/1348 [02:13<00:37,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1054/1348 [02:13<00:37,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1055/1348 [02:13<00:36,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1056/1348 [02:13<00:36,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1057/1348 [02:13<00:36,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 1058/1348 [02:13<00:36,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1059/1348 [02:13<00:36,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1060/1348 [02:13<00:36,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1061/1348 [02:14<00:36,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1062/1348 [02:14<00:36,  7.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1063/1348 [02:14<00:36,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1064/1348 [02:14<00:35,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1065/1348 [02:14<00:35,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1066/1348 [02:14<00:35,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1067/1348 [02:14<00:35,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1068/1348 [02:15<00:35,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1069/1348 [02:15<00:35,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1070/1348 [02:15<00:34,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 1071/1348 [02:15<00:34,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1072/1348 [02:15<00:34,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1073/1348 [02:15<00:34,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1074/1348 [02:15<00:34,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1075/1348 [02:15<00:34,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1076/1348 [02:16<00:33,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1077/1348 [02:16<00:33,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1078/1348 [02:16<00:33,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1079/1348 [02:16<00:33,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1080/1348 [02:16<00:33,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1081/1348 [02:16<00:33,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1082/1348 [02:16<00:33,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1083/1348 [02:16<00:33,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1084/1348 [02:16<00:32,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 1085/1348 [02:17<00:32,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1086/1348 [02:17<00:32,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1087/1348 [02:17<00:32,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1088/1348 [02:17<00:32,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1089/1348 [02:17<00:32,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1090/1348 [02:17<00:32,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1091/1348 [02:17<00:32,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1092/1348 [02:18<00:32,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1093/1348 [02:18<00:31,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1094/1348 [02:18<00:31,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 1095/1348 [02:18<00:31,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|âââââââââ | 1096/1348 [02:18<00:31,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|âââââââââ | 1097/1348 [02:18<00:31,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|âââââââââ | 1098/1348 [02:18<00:31,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1099/1348 [02:18<00:31,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1100/1348 [02:19<00:31,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1101/1348 [02:19<00:31,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1102/1348 [02:19<00:30,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1103/1348 [02:19<00:30,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1104/1348 [02:19<00:30,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1105/1348 [02:19<00:30,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1106/1348 [02:19<00:30,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1107/1348 [02:19<00:30,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1108/1348 [02:20<00:30,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1109/1348 [02:20<00:30,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1110/1348 [02:20<00:29,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1111/1348 [02:20<00:29,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 1112/1348 [02:20<00:29,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1113/1348 [02:20<00:29,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1114/1348 [02:20<00:29,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1115/1348 [02:20<00:29,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1116/1348 [02:21<00:29,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1117/1348 [02:21<00:29,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1118/1348 [02:21<00:29,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1119/1348 [02:21<00:29,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1120/1348 [02:21<00:28,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1121/1348 [02:21<00:28,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1122/1348 [02:21<00:28,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1123/1348 [02:21<00:28,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1124/1348 [02:22<00:28,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 1125/1348 [02:22<00:28,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1126/1348 [02:22<00:27,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1127/1348 [02:22<00:27,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1128/1348 [02:22<00:27,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1129/1348 [02:22<00:27,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1130/1348 [02:22<00:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1131/1348 [02:22<00:27,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1132/1348 [02:23<00:27,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1133/1348 [02:23<00:26,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1134/1348 [02:23<00:26,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1135/1348 [02:23<00:26,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1136/1348 [02:23<00:26,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1137/1348 [02:23<00:26,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1138/1348 [02:23<00:26,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 1139/1348 [02:23<00:26,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1140/1348 [02:24<00:26,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1141/1348 [02:24<00:26,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1142/1348 [02:24<00:25,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1143/1348 [02:24<00:25,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1144/1348 [02:24<00:25,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1145/1348 [02:24<00:25,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1146/1348 [02:24<00:25,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1147/1348 [02:24<00:25,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1148/1348 [02:25<00:25,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1149/1348 [02:25<00:25,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1150/1348 [02:25<00:24,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1151/1348 [02:25<00:24,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 1152/1348 [02:25<00:24,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1153/1348 [02:25<00:25,  7.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1154/1348 [02:25<00:25,  7.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1155/1348 [02:25<00:24,  7.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1156/1348 [02:26<00:24,  7.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1157/1348 [02:26<00:24,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1158/1348 [02:26<00:24,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1159/1348 [02:26<00:23,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1160/1348 [02:26<00:23,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1161/1348 [02:26<00:23,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1162/1348 [02:26<00:23,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1163/1348 [02:26<00:23,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1164/1348 [02:27<00:23,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1165/1348 [02:27<00:23,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 1166/1348 [02:27<00:22,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1167/1348 [02:27<00:22,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1168/1348 [02:27<00:22,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1169/1348 [02:27<00:22,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1170/1348 [02:27<00:22,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1171/1348 [02:27<00:22,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1172/1348 [02:28<00:22,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1173/1348 [02:28<00:21,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1174/1348 [02:28<00:21,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1175/1348 [02:28<00:21,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1176/1348 [02:28<00:21,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1177/1348 [02:28<00:21,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1178/1348 [02:28<00:21,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 1179/1348 [02:28<00:21,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1180/1348 [02:29<00:21,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1181/1348 [02:29<00:20,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1182/1348 [02:29<00:20,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1183/1348 [02:29<00:20,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1184/1348 [02:29<00:20,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1185/1348 [02:29<00:20,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1186/1348 [02:29<00:20,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1187/1348 [02:29<00:20,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1188/1348 [02:30<00:20,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1189/1348 [02:30<00:19,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1190/1348 [02:30<00:19,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1191/1348 [02:30<00:19,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 1192/1348 [02:30<00:19,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1193/1348 [02:30<00:19,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1194/1348 [02:30<00:19,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1195/1348 [02:30<00:19,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1196/1348 [02:31<00:19,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1197/1348 [02:31<00:18,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1198/1348 [02:31<00:18,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1199/1348 [02:31<00:18,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1200/1348 [02:31<00:18,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1201/1348 [02:31<00:18,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1202/1348 [02:31<00:18,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1203/1348 [02:31<00:18,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1204/1348 [02:32<00:18,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1205/1348 [02:32<00:17,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 1206/1348 [02:32<00:17,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1207/1348 [02:32<00:17,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1208/1348 [02:32<00:17,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1209/1348 [02:32<00:17,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1210/1348 [02:32<00:17,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1211/1348 [02:32<00:17,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1212/1348 [02:33<00:17,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1213/1348 [02:33<00:16,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1214/1348 [02:33<00:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1215/1348 [02:33<00:16,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1216/1348 [02:33<00:16,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1217/1348 [02:33<00:16,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1218/1348 [02:33<00:16,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 1219/1348 [02:33<00:16,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1220/1348 [02:34<00:15,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1221/1348 [02:34<00:15,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1222/1348 [02:34<00:15,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1223/1348 [02:34<00:15,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1224/1348 [02:34<00:15,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1225/1348 [02:34<00:15,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1226/1348 [02:34<00:15,  7.90it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1227/1348 [02:34<00:15,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1228/1348 [02:35<00:15,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1229/1348 [02:35<00:14,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 1230/1348 [02:35<00:14,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 1231/1348 [02:35<00:14,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 1232/1348 [02:35<00:14,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 1233/1348 [02:35<00:14,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1234/1348 [02:35<00:14,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1235/1348 [02:35<00:14,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1236/1348 [02:36<00:13,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1237/1348 [02:36<00:13,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1238/1348 [02:36<00:13,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1239/1348 [02:36<00:13,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1240/1348 [02:36<00:13,  8.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1241/1348 [02:36<00:13,  8.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1242/1348 [02:36<00:13,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1243/1348 [02:36<00:13,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1244/1348 [02:37<00:12,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1245/1348 [02:37<00:12,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 1246/1348 [02:37<00:12,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1247/1348 [02:37<00:12,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1248/1348 [02:37<00:12,  8.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1249/1348 [02:37<00:12,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1250/1348 [02:37<00:12,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1251/1348 [02:37<00:12,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1252/1348 [02:38<00:12,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1253/1348 [02:38<00:11,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1254/1348 [02:38<00:11,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1255/1348 [02:38<00:11,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1256/1348 [02:38<00:11,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1257/1348 [02:38<00:11,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1258/1348 [02:38<00:11,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1259/1348 [02:38<00:11,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 1260/1348 [02:39<00:11,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1261/1348 [02:39<00:10,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1262/1348 [02:39<00:10,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1263/1348 [02:39<00:10,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1264/1348 [02:39<00:10,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1265/1348 [02:39<00:10,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1266/1348 [02:39<00:10,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1267/1348 [02:40<00:10,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1268/1348 [02:40<00:10,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1269/1348 [02:40<00:09,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1270/1348 [02:40<00:09,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1271/1348 [02:40<00:09,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1272/1348 [02:40<00:09,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 1273/1348 [02:40<00:09,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1274/1348 [02:40<00:09,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1275/1348 [02:41<00:09,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1276/1348 [02:41<00:09,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1277/1348 [02:41<00:08,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1278/1348 [02:41<00:08,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1279/1348 [02:41<00:08,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1280/1348 [02:41<00:08,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1281/1348 [02:41<00:08,  8.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1282/1348 [02:41<00:08,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1283/1348 [02:42<00:08,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1284/1348 [02:42<00:08,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1285/1348 [02:42<00:07,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1286/1348 [02:42<00:07,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 1287/1348 [02:42<00:07,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1288/1348 [02:42<00:07,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1289/1348 [02:42<00:07,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1290/1348 [02:42<00:07,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1291/1348 [02:43<00:07,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1292/1348 [02:43<00:07,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1293/1348 [02:43<00:06,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1294/1348 [02:43<00:06,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1295/1348 [02:43<00:06,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1296/1348 [02:43<00:06,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1297/1348 [02:43<00:06,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1298/1348 [02:43<00:06,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1299/1348 [02:44<00:06,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 1300/1348 [02:44<00:06,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1301/1348 [02:44<00:05,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1302/1348 [02:44<00:05,  7.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1303/1348 [02:44<00:05,  7.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1304/1348 [02:44<00:05,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1305/1348 [02:44<00:05,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1306/1348 [02:44<00:05,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1307/1348 [02:45<00:05,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1308/1348 [02:45<00:05,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1309/1348 [02:45<00:04,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1310/1348 [02:45<00:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1311/1348 [02:45<00:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1312/1348 [02:45<00:04,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1313/1348 [02:45<00:04,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 1314/1348 [02:45<00:04,  8.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1315/1348 [02:46<00:04,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1316/1348 [02:46<00:04,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1317/1348 [02:46<00:03,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1318/1348 [02:46<00:03,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1319/1348 [02:46<00:03,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1320/1348 [02:46<00:03,  8.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1321/1348 [02:46<00:03,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1322/1348 [02:46<00:03,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1323/1348 [02:47<00:03,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1324/1348 [02:47<00:03,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1325/1348 [02:47<00:02,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1326/1348 [02:47<00:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 1327/1348 [02:47<00:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1328/1348 [02:47<00:02,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1329/1348 [02:47<00:02,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1330/1348 [02:47<00:02,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1331/1348 [02:48<00:02,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1332/1348 [02:48<00:02,  7.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1333/1348 [02:48<00:01,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1334/1348 [02:48<00:01,  7.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1335/1348 [02:48<00:01,  7.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1336/1348 [02:48<00:01,  7.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1337/1348 [02:48<00:01,  7.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1338/1348 [02:48<00:01,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1339/1348 [02:49<00:01,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1340/1348 [02:49<00:01,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 1341/1348 [02:49<00:00,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1342/1348 [02:49<00:00,  7.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1343/1348 [02:49<00:00,  7.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1344/1348 [02:49<00:00,  7.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1345/1348 [02:49<00:00,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1346/1348 [02:49<00:00,  7.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1347/1348 [02:50<00:00,  7.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1348/1348 [02:50<00:00,  7.99it/s]#033[A01/14/2021 16:04:33 - INFO - nn_pruning.examples.question_answering.qa_train -     Evaluation done in total 170.323371 secs (0.015794 sec per example)\u001b[0m\n",
      "\u001b[34m01/14/2021 16:04:45 - INFO - nn_pruning.examples.question_answering.qa_utils -   Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/10570 [00:00<?, ?it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 36/10570 [00:00<00:29, 356.88it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  1%|          | 75/10570 [00:00<00:28, 365.78it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  1%|          | 114/10570 [00:00<00:28, 370.61it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 153/10570 [00:00<00:27, 375.51it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 192/10570 [00:00<00:27, 377.76it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 225/10570 [00:00<00:28, 361.52it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 258/10570 [00:00<00:32, 317.26it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 288/10570 [00:00<00:36, 283.56it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 326/10570 [00:00<00:33, 306.57it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 366/10570 [00:01<00:31, 328.26it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 403/10570 [00:01<00:29, 339.19it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 440/10570 [00:01<00:29, 346.18it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 476/10570 [00:01<00:28, 348.94it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 516/10570 [00:01<00:27, 360.62it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 554/10570 [00:01<00:27, 365.76it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 592/10570 [00:01<00:27, 366.81it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 631/10570 [00:01<00:26, 373.43it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 669/10570 [00:01<00:26, 374.53it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 707/10570 [00:01<00:26, 374.02it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 745/10570 [00:02<00:26, 366.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 782/10570 [00:02<00:27, 358.91it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 818/10570 [00:02<00:29, 335.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 853/10570 [00:02<00:28, 338.87it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 890/10570 [00:02<00:27, 347.43it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 925/10570 [00:02<00:28, 341.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 960/10570 [00:02<00:27, 343.64it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 995/10570 [00:02<00:28, 341.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1030/10570 [00:02<00:27, 341.77it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1065/10570 [00:03<00:27, 341.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1100/10570 [00:03<00:28, 335.71it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 1136/10570 [00:03<00:27, 342.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 1174/10570 [00:03<00:26, 350.77it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 1211/10570 [00:03<00:26, 355.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 1250/10570 [00:03<00:25, 362.95it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 1287/10570 [00:03<00:25, 361.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 1325/10570 [00:03<00:25, 366.96it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 1362/10570 [00:03<00:25, 367.26it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 1399/10570 [00:03<00:25, 357.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1435/10570 [00:04<00:25, 357.97it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1473/10570 [00:04<00:25, 361.57it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1511/10570 [00:04<00:24, 365.17it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1548/10570 [00:04<00:24, 364.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1585/10570 [00:04<00:24, 365.58it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1623/10570 [00:04<00:24, 367.53it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 1663/10570 [00:04<00:23, 374.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 1702/10570 [00:04<00:23, 378.07it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 1740/10570 [00:04<00:23, 374.15it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 1779/10570 [00:04<00:23, 376.13it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 1817/10570 [00:05<00:23, 374.93it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1855/10570 [00:05<00:23, 371.08it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1895/10570 [00:05<00:22, 378.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1933/10570 [00:05<00:23, 375.33it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 1973/10570 [00:05<00:22, 379.67it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 2012/10570 [00:05<00:22, 376.20it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 2051/10570 [00:05<00:22, 378.06it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 2090/10570 [00:05<00:22, 381.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 2129/10570 [00:05<00:24, 343.51it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 2165/10570 [00:06<00:24, 346.92it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 2203/10570 [00:06<00:23, 353.33it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 2241/10570 [00:06<00:23, 360.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2278/10570 [00:06<00:23, 360.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2315/10570 [00:06<00:23, 357.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2352/10570 [00:06<00:22, 361.08it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2389/10570 [00:06<00:23, 354.96it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2425/10570 [00:06<00:22, 355.39it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2461/10570 [00:06<00:23, 352.03it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2497/10570 [00:06<00:23, 344.21it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2532/10570 [00:07<00:23, 336.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2566/10570 [00:07<00:24, 327.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 2603/10570 [00:07<00:23, 337.18it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 2640/10570 [00:07<00:22, 344.82it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 2678/10570 [00:07<00:22, 353.03it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2715/10570 [00:07<00:22, 356.67it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2754/10570 [00:07<00:21, 364.75it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2793/10570 [00:07<00:21, 370.07it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 2831/10570 [00:07<00:20, 371.52it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 2869/10570 [00:08<00:20, 367.14it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 2906/10570 [00:08<00:21, 362.01it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 2943/10570 [00:08<00:20, 364.14it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 2980/10570 [00:08<00:21, 358.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 3016/10570 [00:08<00:21, 357.93it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 3053/10570 [00:08<00:20, 360.08it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 3090/10570 [00:08<00:20, 357.65it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3127/10570 [00:08<00:20, 358.62it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3163/10570 [00:08<00:20, 353.88it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3199/10570 [00:08<00:21, 350.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 3235/10570 [00:09<00:21, 348.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 3271/10570 [00:09<00:20, 349.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 31%|ââââ      | 3306/10570 [00:09<00:20, 349.51it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3343/10570 [00:09<00:20, 355.39it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3379/10570 [00:09<00:20, 352.91it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3415/10570 [00:09<00:20, 351.22it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3452/10570 [00:09<00:20, 354.43it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3488/10570 [00:09<00:20, 350.19it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3524/10570 [00:09<00:19, 352.54it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3560/10570 [00:09<00:19, 353.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3596/10570 [00:10<00:19, 349.67it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3633/10570 [00:10<00:19, 352.77it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3669/10570 [00:10<00:19, 353.66it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3705/10570 [00:10<00:19, 353.57it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3741/10570 [00:10<00:19, 346.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 3778/10570 [00:10<00:19, 352.84it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 3814/10570 [00:10<00:19, 348.17it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 3851/10570 [00:10<00:19, 351.65it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3887/10570 [00:10<00:18, 353.32it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3923/10570 [00:11<00:18, 353.09it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3959/10570 [00:11<00:18, 354.32it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 3995/10570 [00:11<00:18, 354.40it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 4031/10570 [00:11<00:18, 353.41it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 4068/10570 [00:11<00:18, 357.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4104/10570 [00:11<00:18, 343.02it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4139/10570 [00:11<00:19, 330.46it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4173/10570 [00:11<00:23, 270.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4202/10570 [00:11<00:26, 240.82it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4229/10570 [00:12<00:25, 247.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4259/10570 [00:12<00:24, 257.74it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4286/10570 [00:12<00:32, 193.16it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4309/10570 [00:12<00:34, 182.97it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4344/10570 [00:12<00:29, 213.53it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 4380/10570 [00:12<00:25, 242.61it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4413/10570 [00:12<00:23, 261.87it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4450/10570 [00:12<00:21, 285.68it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4488/10570 [00:13<00:19, 307.50it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4522/10570 [00:13<00:19, 306.62it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4555/10570 [00:13<00:19, 310.95it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4590/10570 [00:13<00:18, 319.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4623/10570 [00:13<00:19, 305.56it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4655/10570 [00:13<00:19, 299.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4689/10570 [00:13<00:18, 309.85it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4726/10570 [00:13<00:18, 324.07it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4759/10570 [00:13<00:18, 312.88it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4791/10570 [00:14<00:18, 314.27it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4829/10570 [00:14<00:17, 329.25it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4863/10570 [00:14<00:18, 310.15it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4899/10570 [00:14<00:17, 323.17it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 4934/10570 [00:14<00:17, 330.07it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 4968/10570 [00:14<00:16, 331.33it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 5002/10570 [00:14<00:17, 327.20it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5036/10570 [00:14<00:16, 330.12it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5072/10570 [00:14<00:16, 335.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5107/10570 [00:14<00:16, 338.90it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5143/10570 [00:15<00:15, 343.09it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5178/10570 [00:15<00:15, 344.25it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5214/10570 [00:15<00:15, 346.06it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5249/10570 [00:15<00:15, 346.05it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5286/10570 [00:15<00:15, 350.38it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5322/10570 [00:15<00:14, 351.20it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 5358/10570 [00:15<00:14, 350.48it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 5394/10570 [00:15<00:14, 352.31it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 5430/10570 [00:15<00:14, 348.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5465/10570 [00:16<00:15, 322.71it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5498/10570 [00:16<00:16, 311.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5531/10570 [00:16<00:16, 314.37it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5565/10570 [00:16<00:15, 320.67it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5600/10570 [00:16<00:15, 326.65it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5633/10570 [00:16<00:15, 316.88it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5665/10570 [00:16<00:15, 306.84it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5701/10570 [00:16<00:15, 320.85it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5736/10570 [00:16<00:14, 327.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5770/10570 [00:16<00:14, 328.56it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5804/10570 [00:17<00:14, 330.18it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5839/10570 [00:17<00:14, 335.72it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5873/10570 [00:17<00:13, 335.53it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5908/10570 [00:17<00:13, 338.25it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5943/10570 [00:17<00:13, 339.31it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 5978/10570 [00:17<00:13, 340.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 6013/10570 [00:17<00:13, 337.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 6047/10570 [00:17<00:13, 336.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6081/10570 [00:17<00:13, 329.56it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6115/10570 [00:17<00:13, 332.40it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6151/10570 [00:18<00:13, 339.39it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6186/10570 [00:18<00:12, 340.41it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6221/10570 [00:18<00:12, 341.01it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6256/10570 [00:18<00:13, 322.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6292/10570 [00:18<00:12, 330.29it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6326/10570 [00:18<00:12, 331.20it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6361/10570 [00:18<00:12, 336.54it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 6395/10570 [00:18<00:12, 322.71it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 6432/10570 [00:18<00:12, 333.87it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 6469/10570 [00:19<00:11, 343.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6504/10570 [00:19<00:11, 344.45it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6539/10570 [00:19<00:11, 345.24it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6574/10570 [00:19<00:11, 344.19it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6609/10570 [00:19<00:11, 339.50it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6645/10570 [00:19<00:11, 343.66it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6680/10570 [00:19<00:11, 343.45it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6715/10570 [00:19<00:11, 331.55it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6751/10570 [00:19<00:11, 338.77it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6786/10570 [00:19<00:11, 341.52it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6821/10570 [00:20<00:11, 337.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6855/10570 [00:20<00:11, 336.09it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6889/10570 [00:20<00:11, 333.69it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 6924/10570 [00:20<00:10, 336.17it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 6961/10570 [00:20<00:10, 343.68it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 6996/10570 [00:20<00:10, 345.08it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 7033/10570 [00:20<00:10, 349.62it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 7069/10570 [00:20<00:09, 350.17it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 7105/10570 [00:20<00:09, 350.88it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7142/10570 [00:20<00:09, 353.64it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7178/10570 [00:21<00:09, 353.94it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7214/10570 [00:21<00:09, 350.47it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7250/10570 [00:21<00:09, 347.20it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7285/10570 [00:21<00:09, 345.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7321/10570 [00:21<00:09, 348.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7356/10570 [00:21<00:10, 312.66it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7390/10570 [00:21<00:09, 319.30it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7427/10570 [00:21<00:09, 331.30it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 7461/10570 [00:21<00:09, 332.10it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 7497/10570 [00:22<00:09, 337.23it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 71%|ââââââââ  | 7534/10570 [00:22<00:08, 343.80it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7569/10570 [00:22<00:08, 344.36it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7605/10570 [00:22<00:08, 348.40it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7640/10570 [00:22<00:08, 348.77it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7675/10570 [00:22<00:08, 331.14it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7711/10570 [00:22<00:08, 336.90it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7745/10570 [00:22<00:08, 335.99it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7779/10570 [00:22<00:08, 319.11it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7813/10570 [00:23<00:08, 323.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7848/10570 [00:23<00:08, 328.90it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7884/10570 [00:23<00:08, 335.32it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7921/10570 [00:23<00:07, 342.95it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7957/10570 [00:23<00:07, 345.17it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 7992/10570 [00:23<00:07, 341.46it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 8027/10570 [00:23<00:07, 340.56it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 8062/10570 [00:23<00:07, 334.54it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8098/10570 [00:23<00:07, 340.29it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8133/10570 [00:23<00:07, 342.90it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8168/10570 [00:24<00:07, 334.67it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8202/10570 [00:24<00:07, 330.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8236/10570 [00:24<00:07, 327.62it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8269/10570 [00:24<00:07, 325.53it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8302/10570 [00:24<00:07, 313.65it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8335/10570 [00:24<00:07, 317.65it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8370/10570 [00:24<00:06, 325.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8405/10570 [00:24<00:06, 331.38it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8441/10570 [00:24<00:06, 338.80it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8478/10570 [00:24<00:06, 346.28it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 8513/10570 [00:25<00:05, 345.92it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 8549/10570 [00:25<00:05, 349.64it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 8585/10570 [00:25<00:05, 344.38it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8621/10570 [00:25<00:05, 346.87it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8656/10570 [00:25<00:05, 344.29it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8692/10570 [00:25<00:05, 348.74it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8727/10570 [00:25<00:05, 341.68it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8762/10570 [00:25<00:05, 340.11it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8797/10570 [00:25<00:05, 337.51it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8831/10570 [00:26<00:05, 337.61it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8866/10570 [00:26<00:05, 340.50it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8901/10570 [00:26<00:04, 342.12it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 8937/10570 [00:26<00:04, 345.78it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 8972/10570 [00:26<00:04, 345.96it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 9008/10570 [00:26<00:04, 349.43it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 9043/10570 [00:26<00:04, 343.91it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 9078/10570 [00:26<00:04, 341.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 9113/10570 [00:26<00:04, 343.14it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9148/10570 [00:26<00:04, 344.66it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9184/10570 [00:27<00:03, 346.89it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9219/10570 [00:27<00:03, 347.76it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9256/10570 [00:27<00:03, 353.79it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9292/10570 [00:27<00:03, 350.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9328/10570 [00:27<00:03, 347.11it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9364/10570 [00:27<00:03, 348.33it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9399/10570 [00:27<00:03, 345.50it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9434/10570 [00:27<00:03, 346.22it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9471/10570 [00:27<00:03, 351.34it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9507/10570 [00:27<00:03, 328.95it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9544/10570 [00:28<00:03, 339.08it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 9580/10570 [00:28<00:02, 343.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 9616/10570 [00:28<00:02, 347.42it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 9652/10570 [00:28<00:02, 348.53it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9689/10570 [00:28<00:02, 352.98it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9727/10570 [00:28<00:02, 358.05it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9763/10570 [00:28<00:02, 355.00it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9799/10570 [00:28<00:02, 351.95it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9835/10570 [00:28<00:02, 348.57it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9870/10570 [00:28<00:02, 347.63it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9905/10570 [00:29<00:01, 345.81it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9942/10570 [00:29<00:01, 351.86it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9978/10570 [00:29<00:01, 345.27it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 10013/10570 [00:29<00:01, 345.64it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 10050/10570 [00:29<00:01, 350.03it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 10086/10570 [00:29<00:01, 346.70it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10121/10570 [00:29<00:01, 347.32it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10157/10570 [00:29<00:01, 349.08it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10192/10570 [00:29<00:01, 338.76it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10228/10570 [00:30<00:00, 344.31it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10263/10570 [00:30<00:00, 343.09it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10299/10570 [00:30<00:00, 347.11it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10334/10570 [00:30<00:00, 346.43it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10369/10570 [00:30<00:00, 345.38it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10404/10570 [00:30<00:00, 341.70it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10439/10570 [00:30<00:00, 342.48it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10474/10570 [00:30<00:00, 330.90it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10511/10570 [00:30<00:00, 339.17it/s]#033[A#033[A\n",
      "\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 10547/10570 [00:30<00:00, 345.01it/s]#033[A#033[A#015100%|ââââââââââ| 10570/10570 [00:31<00:00, 340.64it/s]\u001b[0m\n",
      "\u001b[34m01/14/2021 16:05:16 - INFO - nn_pruning.examples.question_answering.qa_utils -   Saving predictions to /opt/ml/model/checkpoint-500/predictions.json.\u001b[0m\n",
      "\u001b[34m01/14/2021 16:05:16 - INFO - nn_pruning.examples.question_answering.qa_utils -   Saving nbest_preds to /opt/ml/model/checkpoint-500/nbest_predictions.json.\u001b[0m\n",
      "\u001b[34m01/14/2021 16:05:22 - INFO - /opt/conda/lib/python3.6/site-packages/datasets/metric.py -   Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m#015                                                 #015\u001b[0m\n",
      "\u001b[34m#015                                                   #015#033[A#015 90%|âââââââââ | 500/554 [12:17<00:32,  1.66it/s]\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1348/1348 [03:39<00:00,  7.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                                   #033[A01/14/2021 16:05:22 - INFO - nn_pruning.examples.question_answering.qa_train -   ***** Eval results *****\u001b[0m\n",
      "\u001b[34m01/14/2021 16:05:22 - INFO - nn_pruning.examples.question_answering.qa_train -     exact_match = 14.3519394512772\u001b[0m\n",
      "\u001b[34m01/14/2021 16:05:22 - INFO - nn_pruning.examples.question_answering.qa_train -     f1 = 26.77266717929784\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 501/554 [12:18<58:36, 66.36s/it]#015 91%|âââââââââ | 502/554 [12:19<40:24, 46.63s/it]#015 91%|âââââââââ | 503/554 [12:19<27:53, 32.82s/it]#015 91%|âââââââââ | 504/554 [12:20<19:17, 23.15s/it]#015 91%|âââââââââ | 505/554 [12:20<13:22, 16.38s/it]#015 91%|ââââââââââ| 506/554 [12:21<09:19, 11.65s/it]#015 92%|ââââââââââ| 507/554 [12:22<06:31,  8.33s/it]#015 92%|ââââââââââ| 508/554 [12:22<04:36,  6.01s/it]#015 92%|ââââââââââ| 509/554 [12:23<03:17,  4.39s/it]#015 92%|ââââââââââ| 510/554 [12:23<02:22,  3.25s/it]#015 92%|ââââââââââ| 511/554 [12:24<01:45,  2.45s/it]#015 92%|ââââââââââ| 512/554 [12:25<01:19,  1.90s/it]#015 93%|ââââââââââ| 513/554 [12:25<01:01,  1.51s/it]#015 93%|ââââââââââ| 514/554 [12:26<00:49,  1.23s/it]#015 93%|ââââââââââ| 515/554 [12:26<00:40,  1.04s/it]#015 93%|ââââââââââ| 516/554 [12:27<00:34,  1.10it/s]#015 93%|ââââââââââ| 517/554 [12:28<00:30,  1.23it/s]#015 94%|ââââââââââ| 518/554 [12:28<00:27,  1.33it/s]#015 94%|ââââââââââ| 519/554 [12:29<00:24,  1.42it/s]#015 94%|ââââââââââ| 520/554 [12:29<00:22,  1.49it/s]#015 94%|ââââââââââ| 521/554 [12:30<00:21,  1.54it/s]#015 94%|ââââââââââ| 522/554 [12:31<00:20,  1.58it/s]#015 94%|ââââââââââ| 523/554 [12:31<00:19,  1.60it/s]#015 95%|ââââââââââ| 524/554 [12:32<00:18,  1.62it/s]#015 95%|ââââââââââ| 525/554 [12:32<00:17,  1.64it/s]#015 95%|ââââââââââ| 526/554 [12:33<00:16,  1.65it/s]#015 95%|ââââââââââ| 527/554 [12:34<00:16,  1.66it/s]#015 95%|ââââââââââ| 528/554 [12:34<00:15,  1.66it/s]#015 95%|ââââââââââ| 529/554 [12:35<00:15,  1.67it/s]#015 96%|ââââââââââ| 530/554 [12:35<00:14,  1.67it/s]#015 96%|ââââââââââ| 531/554 [12:36<00:13,  1.67it/s]#015 96%|ââââââââââ| 532/554 [12:37<00:13,  1.67it/s]#015 96%|ââââââââââ| 533/554 [12:37<00:12,  1.67it/s]#015 96%|ââââââââââ| 534/554 [12:38<00:11,  1.67it/s]#015 97%|ââââââââââ| 535/554 [12:38<00:11,  1.67it/s]#015 97%|ââââââââââ| 536/554 [12:39<00:10,  1.67it/s]#015 97%|ââââââââââ| 537/554 [12:40<00:10,  1.67it/s]#015 97%|ââââââââââ| 538/554 [12:40<00:09,  1.67it/s]#015 97%|ââââââââââ| 539/554 [12:41<00:08,  1.67it/s]#015 97%|ââââââââââ| 540/554 [12:41<00:08,  1.67it/s]#015 98%|ââââââââââ| 541/554 [12:42<00:07,  1.67it/s]#015 98%|ââââââââââ| 542/554 [12:43<00:07,  1.67it/s]#015 98%|ââââââââââ| 543/554 [12:43<00:06,  1.67it/s]#015 98%|ââââââââââ| 544/554 [12:44<00:05,  1.67it/s]#015 98%|ââââââââââ| 545/554 [12:44<00:05,  1.67it/s]#015 99%|ââââââââââ| 546/554 [12:45<00:04,  1.67it/s]#015 99%|ââââââââââ| 547/554 [12:46<00:04,  1.67it/s]#015 99%|ââââââââââ| 548/554 [12:46<00:03,  1.67it/s]#015 99%|ââââââââââ| 549/554 [12:47<00:02,  1.67it/s]#015 99%|ââââââââââ| 550/554 [12:47<00:02,  1.67it/s]#015 99%|ââââââââââ| 551/554 [12:48<00:01,  1.67it/s]#015100%|ââââââââââ| 552/554 [12:49<00:01,  1.67it/s]#015100%|ââââââââââ| 553/554 [12:49<00:00,  1.67it/s]#015100%|ââââââââââ| 554/554 [12:50<00:00,  1.67it/s][INFO|trainer.py:862] 2021-01-14 16:05:54,821 >> \n",
      "\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m#015                                                 #015#015100%|ââââââââââ| 554/554 [12:50<00:00,  1.67it/s]#015100%|ââââââââââ| 554/554 [12:50<00:00,  1.39s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1226] 2021-01-14 16:05:54,822 >> Saving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:289] 2021-01-14 16:05:54,825 >> Configuration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:814] 2021-01-14 16:05:55,662 >> Model weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m01/14/2021 16:05:55 - INFO - nn_pruning.examples.xp -   *** Evaluate ***\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:388] 2021-01-14 16:05:55,701 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1412] 2021-01-14 16:05:55,702 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1413] 2021-01-14 16:05:55,702 >>   Num examples = 10784\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1414] 2021-01-14 16:05:55,702 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1348 [00:00<?, ?it/s]#015  0%|          | 2/1348 [00:00<01:24, 15.87it/s]#015  0%|          | 3/1348 [00:00<01:50, 12.21it/s]#015  0%|          | 4/1348 [00:00<02:07, 10.51it/s]#015  0%|          | 5/1348 [00:00<02:20,  9.59it/s]#015  0%|          | 6/1348 [00:00<02:28,  9.05it/s]#015  1%|          | 7/1348 [00:00<02:34,  8.68it/s]#015  1%|          | 8/1348 [00:00<02:37,  8.48it/s]#015  1%|          | 9/1348 [00:01<02:40,  8.36it/s]#015  1%|          | 10/1348 [00:01<02:41,  8.27it/s]#015  1%|          | 11/1348 [00:01<02:42,  8.20it/s]#015  1%|          | 12/1348 [00:01<02:43,  8.15it/s]#015  1%|          | 13/1348 [00:01<02:44,  8.13it/s]#015  1%|          | 14/1348 [00:01<02:44,  8.12it/s]#015  1%|          | 15/1348 [00:01<02:44,  8.10it/s]#015  1%|          | 16/1348 [00:01<02:44,  8.08it/s]#015  1%|â         | 17/1348 [00:01<02:45,  8.02it/s]#015  1%|â         | 18/1348 [00:02<02:45,  8.01it/s]#015  1%|â         | 19/1348 [00:02<02:45,  8.01it/s]#015  1%|â         | 20/1348 [00:02<02:45,  8.02it/s]#015  2%|â         | 21/1348 [00:02<02:45,  8.03it/s]#015  2%|â         | 22/1348 [00:02<02:44,  8.04it/s]#015  2%|â         | 23/1348 [00:02<02:45,  8.03it/s]#015  2%|â         | 24/1348 [00:02<02:46,  7.97it/s]#015  2%|â         | 25/1348 [00:02<02:45,  7.97it/s]#015  2%|â         | 26/1348 [00:03<02:46,  7.96it/s]#015  2%|â         | 27/1348 [00:03<02:46,  7.94it/s]#015  2%|â         | 28/1348 [00:03<02:47,  7.90it/s]#015  2%|â         | 29/1348 [00:03<02:47,  7.86it/s]#015  2%|â         | 30/1348 [00:03<02:47,  7.86it/s]#015  2%|â         | 31/1348 [00:03<02:47,  7.86it/s]#015  2%|â         | 32/1348 [00:03<02:49,  7.79it/s]#015  2%|â         | 33/1348 [00:04<02:48,  7.80it/s]#015  3%|â         | 34/1348 [00:04<02:48,  7.80it/s]#015  3%|â         | 35/1348 [00:04<02:48,  7.79it/s]#015  3%|â         | 36/1348 [00:04<02:48,  7.78it/s]#015  3%|â         | 37/1348 [00:04<02:47,  7.81it/s]#015  3%|â         | 38/1348 [00:04<02:47,  7.83it/s]#015  3%|â         | 39/1348 [00:04<02:47,  7.84it/s]#015  3%|â         | 40/1348 [00:04<02:46,  7.88it/s]#015  3%|â         | 41/1348 [00:05<02:45,  7.91it/s]#015  3%|â         | 42/1348 [00:05<02:44,  7.96it/s]#015  3%|â         | 43/1348 [00:05<02:43,  7.99it/s]#015  3%|â         | 44/1348 [00:05<02:42,  8.00it/s]#015  3%|â         | 45/1348 [00:05<02:42,  8.02it/s]#015  3%|â         | 46/1348 [00:05<02:42,  8.04it/s]#015  3%|â         | 47/1348 [00:05<02:41,  8.03it/s]#015  4%|â         | 48/1348 [00:05<02:42,  7.98it/s]#015  4%|â         | 49/1348 [00:06<02:42,  7.99it/s]#015  4%|â         | 50/1348 [00:06<02:43,  7.92it/s]#015  4%|â         | 51/1348 [00:06<02:44,  7.87it/s]#015  4%|â         | 52/1348 [00:06<02:44,  7.88it/s]#015  4%|â         | 53/1348 [00:06<02:44,  7.88it/s]#015  4%|â         | 54/1348 [00:06<02:44,  7.87it/s]#015  4%|â         | 55/1348 [00:06<02:43,  7.91it/s]#015  4%|â         | 56/1348 [00:06<02:43,  7.92it/s]#015  4%|â         | 57/1348 [00:07<02:42,  7.95it/s]#015  4%|â         | 58/1348 [00:07<02:42,  7.95it/s]#015  4%|â         | 59/1348 [00:07<02:41,  7.96it/s]#015  4%|â         | 60/1348 [00:07<02:41,  7.98it/s]#015  5%|â         | 61/1348 [00:07<02:41,  7.98it/s]#015  5%|â         | 62/1348 [00:07<02:40,  7.99it/s]#015  5%|â         | 63/1348 [00:07<02:40,  8.00it/s]#015  5%|â         | 64/1348 [00:07<02:40,  7.99it/s]#015  5%|â         | 65/1348 [00:08<02:40,  8.01it/s]#015  5%|â         | 66/1348 [00:08<02:39,  8.02it/s]#015  5%|â         | 67/1348 [00:08<02:39,  8.04it/s]#015  5%|â         | 68/1348 [00:08<02:39,  8.05it/s]#015  5%|â         | 69/1348 [00:08<02:38,  8.05it/s]#015  5%|â         | 70/1348 [00:08<02:39,  8.04it/s]#015  5%|â         | 71/1348 [00:08<02:39,  8.02it/s]#015  5%|â         | 72/1348 [00:08<02:40,  7.97it/s]#015  5%|â         | 73/1348 [00:09<02:40,  7.97it/s]#015  5%|â         | 74/1348 [00:09<02:39,  7.99it/s]#015  6%|â         | 75/1348 [00:09<02:38,  8.01it/s]#015  6%|â         | 76/1348 [00:09<02:39,  8.00it/s]#015  6%|â         | 77/1348 [00:09<02:40,  7.93it/s]#015  6%|â         | 78/1348 [00:09<02:40,  7.94it/s]#015  6%|â         | 79/1348 [00:09<02:39,  7.96it/s]#015  6%|â         | 80/1348 [00:09<02:39,  7.95it/s]#015  6%|â         | 81/1348 [00:10<02:38,  7.99it/s]#015  6%|â         | 82/1348 [00:10<02:38,  8.00it/s]#015  6%|â         | 83/1348 [00:10<02:38,  7.96it/s]#015  6%|â         | 84/1348 [00:10<02:38,  7.99it/s]#015  6%|â         | 85/1348 [00:10<02:37,  8.00it/s]#015  6%|â         | 86/1348 [00:10<02:37,  8.03it/s]#015  6%|â         | 87/1348 [00:10<02:36,  8.05it/s]#015  7%|â         | 88/1348 [00:10<02:37,  8.02it/s]#015  7%|â         | 89/1348 [00:11<02:37,  8.01it/s]#015  7%|â         | 90/1348 [00:11<02:37,  8.00it/s]#015  7%|â         | 91/1348 [00:11<02:37,  7.99it/s]#015  7%|â         | 92/1348 [00:11<02:37,  7.99it/s]#015  7%|â         | 93/1348 [00:11<02:37,  7.97it/s]#015  7%|â         | 94/1348 [00:11<02:37,  7.97it/s]#015  7%|â         | 95/1348 [00:11<02:37,  7.97it/s]#015  7%|â         | 96/1348 [00:11<02:37,  7.94it/s]#015  7%|â         | 97/1348 [00:12<02:37,  7.93it/s]#015  7%|â         | 98/1348 [00:12<02:37,  7.96it/s]#015  7%|â         | 99/1348 [00:12<02:37,  7.95it/s]#015  7%|â         | 100/1348 [00:12<02:37,  7.94it/s]#015  7%|â         | 101/1348 [00:12<02:37,  7.91it/s]#015  8%|â         | 102/1348 [00:12<02:37,  7.89it/s]#015  8%|â         | 103/1348 [00:12<02:38,  7.86it/s]#015  8%|â         | 104/1348 [00:12<02:39,  7.82it/s]#015  8%|â         | 105/1348 [00:13<02:38,  7.82it/s]#015  8%|â         | 106/1348 [00:13<02:37,  7.86it/s]#015  8%|â         | 107/1348 [00:13<02:37,  7.90it/s]#015  8%|â         | 108/1348 [00:13<02:36,  7.93it/s]#015  8%|â         | 109/1348 [00:13<02:35,  7.95it/s]#015  8%|â         | 110/1348 [00:13<02:35,  7.97it/s]#015  8%|â         | 111/1348 [00:13<02:35,  7.98it/s]#015  8%|â         | 112/1348 [00:13<02:35,  7.97it/s]#015  8%|â         | 113/1348 [00:14<02:34,  7.98it/s]#015  8%|â         | 114/1348 [00:14<02:34,  7.99it/s]#015  9%|â         | 115/1348 [00:14<02:34,  7.99it/s]#015  9%|â         | 116/1348 [00:14<02:35,  7.94it/s]#015  9%|â         | 117/1348 [00:14<02:35,  7.93it/s]#015  9%|â         | 118/1348 [00:14<02:35,  7.93it/s]#015  9%|â         | 119/1348 [00:14<02:34,  7.94it/s]#015  9%|â         | 120/1348 [00:14<02:34,  7.92it/s]#015  9%|â         | 121/1348 [00:15<02:34,  7.93it/s]#015  9%|â         | 122/1348 [00:15<02:34,  7.95it/s]#015  9%|â         | 123/1348 [00:15<02:34,  7.94it/s]#015  9%|â         | 124/1348 [00:15<02:34,  7.94it/s]#015  9%|â         | 125/1348 [00:15<02:33,  7.95it/s]#015  9%|â         | 126/1348 [00:15<02:33,  7.94it/s]#015  9%|â         | 127/1348 [00:15<02:33,  7.95it/s]#015  9%|â         | 128/1348 [00:15<02:34,  7.91it/s]#015 10%|â         | 129/1348 [00:16<02:34,  7.90it/s]#015 10%|â         | 130/1348 [00:16<02:33,  7.91it/s]#015 10%|â         | 131/1348 [00:16<02:33,  7.92it/s]#015 10%|â         | 132/1348 [00:16<02:33,  7.91it/s]#015 10%|â         | 133/1348 [00:16<02:33,  7.92it/s]#015 10%|â         | 134/1348 [00:16<02:32,  7.94it/s]#015 10%|â         | 135/1348 [00:16<02:32,  7.95it/s]#015 10%|â         | 136/1348 [00:16<02:33,  7.92it/s]#015 10%|â         | 137/1348 [00:17<02:32,  7.93it/s]#015 10%|â         | 138/1348 [00:17<02:32,  7.94it/s]#015 10%|â         | 139/1348 [00:17<02:32,  7.95it/s]#015 10%|â         | 140/1348 [00:17<02:32,  7.93it/s]#015 10%|â         | 141/1348 [00:17<02:31,  7.95it/s]#015 11%|â         | 142/1348 [00:17<02:31,  7.97it/s]#015 11%|â         | 143/1348 [00:17<02:31,  7.96it/s]#015 11%|â         | 144/1348 [00:17<02:31,  7.95it/s]#015 11%|â         | 145/1348 [00:18<02:30,  7.97it/s]#015 11%|â         | 146/1348 [00:18<02:30,  7.97it/s]#015 11%|â         | 147/1348 [00:18<02:30,  7.99it/s]#015 11%|â         | 148/1348 [00:18<02:29,  8.00it/s]#015 11%|â         | 149/1348 [00:18<02:29,  8.01it/s]#015 11%|â         | 150/1348 [00:18<02:29,  8.03it/s]#015 11%|â         | 151/1348 [00:18<02:29,  8.03it/s]#015 11%|ââ        | 152/1348 [00:18<02:29,  8.00it/s]#015 11%|ââ        | 153/1348 [00:19<02:29,  8.00it/s]#015 11%|ââ        | 154/1348 [00:19<02:29,  7.99it/s]#015 11%|ââ        | 155/1348 [00:19<02:29,  7.99it/s]#015 12%|ââ        | 156/1348 [00:19<02:28,  8.01it/s]#015 12%|ââ        | 157/1348 [00:19<02:28,  8.03it/s]#015 12%|ââ        | 158/1348 [00:19<02:28,  8.04it/s]#015 12%|ââ        | 159/1348 [00:19<02:28,  8.03it/s]#015 12%|ââ        | 160/1348 [00:19<02:30,  7.91it/s]#015 12%|ââ        | 161/1348 [00:20<02:29,  7.92it/s]#015 12%|ââ        | 162/1348 [00:20<02:29,  7.95it/s]#015 12%|ââ        | 163/1348 [00:20<02:28,  7.98it/s]#015 12%|ââ        | 164/1348 [00:20<02:28,  8.00it/s]#015 12%|ââ        | 165/1348 [00:20<02:27,  8.01it/s]#015 12%|ââ        | 166/1348 [00:20<02:27,  8.02it/s]#015 12%|ââ        | 167/1348 [00:20<02:27,  8.01it/s]#015 12%|ââ        | 168/1348 [00:20<02:27,  8.02it/s]#015 13%|ââ        | 169/1348 [00:21<02:28,  7.96it/s]#015 13%|ââ        | 170/1348 [00:21<02:27,  7.97it/s]#015 13%|ââ        | 171/1348 [00:21<02:27,  7.98it/s]#015 13%|ââ        | 172/1348 [00:21<02:27,  7.98it/s]#015 13%|ââ        | 173/1348 [00:21<02:26,  8.00it/s]#015 13%|ââ        | 174/1348 [00:21<02:26,  8.00it/s]#015 13%|ââ        | 175/1348 [00:21<02:27,  7.96it/s]#015 13%|ââ        | 176/1348 [00:21<02:27,  7.96it/s]#015 13%|ââ        | 177/1348 [00:22<02:28,  7.91it/s]#015 13%|ââ        | 178/1348 [00:22<02:28,  7.90it/s]#015 13%|ââ        | 179/1348 [00:22<02:27,  7.93it/s]#015 13%|ââ        | 180/1348 [00:22<02:26,  7.98it/s]#015 13%|ââ        | 181/1348 [00:22<02:26,  7.95it/s]#015 14%|ââ        | 182/1348 [00:22<02:26,  7.96it/s]#015 14%|ââ        | 183/1348 [00:22<02:25,  7.98it/s]#015 14%|ââ        | 184/1348 [00:22<02:25,  8.01it/s]#015 14%|ââ        | 185/1348 [00:23<02:25,  7.99it/s]#015 14%|ââ        | 186/1348 [00:23<02:25,  7.97it/s]#015 14%|ââ        | 187/1348 [00:23<02:25,  7.98it/s]#015 14%|ââ        | 188/1348 [00:23<02:25,  8.00it/s]#015 14%|ââ        | 189/1348 [00:23<02:25,  7.99it/s]#015 14%|ââ        | 190/1348 [00:23<02:24,  8.04it/s]#015 14%|ââ        | 191/1348 [00:23<02:24,  8.03it/s]#015 14%|ââ        | 192/1348 [00:23<02:24,  8.02it/s]#015 14%|ââ        | 193/1348 [00:24<02:24,  7.99it/s]#015 14%|ââ        | 194/1348 [00:24<02:24,  7.99it/s]#015 14%|ââ        | 195/1348 [00:24<02:23,  8.01it/s]#015 15%|ââ        | 196/1348 [00:24<02:23,  8.02it/s]#015 15%|ââ        | 197/1348 [00:24<02:23,  8.01it/s]#015 15%|ââ        | 198/1348 [00:24<02:23,  8.03it/s]#015 15%|ââ        | 199/1348 [00:24<02:23,  8.02it/s]#015 15%|ââ        | 200/1348 [00:24<02:23,  8.01it/s]#015 15%|ââ        | 201/1348 [00:25<02:23,  7.97it/s]#015 15%|ââ        | 202/1348 [00:25<02:23,  7.98it/s]#015 15%|ââ        | 203/1348 [00:25<02:23,  8.00it/s]#015 15%|ââ        | 204/1348 [00:25<02:22,  8.02it/s]#015 15%|ââ        | 205/1348 [00:25<02:22,  8.01it/s]#015 15%|ââ        | 206/1348 [00:25<02:22,  7.99it/s]#015 15%|ââ        | 207/1348 [00:25<02:22,  7.99it/s]#015 15%|ââ        | 208/1348 [00:25<02:22,  8.00it/s]#015 16%|ââ        | 209/1348 [00:26<02:22,  7.99it/s]#015 16%|ââ        | 210/1348 [00:26<02:21,  8.02it/s]#015 16%|ââ        | 211/1348 [00:26<02:21,  8.03it/s]#015 16%|ââ        | 212/1348 [00:26<02:21,  8.06it/s]#015 16%|ââ        | 213/1348 [00:26<02:20,  8.07it/s]#015 16%|ââ        | 214/1348 [00:26<02:20,  8.05it/s]#015 16%|ââ        | 215/1348 [00:26<02:21,  8.03it/s]#015 16%|ââ        | 216/1348 [00:26<02:21,  8.02it/s]#015 16%|ââ        | 217/1348 [00:27<02:21,  7.99it/s]#015 16%|ââ        | 218/1348 [00:27<02:21,  8.01it/s]#015 16%|ââ        | 219/1348 [00:27<02:21,  8.00it/s]#015 16%|ââ        | 220/1348 [00:27<02:21,  7.97it/s]#015 16%|ââ        | 221/1348 [00:27<02:21,  7.99it/s]#015 16%|ââ        | 222/1348 [00:27<02:20,  7.99it/s]#015 17%|ââ        | 223/1348 [00:27<02:21,  7.98it/s]#015 17%|ââ        | 224/1348 [00:27<02:21,  7.95it/s]#015 17%|ââ        | 225/1348 [00:28<02:21,  7.94it/s]#015 17%|ââ        | 226/1348 [00:28<02:21,  7.96it/s]#015 17%|ââ        | 227/1348 [00:28<02:20,  7.97it/s]#015 17%|ââ        | 228/1348 [00:28<02:20,  7.98it/s]#015 17%|ââ        | 229/1348 [00:28<02:20,  7.99it/s]#015 17%|ââ        | 230/1348 [00:28<02:20,  7.99it/s]#015 17%|ââ        | 231/1348 [00:28<02:19,  7.99it/s]#015 17%|ââ        | 232/1348 [00:28<02:19,  7.99it/s]#015 17%|ââ        | 233/1348 [00:29<02:20,  7.95it/s]#015 17%|ââ        | 234/1348 [00:29<02:19,  7.99it/s]#015 17%|ââ        | 235/1348 [00:29<02:19,  7.97it/s]#015 18%|ââ        | 236/1348 [00:29<02:19,  8.00it/s]#015 18%|ââ        | 237/1348 [00:29<02:18,  8.01it/s]#015 18%|ââ        | 238/1348 [00:29<02:18,  8.02it/s]#015 18%|ââ        | 239/1348 [00:29<02:18,  8.03it/s]#015 18%|ââ        | 240/1348 [00:29<02:17,  8.06it/s]#015 18%|ââ        | 241/1348 [00:30<02:17,  8.03it/s]#015 18%|ââ        | 242/1348 [00:30<02:17,  8.03it/s]#015 18%|ââ        | 243/1348 [00:30<02:17,  8.03it/s]#015 18%|ââ        | 244/1348 [00:30<02:17,  8.03it/s]#015 18%|ââ        | 245/1348 [00:30<02:17,  8.00it/s]#015 18%|ââ        | 246/1348 [00:30<02:17,  8.01it/s]#015 18%|ââ        | 247/1348 [00:30<02:17,  8.03it/s]#015 18%|ââ        | 248/1348 [00:30<02:16,  8.04it/s]#015 18%|ââ        | 249/1348 [00:31<02:16,  8.03it/s]#015 19%|ââ        | 250/1348 [00:31<02:17,  7.98it/s]#015 19%|ââ        | 251/1348 [00:31<02:24,  7.58it/s]#015 19%|ââ        | 252/1348 [00:31<02:22,  7.70it/s]#015 19%|ââ        | 253/1348 [00:31<02:20,  7.78it/s]#015 19%|ââ        | 254/1348 [00:31<02:19,  7.85it/s]#015 19%|ââ        | 255/1348 [00:31<02:18,  7.90it/s]#015 19%|ââ        | 256/1348 [00:32<02:23,  7.61it/s]#015 19%|ââ        | 257/1348 [00:32<02:26,  7.46it/s]#015 19%|ââ        | 258/1348 [00:32<02:23,  7.60it/s]#015 19%|ââ        | 259/1348 [00:32<02:20,  7.73it/s]#015 19%|ââ        | 260/1348 [00:32<02:19,  7.81it/s]#015 19%|ââ        | 261/1348 [00:32<02:18,  7.86it/s]#015 19%|ââ        | 262/1348 [00:32<02:17,  7.90it/s]#015 20%|ââ        | 263/1348 [00:32<02:17,  7.90it/s]#015 20%|ââ        | 264/1348 [00:33<02:18,  7.85it/s]#015 20%|ââ        | 265/1348 [00:33<02:17,  7.89it/s]#015 20%|ââ        | 266/1348 [00:33<02:16,  7.92it/s]#015 20%|ââ        | 267/1348 [00:33<02:15,  7.96it/s]#015 20%|ââ        | 268/1348 [00:33<02:16,  7.93it/s]#015 20%|ââ        | 269/1348 [00:33<02:16,  7.90it/s]#015 20%|ââ        | 270/1348 [00:33<02:16,  7.87it/s]#015 20%|ââ        | 271/1348 [00:33<02:16,  7.91it/s]#015 20%|ââ        | 272/1348 [00:34<02:15,  7.94it/s]#015 20%|ââ        | 273/1348 [00:34<02:15,  7.91it/s]#015 20%|ââ        | 274/1348 [00:34<02:15,  7.93it/s]#015 20%|ââ        | 275/1348 [00:34<02:15,  7.93it/s]#015 20%|ââ        | 276/1348 [00:34<02:15,  7.93it/s]#015 21%|ââ        | 277/1348 [00:34<02:15,  7.93it/s]#015 21%|ââ        | 278/1348 [00:34<02:14,  7.98it/s]#015 21%|ââ        | 279/1348 [00:34<02:13,  7.99it/s]#015 21%|ââ        | 280/1348 [00:35<02:13,  7.99it/s]#015 21%|ââ        | 281/1348 [00:35<02:13,  7.98it/s]#015 21%|ââ        | 282/1348 [00:35<02:13,  8.00it/s]#015 21%|ââ        | 283/1348 [00:35<02:12,  8.02it/s]#015 21%|ââ        | 284/1348 [00:35<02:13,  7.99it/s]#015 21%|ââ        | 285/1348 [00:35<02:13,  7.99it/s]#015 21%|ââ        | 286/1348 [00:35<02:13,  7.98it/s]#015 21%|âââ       | 287/1348 [00:35<02:13,  7.96it/s]#015 21%|âââ       | 288/1348 [00:36<02:12,  7.97it/s]#015 21%|âââ       | 289/1348 [00:36<02:12,  7.98it/s]#015 22%|âââ       | 290/1348 [00:36<02:12,  7.99it/s]#015 22%|âââ       | 291/1348 [00:36<02:12,  7.99it/s]#015 22%|âââ       | 292/1348 [00:36<02:12,  7.98it/s]#015 22%|âââ       | 293/1348 [00:36<02:12,  7.98it/s]#015 22%|âââ       | 294/1348 [00:36<02:12,  7.98it/s]#015 22%|âââ       | 295/1348 [00:36<02:11,  8.01it/s]#015 22%|âââ       | 296/1348 [00:37<02:11,  7.99it/s]#015 22%|âââ       | 297/1348 [00:37<02:12,  7.96it/s]#015 22%|âââ       | 298/1348 [00:37<02:12,  7.93it/s]#015 22%|âââ       | 299/1348 [00:37<02:11,  7.97it/s]#015 22%|âââ       | 300/1348 [00:37<02:11,  7.97it/s]#015 22%|âââ       | 301/1348 [00:37<02:11,  7.95it/s]#015 22%|âââ       | 302/1348 [00:37<02:12,  7.92it/s]#015 22%|âââ       | 303/1348 [00:37<02:11,  7.92it/s]#015 23%|âââ       | 304/1348 [00:38<02:13,  7.79it/s]#015 23%|âââ       | 305/1348 [00:38<02:13,  7.80it/s]#015 23%|âââ      \n",
      " | 306/1348 [00:38<02:12,  7.86it/s]#015 23%|âââ       | 307/1348 [00:38<02:11,  7.89it/s]#015 23%|âââ       | 308/1348 [00:38<02:11,  7.92it/s]#015 23%|âââ       | 309/1348 [00:38<02:10,  7.94it/s]#015 23%|âââ       | 310/1348 [00:38<02:11,  7.91it/s]#015 23%|âââ       | 311/1348 [00:38<02:10,  7.92it/s]#015 23%|âââ       | 312/1348 [00:39<02:10,  7.95it/s]#015 23%|âââ       | 313/1348 [00:39<02:10,  7.95it/s]#015 23%|âââ       | 314/1348 [00:39<02:10,  7.91it/s]#015 23%|âââ       | 315/1348 [00:39<02:10,  7.93it/s]#015 23%|âââ       | 316/1348 [00:39<02:09,  7.94it/s]#015 24%|âââ       | 317/1348 [00:39<02:10,  7.87it/s]#015 24%|âââ       | 318/1348 [00:39<02:11,  7.85it/s]#015 24%|âââ       | 319/1348 [00:39<02:10,  7.88it/s]#015 24%|âââ       | 320/1348 [00:40<02:10,  7.89it/s]#015 24%|âââ       | 321/1348 [00:40<02:09,  7.92it/s]#015 24%|âââ       | 322/1348 [00:40<02:10,  7.85it/s]#015 24%|âââ       | 323/1348 [00:40<02:10,  7.84it/s]#015 24%|âââ       | 324/1348 [00:40<02:10,  7.87it/s]#015 24%|âââ       | 325/1348 [00:40<02:10,  7.87it/s]#015 24%|âââ       | 326/1348 [00:40<02:09,  7.87it/s]#015 24%|âââ       | 327/1348 [00:40<02:08,  7.92it/s]#015 24%|âââ       | 328/1348 [00:41<02:08,  7.94it/s]#015 24%|âââ       | 329/1348 [00:41<02:08,  7.96it/s]#015 24%|âââ       | 330/1348 [00:41<02:08,  7.92it/s]#015 25%|âââ       | 331/1348 [00:41<02:07,  7.95it/s]#015 25%|âââ       | 332/1348 [00:41<02:07,  7.97it/s]#015 25%|âââ       | 333/1348 [00:41<02:06,  8.00it/s]#015 25%|âââ       | 334/1348 [00:41<02:06,  8.02it/s]#015 25%|âââ       | 335/1348 [00:41<02:06,  8.02it/s]#015 25%|âââ       | 336/1348 [00:42<02:05,  8.03it/s]#015 25%|âââ       | 337/1348 [00:42<02:05,  8.04it/s]#015 25%|âââ       | 338/1348 [00:42<02:06,  7.98it/s]#015 25%|âââ       | 339/1348 [00:42<02:07,  7.94it/s]#015 25%|âââ       | 340/1348 [00:42<02:06,  7.94it/s]#015 25%|âââ       | 341/1348 [00:42<02:06,  7.97it/s]#015 25%|âââ       | 342/1348 [00:42<02:06,  7.97it/s]#015 25%|âââ       | 343/1348 [00:42<02:06,  7.96it/s]#015 26%|âââ       | 344/1348 [00:43<02:07,  7.89it/s]#015 26%|âââ       | 345/1348 [00:43<02:06,  7.93it/s]#015 26%|âââ       | 346/1348 [00:43<02:06,  7.94it/s]#015 26%|âââ       | 347/1348 [00:43<02:05,  7.95it/s]#015 26%|âââ       | 348/1348 [00:43<02:05,  7.98it/s]#015 26%|âââ       | 349/1348 [00:43<02:04,  8.01it/s]#015 26%|âââ       | 350/1348 [00:43<02:04,  8.04it/s]#015 26%|âââ       | 351/1348 [00:43<02:03,  8.05it/s]#015 26%|âââ       | 352/1348 [00:44<02:03,  8.06it/s]#015 26%|âââ       | 353/1348 [00:44<02:03,  8.04it/s]#015 26%|âââ       | 354/1348 [00:44<02:03,  8.02it/s]#015 26%|âââ       | 355/1348 [00:44<02:03,  8.05it/s]#015 26%|âââ       | 356/1348 [00:44<02:03,  8.05it/s]#015 26%|âââ       | 357/1348 [00:44<02:03,  8.02it/s]#015 27%|âââ       | 358/1348 [00:44<02:03,  8.00it/s]#015 27%|âââ       | 359/1348 [00:44<02:03,  8.01it/s]#015 27%|âââ       | 360/1348 [00:45<02:03,  7.97it/s]#015 27%|âââ       | 361/1348 [00:45<02:03,  7.98it/s]#015 27%|âââ       | 362/1348 [00:45<02:03,  7.96it/s]#015 27%|âââ       | 363/1348 [00:45<02:03,  7.96it/s]#015 27%|âââ       | 364/1348 [00:45<02:03,  7.96it/s]#015 27%|âââ       | 365/1348 [00:45<02:03,  7.94it/s]#015 27%|âââ       | 366/1348 [00:45<02:03,  7.96it/s]#015 27%|âââ       | 367/1348 [00:46<02:02,  7.98it/s]#015 27%|âââ       | 368/1348 [00:46<02:02,  7.99it/s]#015 27%|âââ       | 369/1348 [00:46<02:02,  7.99it/s]#015 27%|âââ       | 370/1348 [00:46<02:02,  7.97it/s]#015 28%|âââ       | 371/1348 [00:46<02:02,  7.98it/s]#015 28%|âââ       | 372/1348 [00:46<02:02,  7.99it/s]#015 28%|âââ       | 373/1348 [00:46<02:02,  7.97it/s]#015 28%|âââ       | 374/1348 [00:46<02:02,  7.97it/s]#015 28%|âââ       | 375/1348 [00:47<02:01,  7.98it/s]#015 28%|âââ       | 376/1348 [00:47<02:01,  7.98it/s]#015 28%|âââ       | 377/1348 [00:47<02:01,  7.97it/s]#015 28%|âââ       | 378/1348 [00:47<02:01,  7.96it/s]#015 28%|âââ       | 379/1348 [00:47<02:01,  7.98it/s]#015 28%|âââ       | 380/1348 [00:47<02:01,  7.98it/s]#015 28%|âââ       | 381/1348 [00:47<02:01,  7.98it/s]#015 28%|âââ       | 382/1348 [00:47<02:00,  7.99it/s]#015 28%|âââ       | 383/1348 [00:48<02:00,  8.00it/s]#015 28%|âââ       | 384/1348 [00:48<02:01,  7.96it/s]#015 29%|âââ       | 385/1348 [00:48<02:01,  7.94it/s]#015 29%|âââ       | 386/1348 [00:48<02:01,  7.90it/s]#015 29%|âââ       | 387/1348 [00:48<02:01,  7.92it/s]#015 29%|âââ       | 388/1348 [00:48<02:01,  7.91it/s]#015 29%|âââ       | 389/1348 [00:48<02:01,  7.92it/s]#015 29%|âââ       | 390/1348 [00:48<02:00,  7.95it/s]#015 29%|âââ       | 391/1348 [00:49<02:00,  7.96it/s]#015 29%|âââ       | 392/1348 [00:49<01:59,  7.97it/s]#015 29%|âââ       | 393/1348 [00:49<01:59,  7.97it/s]#015 29%|âââ       | 394/1348 [00:49<02:00,  7.94it/s]#015 29%|âââ       | 395/1348 [00:49<01:59,  7.95it/s]#015 29%|âââ       | 396/1348 [00:49<01:59,  7.96it/s]#015 29%|âââ       | 397/1348 [00:49<01:59,  7.95it/s]#015 30%|âââ       | 398/1348 [00:49<01:59,  7.92it/s]#015 30%|âââ       | 399/1348 [00:50<01:59,  7.93it/s]#015 30%|âââ       | 400/1348 [00:50<01:59,  7.95it/s]#015 30%|âââ       | 401/1348 [00:50<01:59,  7.95it/s]#015 30%|âââ       | 402/1348 [00:50<01:59,  7.91it/s]#015 30%|âââ       | 403/1348 [00:50<01:59,  7.91it/s]#015 30%|âââ       | 404/1348 [00:50<01:59,  7.93it/s]#015 30%|âââ       | 405/1348 [00:50<01:58,  7.95it/s]#015 30%|âââ       | 406/1348 [00:50<01:58,  7.95it/s]#015 30%|âââ       | 407/1348 [00:51<01:58,  7.94it/s]#015 30%|âââ       | 408/1348 [00:51<01:58,  7.92it/s]#015 30%|âââ       | 409/1348 [00:51<01:58,  7.93it/s]#015 30%|âââ       | 410/1348 [00:51<01:58,  7.90it/s]#015 30%|âââ       | 411/1348 [00:51<01:58,  7.90it/s]#015 31%|âââ       | 412/1348 [00:51<01:58,  7.93it/s]#015 31%|âââ       | 413/1348 [00:51<01:57,  7.94it/s]#015 31%|âââ       | 414/1348 [00:51<01:57,  7.95it/s]#015 31%|âââ       | 415/1348 [00:52<01:57,  7.93it/s]#015 31%|âââ       | 416/1348 [00:52<01:57,  7.96it/s]#015 31%|âââ       | 417/1348 [00:52<01:56,  7.96it/s]#015 31%|âââ       | 418/1348 [00:52<01:57,  7.94it/s]#015 31%|âââ       | 419/1348 [00:52<01:56,  7.96it/s]#015 31%|âââ       | 420/1348 [00:52<01:56,  7.97it/s]#015 31%|âââ       | 421/1348 [00:52<01:56,  7.94it/s]#015 31%|ââââ      | 422/1348 [00:52<01:56,  7.96it/s]#015 31%|ââââ      | 423/1348 [00:53<01:55,  7.99it/s]#015 31%|ââââ      | 424/1348 [00:53<01:57,  7.83it/s]#015 32%|ââââ      | 425/1348 [00:53<01:57,  7.85it/s]#015 32%|ââââ      | 426/1348 [00:53<01:57,  7.87it/s]#015 32%|ââââ      | 427/1348 [00:53<01:56,  7.90it/s]#015 32%|ââââ      | 428/1348 [00:53<01:55,  7.93it/s]#015 32%|ââââ      | 429/1348 [00:53<01:55,  7.93it/s]#015 32%|ââââ      | 430/1348 [00:53<01:55,  7.96it/s]#015 32%|ââââ      | 431/1348 [00:54<01:55,  7.97it/s]#015 32%|ââââ      | 432/1348 [00:54<01:55,  7.94it/s]#015 32%|ââââ      | 433/1348 [00:54<01:54,  7.96it/s]#015 32%|ââââ      | 434/1348 [00:54<01:55,  7.94it/s]#015 32%|ââââ      | 435/1348 [00:54<01:54,  7.95it/s]#015 32%|ââââ      | 436/1348 [00:54<01:54,  7.96it/s]#015 32%|ââââ      | 437/1348 [00:54<01:54,  7.97it/s]#015 32%|ââââ      | 438/1348 [00:54<01:54,  7.96it/s]#015 33%|ââââ      | 439/1348 [00:55<01:54,  7.95it/s]#015 33%|ââââ      | 440/1348 [00:55<01:54,  7.95it/s]#015 33%|ââââ      | 441/1348 [00:55<01:54,  7.93it/s]#015 33%|ââââ      | 442/1348 [00:55<01:54,  7.92it/s]#015 33%|ââââ      | 443/1348 [00:55<01:54,  7.92it/s]#015 33%|ââââ      | 444/1348 [00:55<01:53,  7.94it/s]#015 33%|ââââ      | 445/1348 [00:55<01:53,  7.96it/s]#015 33%|ââââ      | 446/1348 [00:55<01:53,  7.98it/s]#015 33%|ââââ      | 447/1348 [00:56<01:52,  7.99it/s]#015 33%|ââââ      | 448/1348 [00:56<01:52,  7.98it/s]#015 33%|ââââ      | 449/1348 [00:56<01:52,  7.97it/s]#015 33%|ââââ      | 450/1348 [00:56<01:53,  7.94it/s]#015 33%|ââââ      | 451/1348 [00:56<01:53,  7.92it/s]#015 34%|ââââ      | 452/1348 [00:56<01:53,  7.92it/s]#015 34%|ââââ      | 453/1348 [00:56<01:52,  7.95it/s]#015 34%|ââââ      | 454/1348 [00:56<01:52,  7.94it/s]#015 34%|ââââ      | 455/1348 [00:57<01:52,  7.94it/s]#015 34%|ââââ      | 456/1348 [00:57<01:52,  7.95it/s]#015 34%|ââââ      | 457/1348 [00:57<01:52,  7.95it/s]#015 34%|ââââ      | 458/1348 [00:57<01:51,  7.97it/s]#015 34%|ââââ      | 459/1348 [00:57<01:52,  7.93it/s]#015 34%|ââââ      | 460/1348 [00:57<01:51,  7.94it/s]#015 34%|ââââ      | 461/1348 [00:57<01:51,  7.97it/s]#015 34%|ââââ      | 462/1348 [00:57<01:51,  7.97it/s]#015 34%|ââââ      | 463/1348 [00:58<01:51,  7.96it/s]#015 34%|ââââ      | 464/1348 [00:58<01:51,  7.93it/s]#015 34%|ââââ      | 465/1348 [00:58<01:51,  7.94it/s]#015 35%|ââââ      | 466/1348 [00:58<01:50,  7.95it/s]#015 35%|ââââ      | 467/1348 [00:58<01:52,  7.85it/s]#015 35%|ââââ      | 468/1348 [00:58<01:51,  7.89it/s]#015 35%|ââââ      | 469/1348 [00:58<01:51,  7.92it/s]#015 35%|ââââ      | 470/1348 [00:58<01:50,  7.94it/s]#015 35%|ââââ      | 471/1348 [00:59<01:50,  7.90it/s]#015 35%|ââââ      | 472/1348 [00:59<01:50,  7.90it/s]#015 35%|ââââ      | 473/1348 [00:59<01:50,  7.91it/s]#015 35%|ââââ      | 474/1348 [00:59<01:49,  7.95it/s]#015 35%|ââââ      | 475/1348 [00:59<01:50,  7.91it/s]#015 35%|ââââ      | 476/1348 [00:59<01:49,  7.95it/s]#015 35%|ââââ      | 477/1348 [00:59<01:49,  7.97it/s]#015 35%|ââââ      | 478/1348 [00:59<01:49,  7.97it/s]#015 36%|ââââ      | 479/1348 [01:00<01:49,  7.94it/s]#015 36%|ââââ      | 480/1348 [01:00<01:49,  7.94it/s]#015 36%|ââââ      | 481/1348 [01:00<01:48,  7.96it/s]#015 36%|ââââ      | 482/1348 [01:00<01:48,  7.96it/s]#015 36%|ââââ      | 483/1348 [01:00<01:49,  7.92it/s]#015 36%|ââââ      | 484/1348 [01:00<01:48,  7.95it/s]#015 36%|ââââ      | 485/1348 [01:00<01:48,  7.96it/s]#015 36%|ââââ      | 486/1348 [01:00<01:48,  7.96it/s]#015 36%|ââââ      | 487/1348 [01:01<01:48,  7.96it/s]#015 36%|ââââ      | 488/1348 [01:01<01:47,  7.97it/s]#015 36%|ââââ      | 489/1348 [01:01<01:47,  7.97it/s]#015 36%|ââââ      | 490/1348 [01:01<01:47,  7.98it/s]#015 36%|ââââ      | 491/1348 [01:01<01:48,  7.93it/s]#015 36%|ââââ      | 492/1348 [01:01<01:47,  7.94it/s]#015 37%|ââââ      | 493/1348 [01:01<01:47,  7.96it/s]#015 37%|ââââ      | 494/1348 [01:01<01:47,  7.96it/s]#015 37%|ââââ      | 495/1348 [01:02<01:47,  7.96it/s]#015 37%|ââââ      | 496/1348 [01:02<01:46,  7.97it/s]#015 37%|ââââ      | 497/1348 [01:02<01:46,  7.96it/s]#015 37%|ââââ      | 498/1348 [01:02<01:46,  7.97it/s]#015 37%|ââââ      | 499/1348 [01:02<01:46,  7.94it/s]#015 37%|ââââ      | 500/1348 [01:02<01:46,  7.94it/s]#015 37%|ââââ      | 501/1348 [01:02<01:46,  7.96it/s]#015 37%|ââââ      | 502/1348 [01:02<01:46,  7.98it/s]#015 37%|ââââ      | 503/1348 [01:03<01:45,  7.99it/s]#015 37%|ââââ      | 504/1348 [01:03<01:48,  7.75it/s]#015 37%|ââââ      | 505/1348 [01:03<01:48,  7.80it/s]#015 38%|ââââ      | 506/1348 [01:03<01:47,  7.85it/s]#015 38%|ââââ      | 507/1348 [01:03<01:47,  7.86it/s]#015 38%|ââââ      | 508/1348 [01:03<01:46,  7.89it/s]#015 38%|ââââ      | 509/1348 [01:03<01:46,  7.91it/s]#015 38%|ââââ      | 510/1348 [01:04<01:45,  7.94it/s]#015 38%|ââââ      | 511/1348 [01:04<01:45,  7.95it/s]#015 38%|ââââ      | 512/1348 [01:04<01:45,  7.94it/s]#015 38%|ââââ      | 513/1348 [01:04<01:44,  7.96it/s]#015 38%|ââââ      | 514/1348 [01:04<01:44,  7.97it/s]#015 38%|ââââ      | 515/1348 [01:04<01:44,  7.95it/s]#015 38%|ââââ      | 516/1348 [01:04<01:44,  7.96it/s]#015 38%|ââââ      | 517/1348 [01:04<01:45,  7.90it/s]#015 38%|ââââ      | 518/1348 [01:05<01:45,  7.86it/s]#015 39%|ââââ      | 519/1348 [01:05<01:45,  7.87it/s]#015 39%|ââââ      | 520/1348 [01:05<01:45,  7.88it/s]#015 39%|ââââ      | 521/1348 [01:05<01:48,  7.65it/s]#015 39%|ââââ      | 522/1348 [01:05<01:47,  7.69it/s]#015 39%|ââââ      | 523/1348 [01:05<01:47,  7.69it/s]#015 39%|ââââ      | 524/1348 [01:05<01:46,  7.71it/s]#015 39%|ââââ      | 525/1348 [01:05<01:46,  7.74it/s]#015 39%|ââââ      | 526/1348 [01:06<01:46,  7.73it/s]#015 39%|ââââ      | 527/1348 [01:06<01:46,  7.72it/s]#015 39%|ââââ      | 528/1348 [01:06<01:46,  7.73it/s]#015 39%|ââââ      | 529/1348 [01:06<01:45,  7.73it/s]#015 39%|ââââ      | 530/1348 [01:06<01:46,  7.71it/s]#015 39%|ââââ      | 531/1348 [01:06<01:46,  7.69it/s]#015 39%|ââââ      | 532/1348 [01:06<01:45,  7.74it/s]#015 40%|ââââ      | 533/1348 [01:06<01:44,  7.77it/s]#015 40%|ââââ      | 534/1348 [01:07<01:44,  7.79it/s]#015 40%|ââââ      | 535/1348 [01:07<01:44,  7.79it/s]#015 40%|ââââ      | 536/1348 [01:07<01:44,  7.79it/s]#015 40%|ââââ      | 537/1348 [01:07<01:43,  7.84it/s]#015 40%|ââââ      | 538/1348 [01:07<01:43,  7.85it/s]#015 40%|ââââ      | 539/1348 [01:07<01:42,  7.88it/s]#015 40%|ââââ      | 540/1348 [01:07<01:42,  7.91it/s]#015 40%|ââââ      | 541/1348 [01:07<01:42,  7.89it/s]#015 40%|ââââ      | 542/1348 [01:08<01:42,  7.87it/s]#015 40%|ââââ      | 543/1348 [01:08<01:42,  7.85it/s]#015 40%|ââââ      | 544/1348 [01:08<01:44,  7.68it/s]#015 40%|ââââ      | 545/1348 [01:08<01:44,  7.70it/s]#015 41%|ââââ      | 546/1348 [01:08<01:44,  7.70it/s]#015 41%|ââââ      | 547/1348 [01:08<01:43,  7.72it/s]#015 41%|ââââ      | 548/1348 [01:08<01:43,  7.75it/s]#015 41%|ââââ      | 549/1348 [01:09<01:42,  7.76it/s]#015 41%|ââââ      | 550/1348 [01:09<01:42,  7.76it/s]#015 41%|ââââ      | 551/1348 [01:09<01:42,  7.80it/s]#015 41%|ââââ      | 552/1348 [01:09<01:42,  7.80it/s]#015 41%|ââââ      | 553/1348 [01:09<01:41,  7.81it/s]#015 41%|ââââ      | 554/1348 [01:09<01:42,  7.75it/s]#015 41%|ââââ      | 555/1348 [01:09<01:42,  7.73it/s]#015 41%|ââââ      | 556/1348 [01:09<01:43,  7.65it/s]#015 41%|âââââ     | 557/1348 [01:10<01:43,  7.67it/s]#015 41%|âââââ     | 558/1348 [01:10<01:41,  7.76it/s]#015 41%|âââââ     | 559/1348 [01:10<01:40,  7.83it/s]#015 42%|âââââ     | 560/1348 [01:10<01:39,  7.89it/s]#015 42%|âââââ     | 561/1348 [01:10<01:39,  7.92it/s]#015 42%|âââââ     | 562/1348 [01:10<01:39,  7.88it/s]#015 42%|âââââ     | 563/1348 [01:10<01:39,  7.90it/s]#015 42%|âââââ     | 564/1348 [01:10<01:39,  7.92it/s]#015 42%|âââââ     | 565/1348 [01:11<01:38,  7.93it/s]#015 42%|âââââ     | 566/1348 [01:11<01:38,  7.94it/s]#015 42%|âââââ     | 567/1348 [01:11<01:38,  7.94it/s]#015 42%|âââââ     | 568/1348 [01:11<01:38,  7.94it/s]#015 42%|âââââ     | 569/1348 [01:11<01:37,  7.96it/s]#015 42%|âââââ     | 570/1348 [01:11<01:37,  7.94it/s]#015 42%|âââââ     | 571/1348 [01:11<01:37,  7.96it/s]#015 42%|âââââ     | 572/1348 [01:11<01:37,  7.98it/s]#015 43%|âââââ     | 573/1348 [01:12<01:37,  7.98it/s]#015 43%|âââââ     | 574/1348 [01:12<01:36,  7.99it/s]#015 43%|âââââ     | 575/1348 [01:12<01:36,  8.00it/s]#015 43%|âââââ     | 576/1348 [01:12<01:36,  8.01it/s]#015 43%|âââââ     | 577/1348 [01:12<01:36,  8.01it/s]#015 43%|âââââ     | 578/1348 [01:12<01:36,  7.97it/s]#015 43%|âââââ     | 579/1348 [01:12<01:36,  7.93it/s]#015 43%|âââââ     | 580/1348 [01:12<01:37,  7.90it/s]#015 43%|âââââ     | 581/1348 [01:13<01:37,  7.88it/s]#015 43%|âââââ     | 582/1348 [01:13<01:37,  7.87it/s]#015 43%|âââââ     | 583/1348 [01:13<01:37,  7.84it/s]#015 43%|âââââ     | 584/1348 [01:13<01:38,  7.73it/s]#015 43%|âââââ     | 585/1348 [01:13<01:38,  7.77it/s]#015 43%|âââââ     | 586/1348 [01:13<01:37,  7.79it/\u001b[0m\n",
      "\u001b[34ms]#015 44%|âââââ     | 587/1348 [01:13<01:37,  7.84it/s]#015 44%|âââââ     | 588/1348 [01:13<01:36,  7.87it/s]#015 44%|âââââ     | 589/1348 [01:14<01:36,  7.87it/s]#015 44%|âââââ     | 590/1348 [01:14<01:36,  7.87it/s]#015 44%|âââââ     | 591/1348 [01:14<01:35,  7.90it/s]#015 44%|âââââ     | 592/1348 [01:14<01:35,  7.89it/s]#015 44%|âââââ     | 593/1348 [01:14<01:35,  7.88it/s]#015 44%|âââââ     | 594/1348 [01:14<01:35,  7.87it/s]#015 44%|âââââ     | 595/1348 [01:14<01:35,  7.87it/s]#015 44%|âââââ     | 596/1348 [01:14<01:35,  7.88it/s]#015 44%|âââââ     | 597/1348 [01:15<01:35,  7.90it/s]#015 44%|âââââ     | 598/1348 [01:15<01:34,  7.90it/s]#015 44%|âââââ     | 599/1348 [01:15<01:35,  7.87it/s]#015 45%|âââââ     | 600/1348 [01:15<01:35,  7.85it/s]#015 45%|âââââ     | 601/1348 [01:15<01:35,  7.85it/s]#015 45%|âââââ     | 602/1348 [01:15<01:35,  7.81it/s]#015 45%|âââââ     | 603/1348 [01:15<01:35,  7.82it/s]#015 45%|âââââ     | 604/1348 [01:15<01:34,  7.87it/s]#015 45%|âââââ     | 605/1348 [01:16<01:33,  7.91it/s]#015 45%|âââââ     | 606/1348 [01:16<01:33,  7.94it/s]#015 45%|âââââ     | 607/1348 [01:16<01:33,  7.95it/s]#015 45%|âââââ     | 608/1348 [01:16<01:33,  7.95it/s]#015 45%|âââââ     | 609/1348 [01:16<01:33,  7.95it/s]#015 45%|âââââ     | 610/1348 [01:16<01:32,  7.95it/s]#015 45%|âââââ     | 611/1348 [01:16<01:32,  7.93it/s]#015 45%|âââââ     | 612/1348 [01:17<01:32,  7.93it/s]#015 45%|âââââ     | 613/1348 [01:17<01:33,  7.88it/s]#015 46%|âââââ     | 614/1348 [01:17<01:33,  7.88it/s]#015 46%|âââââ     | 615/1348 [01:17<01:32,  7.88it/s]#015 46%|âââââ     | 616/1348 [01:17<01:32,  7.87it/s]#015 46%|âââââ     | 617/1348 [01:17<01:32,  7.87it/s]#015 46%|âââââ     | 618/1348 [01:17<01:32,  7.87it/s]#015 46%|âââââ     | 619/1348 [01:17<01:32,  7.90it/s]#015 46%|âââââ     | 620/1348 [01:18<01:31,  7.93it/s]#015 46%|âââââ     | 621/1348 [01:18<01:31,  7.94it/s]#015 46%|âââââ     | 622/1348 [01:18<01:31,  7.97it/s]#015 46%|âââââ     | 623/1348 [01:18<01:31,  7.91it/s]#015 46%|âââââ     | 624/1348 [01:18<01:31,  7.93it/s]#015 46%|âââââ     | 625/1348 [01:18<01:31,  7.92it/s]#015 46%|âââââ     | 626/1348 [01:18<01:32,  7.85it/s]#015 47%|âââââ     | 627/1348 [01:18<01:32,  7.83it/s]#015 47%|âââââ     | 628/1348 [01:19<01:31,  7.89it/s]#015 47%|âââââ     | 629/1348 [01:19<01:30,  7.92it/s]#015 47%|âââââ     | 630/1348 [01:19<01:30,  7.93it/s]#015 47%|âââââ     | 631/1348 [01:19<01:30,  7.93it/s]#015 47%|âââââ     | 632/1348 [01:19<01:29,  7.96it/s]#015 47%|âââââ     | 633/1348 [01:19<01:29,  7.97it/s]#015 47%|âââââ     | 634/1348 [01:19<01:29,  7.94it/s]#015 47%|âââââ     | 635/1348 [01:19<01:29,  7.94it/s]#015 47%|âââââ     | 636/1348 [01:20<01:29,  7.95it/s]#015 47%|âââââ     | 637/1348 [01:20<01:29,  7.96it/s]#015 47%|âââââ     | 638/1348 [01:20<01:29,  7.97it/s]#015 47%|âââââ     | 639/1348 [01:20<01:29,  7.95it/s]#015 47%|âââââ     | 640/1348 [01:20<01:29,  7.95it/s]#015 48%|âââââ     | 641/1348 [01:20<01:29,  7.94it/s]#015 48%|âââââ     | 642/1348 [01:20<01:29,  7.91it/s]#015 48%|âââââ     | 643/1348 [01:20<01:28,  7.94it/s]#015 48%|âââââ     | 644/1348 [01:21<01:28,  7.91it/s]#015 48%|âââââ     | 645/1348 [01:21<01:29,  7.87it/s]#015 48%|âââââ     | 646/1348 [01:21<01:29,  7.89it/s]#015 48%|âââââ     | 647/1348 [01:21<01:28,  7.90it/s]#015 48%|âââââ     | 648/1348 [01:21<01:28,  7.92it/s]#015 48%|âââââ     | 649/1348 [01:21<01:28,  7.92it/s]#015 48%|âââââ     | 650/1348 [01:21<01:28,  7.90it/s]#015 48%|âââââ     | 651/1348 [01:21<01:28,  7.92it/s]#015 48%|âââââ     | 652/1348 [01:22<01:27,  7.94it/s]#015 48%|âââââ     | 653/1348 [01:22<01:27,  7.95it/s]#015 49%|âââââ     | 654/1348 [01:22<01:27,  7.93it/s]#015 49%|âââââ     | 655/1348 [01:22<01:27,  7.92it/s]#015 49%|âââââ     | 656/1348 [01:22<01:27,  7.90it/s]#015 49%|âââââ     | 657/1348 [01:22<01:27,  7.93it/s]#015 49%|âââââ     | 658/1348 [01:22<01:27,  7.93it/s]#015 49%|âââââ     | 659/1348 [01:22<01:26,  7.93it/s]#015 49%|âââââ     | 660/1348 [01:23<01:26,  7.94it/s]#015 49%|âââââ     | 661/1348 [01:23<01:26,  7.94it/s]#015 49%|âââââ     | 662/1348 [01:23<01:26,  7.96it/s]#015 49%|âââââ     | 663/1348 [01:23<01:26,  7.89it/s]#015 49%|âââââ     | 664/1348 [01:23<01:26,  7.88it/s]#015 49%|âââââ     | 665/1348 [01:23<01:26,  7.90it/s]#015 49%|âââââ     | 666/1348 [01:23<01:26,  7.89it/s]#015 49%|âââââ     | 667/1348 [01:23<01:26,  7.90it/s]#015 50%|âââââ     | 668/1348 [01:24<01:25,  7.91it/s]#015 50%|âââââ     | 669/1348 [01:24<01:25,  7.92it/s]#015 50%|âââââ     | 670/1348 [01:24<01:25,  7.93it/s]#015 50%|âââââ     | 671/1348 [01:24<01:25,  7.95it/s]#015 50%|âââââ     | 672/1348 [01:24<01:25,  7.93it/s]#015 50%|âââââ     | 673/1348 [01:24<01:24,  7.95it/s]#015 50%|âââââ     | 674/1348 [01:24<01:24,  7.93it/s]#015 50%|âââââ     | 675/1348 [01:24<01:25,  7.91it/s]#015 50%|âââââ     | 676/1348 [01:25<01:25,  7.89it/s]#015 50%|âââââ     | 677/1348 [01:25<01:24,  7.90it/s]#015 50%|âââââ     | 678/1348 [01:25<01:24,  7.93it/s]#015 50%|âââââ     | 679/1348 [01:25<01:24,  7.94it/s]#015 50%|âââââ     | 680/1348 [01:25<01:23,  7.97it/s]#015 51%|âââââ     | 681/1348 [01:25<01:23,  7.97it/s]#015 51%|âââââ     | 682/1348 [01:25<01:23,  7.95it/s]#015 51%|âââââ     | 683/1348 [01:25<01:23,  7.97it/s]#015 51%|âââââ     | 684/1348 [01:26<01:23,  7.97it/s]#015 51%|âââââ     | 685/1348 [01:26<01:23,  7.96it/s]#015 51%|âââââ     | 686/1348 [01:26<01:23,  7.96it/s]#015 51%|âââââ     | 687/1348 [01:26<01:22,  7.97it/s]#015 51%|âââââ     | 688/1348 [01:26<01:22,  7.95it/s]#015 51%|âââââ     | 689/1348 [01:26<01:22,  7.94it/s]#015 51%|âââââ     | 690/1348 [01:26<01:22,  7.94it/s]#015 51%|ââââââ    | 691/1348 [01:26<01:22,  7.93it/s]#015 51%|ââââââ    | 692/1348 [01:27<01:22,  7.94it/s]#015 51%|ââââââ    | 693/1348 [01:27<01:22,  7.95it/s]#015 51%|ââââââ    | 694/1348 [01:27<01:22,  7.96it/s]#015 52%|ââââââ    | 695/1348 [01:27<01:22,  7.96it/s]#015 52%|ââââââ    | 696/1348 [01:27<01:21,  7.96it/s]#015 52%|ââââââ    | 697/1348 [01:27<01:21,  7.95it/s]#015 52%|ââââââ    | 698/1348 [01:27<01:22,  7.91it/s]#015 52%|ââââââ    | 699/1348 [01:27<01:21,  7.93it/s]#015 52%|ââââââ    | 700/1348 [01:28<01:21,  7.94it/s]#015 52%|ââââââ    | 701/1348 [01:28<01:21,  7.90it/s]#015 52%|ââââââ    | 702/1348 [01:28<01:22,  7.87it/s]#015 52%|ââââââ    | 703/1348 [01:28<01:23,  7.74it/s]#015 52%|ââââââ    | 704/1348 [01:28<01:22,  7.77it/s]#015 52%|ââââââ    | 705/1348 [01:28<01:22,  7.82it/s]#015 52%|ââââââ    | 706/1348 [01:28<01:22,  7.79it/s]#015 52%|ââââââ    | 707/1348 [01:29<01:22,  7.81it/s]#015 53%|ââââââ    | 708/1348 [01:29<01:21,  7.86it/s]#015 53%|ââââââ    | 709/1348 [01:29<01:21,  7.87it/s]#015 53%|ââââââ    | 710/1348 [01:29<01:21,  7.87it/s]#015 53%|ââââââ    | 711/1348 [01:29<01:20,  7.87it/s]#015 53%|ââââââ    | 712/1348 [01:29<01:20,  7.88it/s]#015 53%|ââââââ    | 713/1348 [01:29<01:20,  7.89it/s]#015 53%|ââââââ    | 714/1348 [01:29<01:20,  7.90it/s]#015 53%|ââââââ    | 715/1348 [01:30<01:20,  7.88it/s]#015 53%|ââââââ    | 716/1348 [01:30<01:20,  7.88it/s]#015 53%|ââââââ    | 717/1348 [01:30<01:19,  7.90it/s]#015 53%|ââââââ    | 718/1348 [01:30<01:19,  7.92it/s]#015 53%|ââââââ    | 719/1348 [01:30<01:19,  7.92it/s]#015 53%|ââââââ    | 720/1348 [01:30<01:19,  7.92it/s]#015 53%|ââââââ    | 721/1348 [01:30<01:19,  7.93it/s]#015 54%|ââââââ    | 722/1348 [01:30<01:19,  7.88it/s]#015 54%|ââââââ    | 723/1348 [01:31<01:19,  7.87it/s]#015 54%|ââââââ    | 724/1348 [01:31<01:19,  7.86it/s]#015 54%|ââââââ    | 725/1348 [01:31<01:19,  7.88it/s]#015 54%|ââââââ    | 726/1348 [01:31<01:18,  7.88it/s]#015 54%|ââââââ    | 727/1348 [01:31<01:18,  7.91it/s]#015 54%|ââââââ    | 728/1348 [01:31<01:18,  7.91it/s]#015 54%|ââââââ    | 729/1348 [01:31<01:18,  7.88it/s]#015 54%|ââââââ    | 730/1348 [01:31<01:18,  7.89it/s]#015 54%|ââââââ    | 731/1348 [01:32<01:18,  7.91it/s]#015 54%|ââââââ    | 732/1348 [01:32<01:17,  7.92it/s]#015 54%|ââââââ    | 733/1348 [01:32<01:17,  7.94it/s]#015 54%|ââââââ    | 734/1348 [01:32<01:17,  7.95it/s]#015 55%|ââââââ    | 735/1348 [01:32<01:17,  7.96it/s]#015 55%|ââââââ    | 736/1348 [01:32<01:16,  7.96it/s]#015 55%|ââââââ    | 737/1348 [01:32<01:16,  7.97it/s]#015 55%|ââââââ    | 738/1348 [01:32<01:17,  7.91it/s]#015 55%|ââââââ    | 739/1348 [01:33<01:17,  7.90it/s]#015 55%|ââââââ    | 740/1348 [01:33<01:16,  7.91it/s]#015 55%|ââââââ    | 741/1348 [01:33<01:16,  7.92it/s]#015 55%|ââââââ    | 742/1348 [01:33<01:16,  7.93it/s]#015 55%|ââââââ    | 743/1348 [01:33<01:17,  7.85it/s]#015 55%|ââââââ    | 744/1348 [01:33<01:16,  7.87it/s]#015 55%|ââââââ    | 745/1348 [01:33<01:16,  7.89it/s]#015 55%|ââââââ    | 746/1348 [01:33<01:16,  7.85it/s]#015 55%|ââââââ    | 747/1348 [01:34<01:16,  7.85it/s]#015 55%|ââââââ    | 748/1348 [01:34<01:16,  7.88it/s]#015 56%|ââââââ    | 749/1348 [01:34<01:15,  7.90it/s]#015 56%|ââââââ    | 750/1348 [01:34<01:15,  7.94it/s]#015 56%|ââââââ    | 751/1348 [01:34<01:19,  7.53it/s]#015 56%|ââââââ    | 752/1348 [01:34<01:17,  7.65it/s]#015 56%|ââââââ    | 753/1348 [01:34<01:17,  7.70it/s]#015 56%|ââââââ    | 754/1348 [01:34<01:16,  7.73it/s]#015 56%|ââââââ    | 755/1348 [01:35<01:16,  7.79it/s]#015 56%|ââââââ    | 756/1348 [01:35<01:15,  7.84it/s]#015 56%|ââââââ    | 757/1348 [01:35<01:14,  7.89it/s]#015 56%|ââââââ    | 758/1348 [01:35<01:14,  7.92it/s]#015 56%|ââââââ    | 759/1348 [01:35<01:14,  7.92it/s]#015 56%|ââââââ    | 760/1348 [01:35<01:14,  7.92it/s]#015 56%|ââââââ    | 761/1348 [01:35<01:14,  7.92it/s]#015 57%|ââââââ    | 762/1348 [01:35<01:14,  7.88it/s]#015 57%|ââââââ    | 763/1348 [01:36<01:14,  7.90it/s]#015 57%|ââââââ    | 764/1348 [01:36<01:13,  7.93it/s]#015 57%|ââââââ    | 765/1348 [01:36<01:13,  7.94it/s]#015 57%|ââââââ    | 766/1348 [01:36<01:13,  7.96it/s]#015 57%|ââââââ    | 767/1348 [01:36<01:13,  7.95it/s]#015 57%|ââââââ    | 768/1348 [01:36<01:12,  7.96it/s]#015 57%|ââââââ    | 769/1348 [01:36<01:12,  7.97it/s]#015 57%|ââââââ    | 770/1348 [01:36<01:12,  7.93it/s]#015 57%|ââââââ    | 771/1348 [01:37<01:12,  7.92it/s]#015 57%|ââââââ    | 772/1348 [01:37<01:12,  7.91it/s]#015 57%|ââââââ    | 773/1348 [01:37<01:12,  7.90it/s]#015 57%|ââââââ    | 774/1348 [01:37<01:12,  7.93it/s]#015 57%|ââââââ    | 775/1348 [01:37<01:12,  7.95it/s]#015 58%|ââââââ    | 776/1348 [01:37<01:12,  7.93it/s]#015 58%|ââââââ    | 777/1348 [01:37<01:12,  7.92it/s]#015 58%|ââââââ    | 778/1348 [01:38<01:12,  7.89it/s]#015 58%|ââââââ    | 779/1348 [01:38<01:12,  7.88it/s]#015 58%|ââââââ    | 780/1348 [01:38<01:12,  7.87it/s]#015 58%|ââââââ    | 781/1348 [01:38<01:11,  7.89it/s]#015 58%|ââââââ    | 782/1348 [01:38<01:11,  7.91it/s]#015 58%|ââââââ    | 783/1348 [01:38<01:12,  7.75it/s]#015 58%|ââââââ    | 784/1348 [01:38<01:12,  7.79it/s]#015 58%|ââââââ    | 785/1348 [01:38<01:11,  7.83it/s]#015 58%|ââââââ    | 786/1348 [01:39<01:11,  7.82it/s]#015 58%|ââââââ    | 787/1348 [01:39<01:11,  7.86it/s]#015 58%|ââââââ    | 788/1348 [01:39<01:10,  7.89it/s]#015 59%|ââââââ    | 789/1348 [01:39<01:10,  7.93it/s]#015 59%|ââââââ    | 790/1348 [01:39<01:10,  7.96it/s]#015 59%|ââââââ    | 791/1348 [01:39<01:10,  7.94it/s]#015 59%|ââââââ    | 792/1348 [01:39<01:09,  7.96it/s]#015 59%|ââââââ    | 793/1348 [01:39<01:09,  7.96it/s]#015 59%|ââââââ    | 794/1348 [01:40<01:10,  7.86it/s]#015 59%|ââââââ    | 795/1348 [01:40<01:11,  7.75it/s]#015 59%|ââââââ    | 796/1348 [01:40<01:10,  7.81it/s]#015 59%|ââââââ    | 797/1348 [01:40<01:10,  7.83it/s]#015 59%|ââââââ    | 798/1348 [01:40<01:09,  7.87it/s]#015 59%|ââââââ    | 799/1348 [01:40<01:09,  7.90it/s]#015 59%|ââââââ    | 800/1348 [01:40<01:09,  7.90it/s]#015 59%|ââââââ    | 801/1348 [01:40<01:09,  7.88it/s]#015 59%|ââââââ    | 802/1348 [01:41<01:09,  7.87it/s]#015 60%|ââââââ    | 803/1348 [01:41<01:09,  7.88it/s]#015 60%|ââââââ    | 804/1348 [01:41<01:08,  7.89it/s]#015 60%|ââââââ    | 805/1348 [01:41<01:08,  7.89it/s]#015 60%|ââââââ    | 806/1348 [01:41<01:08,  7.92it/s]#015 60%|ââââââ    | 807/1348 [01:41<01:08,  7.94it/s]#015 60%|ââââââ    | 808/1348 [01:41<01:07,  7.97it/s]#015 60%|ââââââ    | 809/1348 [01:41<01:07,  7.96it/s]#015 60%|ââââââ    | 810/1348 [01:42<01:07,  7.95it/s]#015 60%|ââââââ    | 811/1348 [01:42<01:07,  7.96it/s]#015 60%|ââââââ    | 812/1348 [01:42<01:07,  7.96it/s]#015 60%|ââââââ    | 813/1348 [01:42<01:07,  7.94it/s]#015 60%|ââââââ    | 814/1348 [01:42<01:07,  7.94it/s]#015 60%|ââââââ    | 815/1348 [01:42<01:07,  7.95it/s]#015 61%|ââââââ    | 816/1348 [01:42<01:06,  7.96it/s]#015 61%|ââââââ    | 817/1348 [01:42<01:06,  7.95it/s]#015 61%|ââââââ    | 818/1348 [01:43<01:06,  7.94it/s]#015 61%|ââââââ    | 819/1348 [01:43<01:06,  7.95it/s]#015 61%|ââââââ    | 820/1348 [01:43<01:06,  7.90it/s]#015 61%|ââââââ    | 821/1348 [01:43<01:06,  7.90it/s]#015 61%|ââââââ    | 822/1348 [01:43<01:06,  7.93it/s]#015 61%|ââââââ    | 823/1348 [01:43<01:06,  7.85it/s]#015 61%|ââââââ    | 824/1348 [01:43<01:06,  7.89it/s]#015 61%|ââââââ    | 825/1348 [01:43<01:06,  7.91it/s]#015 61%|âââââââ   | 826/1348 [01:44<01:06,  7.90it/s]#015 61%|âââââââ   | 827/1348 [01:44<01:06,  7.89it/s]#015 61%|âââââââ   | 828/1348 [01:44<01:05,  7.92it/s]#015 61%|âââââââ   | 829/1348 [01:44<01:05,  7.95it/s]#015 62%|âââââââ   | 830/1348 [01:44<01:05,  7.96it/s]#015 62%|âââââââ   | 831/1348 [01:44<01:04,  7.97it/s]#015 62%|âââââââ   | 832/1348 [01:44<01:04,  7.95it/s]#015 62%|âââââââ   | 833/1348 [01:44<01:04,  7.94it/s]#015 62%|âââââââ   | 834/1348 [01:45<01:04,  7.92it/s]#015 62%|âââââââ   | 835/1348 [01:45<01:04,  7.92it/s]#015 62%|âââââââ   | 836/1348 [01:45<01:04,  7.92it/s]#015 62%|âââââââ   | 837/1348 [01:45<01:04,  7.92it/s]#015 62%|âââââââ   | 838/1348 [01:45<01:04,  7.92it/s]#015 62%|âââââââ   | 839/1348 [01:45<01:04,  7.93it/s]#015 62%|âââââââ   | 840/1348 [01:45<01:03,  7.94it/s]#015 62%|âââââââ   | 841/1348 [01:45<01:03,  7.96it/s]#015 62%|âââââââ   | 842/1348 [01:46<01:03,  7.92it/s]#015 63%|âââââââ   | 843/1348 [01:46<01:03,  7.91it/s]#015 63%|âââââââ   | 844/1348 [01:46<01:03,  7.93it/s]#015 63%|âââââââ   | 845/1348 [01:46<01:03,  7.93it/s]#015 63%|âââââââ   | 846/1348 [01:46<01:03,  7.93it/s]#015 63%|âââââââ   | 847/1348 [01:46<01:03,  7.89it/s]#015 63%|âââââââ   | 848/1348 [01:46<01:03,  7.88it/s]#015 63%|âââââââ   | 849/13\u001b[0m\n",
      "\u001b[34m48 [01:46<01:03,  7.90it/s]#015 63%|âââââââ   | 850/1348 [01:47<01:03,  7.90it/s]#015 63%|âââââââ   | 851/1348 [01:47<01:02,  7.92it/s]#015 63%|âââââââ   | 852/1348 [01:47<01:02,  7.94it/s]#015 63%|âââââââ   | 853/1348 [01:47<01:02,  7.95it/s]#015 63%|âââââââ   | 854/1348 [01:47<01:02,  7.97it/s]#015 63%|âââââââ   | 855/1348 [01:47<01:01,  7.96it/s]#015 64%|âââââââ   | 856/1348 [01:47<01:01,  7.96it/s]#015 64%|âââââââ   | 857/1348 [01:47<01:01,  7.97it/s]#015 64%|âââââââ   | 858/1348 [01:48<01:01,  7.93it/s]#015 64%|âââââââ   | 859/1348 [01:48<01:01,  7.93it/s]#015 64%|âââââââ   | 860/1348 [01:48<01:01,  7.90it/s]#015 64%|âââââââ   | 861/1348 [01:48<01:01,  7.91it/s]#015 64%|âââââââ   | 862/1348 [01:48<01:01,  7.87it/s]#015 64%|âââââââ   | 863/1348 [01:48<01:01,  7.85it/s]#015 64%|âââââââ   | 864/1348 [01:48<01:01,  7.88it/s]#015 64%|âââââââ   | 865/1348 [01:49<01:01,  7.91it/s]#015 64%|âââââââ   | 866/1348 [01:49<01:01,  7.87it/s]#015 64%|âââââââ   | 867/1348 [01:49<01:00,  7.90it/s]#015 64%|âââââââ   | 868/1348 [01:49<01:00,  7.92it/s]#015 64%|âââââââ   | 869/1348 [01:49<01:00,  7.94it/s]#015 65%|âââââââ   | 870/1348 [01:49<01:00,  7.90it/s]#015 65%|âââââââ   | 871/1348 [01:49<01:00,  7.87it/s]#015 65%|âââââââ   | 872/1348 [01:49<01:00,  7.91it/s]#015 65%|âââââââ   | 873/1348 [01:50<01:00,  7.89it/s]#015 65%|âââââââ   | 874/1348 [01:50<01:00,  7.85it/s]#015 65%|âââââââ   | 875/1348 [01:50<01:00,  7.85it/s]#015 65%|âââââââ   | 876/1348 [01:50<01:00,  7.86it/s]#015 65%|âââââââ   | 877/1348 [01:50<00:59,  7.87it/s]#015 65%|âââââââ   | 878/1348 [01:50<00:59,  7.85it/s]#015 65%|âââââââ   | 879/1348 [01:50<00:59,  7.88it/s]#015 65%|âââââââ   | 880/1348 [01:50<00:59,  7.91it/s]#015 65%|âââââââ   | 881/1348 [01:51<00:59,  7.89it/s]#015 65%|âââââââ   | 882/1348 [01:51<00:59,  7.85it/s]#015 66%|âââââââ   | 883/1348 [01:51<00:59,  7.85it/s]#015 66%|âââââââ   | 884/1348 [01:51<00:58,  7.89it/s]#015 66%|âââââââ   | 885/1348 [01:51<00:58,  7.90it/s]#015 66%|âââââââ   | 886/1348 [01:51<00:58,  7.90it/s]#015 66%|âââââââ   | 887/1348 [01:51<00:58,  7.89it/s]#015 66%|âââââââ   | 888/1348 [01:51<00:58,  7.93it/s]#015 66%|âââââââ   | 889/1348 [01:52<00:57,  7.96it/s]#015 66%|âââââââ   | 890/1348 [01:52<00:57,  7.95it/s]#015 66%|âââââââ   | 891/1348 [01:52<00:57,  7.96it/s]#015 66%|âââââââ   | 892/1348 [01:52<00:57,  7.96it/s]#015 66%|âââââââ   | 893/1348 [01:52<00:57,  7.96it/s]#015 66%|âââââââ   | 894/1348 [01:52<00:56,  7.97it/s]#015 66%|âââââââ   | 895/1348 [01:52<00:56,  7.97it/s]#015 66%|âââââââ   | 896/1348 [01:52<00:56,  7.98it/s]#015 67%|âââââââ   | 897/1348 [01:53<00:56,  7.99it/s]#015 67%|âââââââ   | 898/1348 [01:53<00:56,  7.96it/s]#015 67%|âââââââ   | 899/1348 [01:53<00:56,  7.95it/s]#015 67%|âââââââ   | 900/1348 [01:53<00:56,  7.96it/s]#015 67%|âââââââ   | 901/1348 [01:53<00:56,  7.98it/s]#015 67%|âââââââ   | 902/1348 [01:53<00:55,  7.97it/s]#015 67%|âââââââ   | 903/1348 [01:53<00:56,  7.92it/s]#015 67%|âââââââ   | 904/1348 [01:53<00:55,  7.93it/s]#015 67%|âââââââ   | 905/1348 [01:54<00:55,  7.92it/s]#015 67%|âââââââ   | 906/1348 [01:54<00:55,  7.92it/s]#015 67%|âââââââ   | 907/1348 [01:54<00:56,  7.87it/s]#015 67%|âââââââ   | 908/1348 [01:54<00:55,  7.88it/s]#015 67%|âââââââ   | 909/1348 [01:54<00:55,  7.92it/s]#015 68%|âââââââ   | 910/1348 [01:54<00:55,  7.94it/s]#015 68%|âââââââ   | 911/1348 [01:54<00:54,  7.95it/s]#015 68%|âââââââ   | 912/1348 [01:54<00:54,  7.95it/s]#015 68%|âââââââ   | 913/1348 [01:55<00:54,  7.96it/s]#015 68%|âââââââ   | 914/1348 [01:55<00:54,  7.95it/s]#015 68%|âââââââ   | 915/1348 [01:55<00:55,  7.87it/s]#015 68%|âââââââ   | 916/1348 [01:55<00:54,  7.88it/s]#015 68%|âââââââ   | 917/1348 [01:55<00:54,  7.89it/s]#015 68%|âââââââ   | 918/1348 [01:55<00:54,  7.93it/s]#015 68%|âââââââ   | 919/1348 [01:55<00:54,  7.93it/s]#015 68%|âââââââ   | 920/1348 [01:55<00:53,  7.95it/s]#015 68%|âââââââ   | 921/1348 [01:56<00:53,  7.93it/s]#015 68%|âââââââ   | 922/1348 [01:56<00:53,  7.95it/s]#015 68%|âââââââ   | 923/1348 [01:56<00:54,  7.87it/s]#015 69%|âââââââ   | 924/1348 [01:56<00:53,  7.89it/s]#015 69%|âââââââ   | 925/1348 [01:56<00:53,  7.90it/s]#015 69%|âââââââ   | 926/1348 [01:56<00:53,  7.92it/s]#015 69%|âââââââ   | 927/1348 [01:56<00:53,  7.90it/s]#015 69%|âââââââ   | 928/1348 [01:56<00:53,  7.91it/s]#015 69%|âââââââ   | 929/1348 [01:57<00:52,  7.92it/s]#015 69%|âââââââ   | 930/1348 [01:57<00:52,  7.93it/s]#015 69%|âââââââ   | 931/1348 [01:57<00:53,  7.85it/s]#015 69%|âââââââ   | 932/1348 [01:57<00:52,  7.88it/s]#015 69%|âââââââ   | 933/1348 [01:57<00:52,  7.89it/s]#015 69%|âââââââ   | 934/1348 [01:57<00:52,  7.92it/s]#015 69%|âââââââ   | 935/1348 [01:57<00:51,  7.94it/s]#015 69%|âââââââ   | 936/1348 [01:57<00:51,  7.94it/s]#015 70%|âââââââ   | 937/1348 [01:58<00:51,  7.95it/s]#015 70%|âââââââ   | 938/1348 [01:58<00:51,  7.96it/s]#015 70%|âââââââ   | 939/1348 [01:58<00:51,  7.89it/s]#015 70%|âââââââ   | 940/1348 [01:58<00:51,  7.87it/s]#015 70%|âââââââ   | 941/1348 [01:58<00:51,  7.85it/s]#015 70%|âââââââ   | 942/1348 [01:58<00:51,  7.84it/s]#015 70%|âââââââ   | 943/1348 [01:58<00:51,  7.84it/s]#015 70%|âââââââ   | 944/1348 [01:58<00:51,  7.90it/s]#015 70%|âââââââ   | 945/1348 [01:59<00:50,  7.93it/s]#015 70%|âââââââ   | 946/1348 [01:59<00:50,  7.94it/s]#015 70%|âââââââ   | 947/1348 [01:59<00:51,  7.86it/s]#015 70%|âââââââ   | 948/1348 [01:59<00:50,  7.86it/s]#015 70%|âââââââ   | 949/1348 [01:59<00:50,  7.90it/s]#015 70%|âââââââ   | 950/1348 [01:59<00:50,  7.92it/s]#015 71%|âââââââ   | 951/1348 [01:59<00:49,  7.94it/s]#015 71%|âââââââ   | 952/1348 [01:59<00:49,  7.97it/s]#015 71%|âââââââ   | 953/1348 [02:00<00:49,  7.96it/s]#015 71%|âââââââ   | 954/1348 [02:00<00:49,  7.94it/s]#015 71%|âââââââ   | 955/1348 [02:00<00:49,  7.88it/s]#015 71%|âââââââ   | 956/1348 [02:00<00:49,  7.91it/s]#015 71%|âââââââ   | 957/1348 [02:00<00:49,  7.89it/s]#015 71%|âââââââ   | 958/1348 [02:00<00:49,  7.90it/s]#015 71%|âââââââ   | 959/1348 [02:00<00:49,  7.94it/s]#015 71%|âââââââ   | 960/1348 [02:01<00:48,  7.95it/s]#015 71%|ââââââââ  | 961/1348 [02:01<00:48,  7.94it/s]#015 71%|ââââââââ  | 962/1348 [02:01<00:48,  7.95it/s]#015 71%|ââââââââ  | 963/1348 [02:01<00:48,  7.91it/s]#015 72%|ââââââââ  | 964/1348 [02:01<00:48,  7.94it/s]#015 72%|ââââââââ  | 965/1348 [02:01<00:48,  7.96it/s]#015 72%|ââââââââ  | 966/1348 [02:01<00:47,  7.97it/s]#015 72%|ââââââââ  | 967/1348 [02:01<00:47,  7.95it/s]#015 72%|ââââââââ  | 968/1348 [02:02<00:47,  7.95it/s]#015 72%|ââââââââ  | 969/1348 [02:02<00:47,  7.96it/s]#015 72%|ââââââââ  | 970/1348 [02:02<00:47,  7.96it/s]#015 72%|ââââââââ  | 971/1348 [02:02<00:47,  7.94it/s]#015 72%|ââââââââ  | 972/1348 [02:02<00:47,  7.96it/s]#015 72%|ââââââââ  | 973/1348 [02:02<00:47,  7.96it/s]#015 72%|ââââââââ  | 974/1348 [02:02<00:46,  7.97it/s]#015 72%|ââââââââ  | 975/1348 [02:02<00:46,  7.97it/s]#015 72%|ââââââââ  | 976/1348 [02:03<00:46,  7.97it/s]#015 72%|ââââââââ  | 977/1348 [02:03<00:46,  7.96it/s]#015 73%|ââââââââ  | 978/1348 [02:03<00:46,  7.97it/s]#015 73%|ââââââââ  | 979/1348 [02:03<00:46,  7.92it/s]#015 73%|ââââââââ  | 980/1348 [02:03<00:46,  7.93it/s]#015 73%|ââââââââ  | 981/1348 [02:03<00:46,  7.95it/s]#015 73%|ââââââââ  | 982/1348 [02:03<00:46,  7.91it/s]#015 73%|ââââââââ  | 983/1348 [02:03<00:46,  7.88it/s]#015 73%|ââââââââ  | 984/1348 [02:04<00:46,  7.91it/s]#015 73%|ââââââââ  | 985/1348 [02:04<00:45,  7.89it/s]#015 73%|ââââââââ  | 986/1348 [02:04<00:46,  7.84it/s]#015 73%|ââââââââ  | 987/1348 [02:04<00:46,  7.83it/s]#015 73%|ââââââââ  | 988/1348 [02:04<00:45,  7.86it/s]#015 73%|ââââââââ  | 989/1348 [02:04<00:45,  7.88it/s]#015 73%|ââââââââ  | 990/1348 [02:04<00:45,  7.90it/s]#015 74%|ââââââââ  | 991/1348 [02:04<00:45,  7.92it/s]#015 74%|ââââââââ  | 992/1348 [02:05<00:44,  7.93it/s]#015 74%|ââââââââ  | 993/1348 [02:05<00:44,  7.92it/s]#015 74%|ââââââââ  | 994/1348 [02:05<00:44,  7.90it/s]#015 74%|ââââââââ  | 995/1348 [02:05<00:45,  7.81it/s]#015 74%|ââââââââ  | 996/1348 [02:05<00:46,  7.57it/s]#015 74%|ââââââââ  | 997/1348 [02:05<00:45,  7.64it/s]#015 74%|ââââââââ  | 998/1348 [02:05<00:45,  7.71it/s]#015 74%|ââââââââ  | 999/1348 [02:05<00:44,  7.76it/s]#015 74%|ââââââââ  | 1000/1348 [02:06<00:44,  7.82it/s]#015 74%|ââââââââ  | 1001/1348 [02:06<00:44,  7.84it/s]#015 74%|ââââââââ  | 1002/1348 [02:06<00:44,  7.83it/s]#015 74%|ââââââââ  | 1003/1348 [02:06<00:44,  7.80it/s]#015 74%|ââââââââ  | 1004/1348 [02:06<00:43,  7.84it/s]#015 75%|ââââââââ  | 1005/1348 [02:06<00:43,  7.86it/s]#015 75%|ââââââââ  | 1006/1348 [02:06<00:43,  7.89it/s]#015 75%|ââââââââ  | 1007/1348 [02:06<00:43,  7.91it/s]#015 75%|ââââââââ  | 1008/1348 [02:07<00:42,  7.93it/s]#015 75%|ââââââââ  | 1009/1348 [02:07<00:42,  7.95it/s]#015 75%|ââââââââ  | 1010/1348 [02:07<00:42,  7.95it/s]#015 75%|ââââââââ  | 1011/1348 [02:07<00:42,  7.90it/s]#015 75%|ââââââââ  | 1012/1348 [02:07<00:42,  7.92it/s]#015 75%|ââââââââ  | 1013/1348 [02:07<00:42,  7.93it/s]#015 75%|ââââââââ  | 1014/1348 [02:07<00:41,  7.95it/s]#015 75%|ââââââââ  | 1015/1348 [02:07<00:41,  7.96it/s]#015 75%|ââââââââ  | 1016/1348 [02:08<00:41,  7.98it/s]#015 75%|ââââââââ  | 1017/1348 [02:08<00:41,  7.97it/s]#015 76%|ââââââââ  | 1018/1348 [02:08<00:41,  7.97it/s]#015 76%|ââââââââ  | 1019/1348 [02:08<00:41,  7.93it/s]#015 76%|ââââââââ  | 1020/1348 [02:08<00:41,  7.94it/s]#015 76%|ââââââââ  | 1021/1348 [02:08<00:41,  7.95it/s]#015 76%|ââââââââ  | 1022/1348 [02:08<00:41,  7.83it/s]#015 76%|ââââââââ  | 1023/1348 [02:08<00:42,  7.64it/s]#015 76%|ââââââââ  | 1024/1348 [02:09<00:41,  7.74it/s]#015 76%|ââââââââ  | 1025/1348 [02:09<00:41,  7.79it/s]#015 76%|ââââââââ  | 1026/1348 [02:09<00:41,  7.81it/s]#015 76%|ââââââââ  | 1027/1348 [02:09<00:40,  7.85it/s]#015 76%|ââââââââ  | 1028/1348 [02:09<00:40,  7.90it/s]#015 76%|ââââââââ  | 1029/1348 [02:09<00:40,  7.92it/s]#015 76%|ââââââââ  | 1030/1348 [02:09<00:40,  7.92it/s]#015 76%|ââââââââ  | 1031/1348 [02:10<00:40,  7.91it/s]#015 77%|ââââââââ  | 1032/1348 [02:10<00:40,  7.85it/s]#015 77%|ââââââââ  | 1033/1348 [02:10<00:40,  7.81it/s]#015 77%|ââââââââ  | 1034/1348 [02:10<00:40,  7.81it/s]#015 77%|ââââââââ  | 1035/1348 [02:10<00:39,  7.86it/s]#015 77%|ââââââââ  | 1036/1348 [02:10<00:39,  7.90it/s]#015 77%|ââââââââ  | 1037/1348 [02:10<00:39,  7.93it/s]#015 77%|ââââââââ  | 1038/1348 [02:10<00:38,  7.95it/s]#015 77%|ââââââââ  | 1039/1348 [02:11<00:38,  7.94it/s]#015 77%|ââââââââ  | 1040/1348 [02:11<00:38,  7.95it/s]#015 77%|ââââââââ  | 1041/1348 [02:11<00:38,  7.96it/s]#015 77%|ââââââââ  | 1042/1348 [02:11<00:38,  7.93it/s]#015 77%|ââââââââ  | 1043/1348 [02:11<00:38,  7.85it/s]#015 77%|ââââââââ  | 1044/1348 [02:11<00:38,  7.87it/s]#015 78%|ââââââââ  | 1045/1348 [02:11<00:38,  7.85it/s]#015 78%|ââââââââ  | 1046/1348 [02:11<00:38,  7.88it/s]#015 78%|ââââââââ  | 1047/1348 [02:12<00:38,  7.89it/s]#015 78%|ââââââââ  | 1048/1348 [02:12<00:37,  7.90it/s]#015 78%|ââââââââ  | 1049/1348 [02:12<00:37,  7.91it/s]#015 78%|ââââââââ  | 1050/1348 [02:12<00:38,  7.83it/s]#015 78%|ââââââââ  | 1051/1348 [02:12<00:37,  7.85it/s]#015 78%|ââââââââ  | 1052/1348 [02:12<00:37,  7.85it/s]#015 78%|ââââââââ  | 1053/1348 [02:12<00:37,  7.86it/s]#015 78%|ââââââââ  | 1054/1348 [02:12<00:37,  7.88it/s]#015 78%|ââââââââ  | 1055/1348 [02:13<00:37,  7.87it/s]#015 78%|ââââââââ  | 1056/1348 [02:13<00:36,  7.90it/s]#015 78%|ââââââââ  | 1057/1348 [02:13<00:36,  7.90it/s]#015 78%|ââââââââ  | 1058/1348 [02:13<00:37,  7.83it/s]#015 79%|ââââââââ  | 1059/1348 [02:13<00:36,  7.84it/s]#015 79%|ââââââââ  | 1060/1348 [02:13<00:36,  7.87it/s]#015 79%|ââââââââ  | 1061/1348 [02:13<00:36,  7.86it/s]#015 79%|ââââââââ  | 1062/1348 [02:13<00:37,  7.66it/s]#015 79%|ââââââââ  | 1063/1348 [02:14<00:36,  7.75it/s]#015 79%|ââââââââ  | 1064/1348 [02:14<00:36,  7.82it/s]#015 79%|ââââââââ  | 1065/1348 [02:14<00:35,  7.86it/s]#015 79%|ââââââââ  | 1066/1348 [02:14<00:35,  7.89it/s]#015 79%|ââââââââ  | 1067/1348 [02:14<00:35,  7.86it/s]#015 79%|ââââââââ  | 1068/1348 [02:14<00:35,  7.87it/s]#015 79%|ââââââââ  | 1069/1348 [02:14<00:35,  7.92it/s]#015 79%|ââââââââ  | 1070/1348 [02:14<00:35,  7.94it/s]#015 79%|ââââââââ  | 1071/1348 [02:15<00:34,  7.94it/s]#015 80%|ââââââââ  | 1072/1348 [02:15<00:34,  7.94it/s]#015 80%|ââââââââ  | 1073/1348 [02:15<00:34,  7.95it/s]#015 80%|ââââââââ  | 1074/1348 [02:15<00:34,  7.92it/s]#015 80%|ââââââââ  | 1075/1348 [02:15<00:34,  7.94it/s]#015 80%|ââââââââ  | 1076/1348 [02:15<00:34,  7.97it/s]#015 80%|ââââââââ  | 1077/1348 [02:15<00:34,  7.95it/s]#015 80%|ââââââââ  | 1078/1348 [02:15<00:33,  7.97it/s]#015 80%|ââââââââ  | 1079/1348 [02:16<00:33,  7.98it/s]#015 80%|ââââââââ  | 1080/1348 [02:16<00:33,  7.99it/s]#015 80%|ââââââââ  | 1081/1348 [02:16<00:33,  7.98it/s]#015 80%|ââââââââ  | 1082/1348 [02:16<00:33,  7.97it/s]#015 80%|ââââââââ  | 1083/1348 [02:16<00:33,  7.96it/s]#015 80%|ââââââââ  | 1084/1348 [02:16<00:33,  7.98it/s]#015 80%|ââââââââ  | 1085/1348 [02:16<00:32,  7.97it/s]#015 81%|ââââââââ  | 1086/1348 [02:16<00:32,  7.97it/s]#015 81%|ââââââââ  | 1087/1348 [02:17<00:32,  7.95it/s]#015 81%|ââââââââ  | 1088/1348 [02:17<00:32,  7.96it/s]#015 81%|ââââââââ  | 1089/1348 [02:17<00:32,  7.96it/s]#015 81%|ââââââââ  | 1090/1348 [02:17<00:32,  7.95it/s]#015 81%|ââââââââ  | 1091/1348 [02:17<00:32,  7.87it/s]#015 81%|ââââââââ  | 1092/1348 [02:17<00:32,  7.91it/s]#015 81%|ââââââââ  | 1093/1348 [02:17<00:32,  7.94it/s]#015 81%|ââââââââ  | 1094/1348 [02:17<00:31,  7.96it/s]#015 81%|ââââââââ  | 1095/1348 [02:18<00:31,  7.97it/s]#015\n",
      " 81%|âââââââââ | 1096/1348 [02:18<00:31,  7.96it/s]#015 81%|âââââââââ | 1097/1348 [02:18<00:31,  7.96it/s]#015 81%|âââââââââ | 1098/1348 [02:18<00:31,  7.93it/s]#015 82%|âââââââââ | 1099/1348 [02:18<00:31,  7.90it/s]#015 82%|âââââââââ | 1100/1348 [02:18<00:31,  7.91it/s]#015 82%|âââââââââ | 1101/1348 [02:18<00:31,  7.93it/s]#015 82%|âââââââââ | 1102/1348 [02:18<00:31,  7.88it/s]#015 82%|âââââââââ | 1103/1348 [02:19<00:31,  7.89it/s]#015 82%|âââââââââ | 1104/1348 [02:19<00:30,  7.88it/s]#015 82%|âââââââââ | 1105/1348 [02:19<00:30,  7.91it/s]#015 82%|âââââââââ | 1106/1348 [02:19<00:30,  7.91it/s]#015 82%|âââââââââ | 1107/1348 [02:19<00:30,  7.82it/s]#015 82%|âââââââââ | 1108/1348 [02:19<00:30,  7.82it/s]#015 82%|âââââââââ | 1109/1348 [02:19<00:30,  7.86it/s]#015 82%|âââââââââ | 1110/1348 [02:20<00:30,  7.90it/s]#015 82%|âââââââââ | 1111/1348 [02:20<00:29,  7.92it/s]#015 82%|âââââââââ | 1112/1348 [02:20<00:29,  7.94it/s]#015 83%|âââââââââ | 1113/1348 [02:20<00:29,  7.96it/s]#015 83%|âââââââââ | 1114/1348 [02:20<00:29,  7.97it/s]#015 83%|âââââââââ | 1115/1348 [02:20<00:29,  7.89it/s]#015 83%|âââââââââ | 1116/1348 [02:20<00:29,  7.91it/s]#015 83%|âââââââââ | 1117/1348 [02:20<00:29,  7.90it/s]#015 83%|âââââââââ | 1118/1348 [02:21<00:29,  7.91it/s]#015 83%|âââââââââ | 1119/1348 [02:21<00:28,  7.93it/s]#015 83%|âââââââââ | 1120/1348 [02:21<00:28,  7.93it/s]#015 83%|âââââââââ | 1121/1348 [02:21<00:28,  7.92it/s]#015 83%|âââââââââ | 1122/1348 [02:21<00:28,  7.92it/s]#015 83%|âââââââââ | 1123/1348 [02:21<00:28,  7.86it/s]#015 83%|âââââââââ | 1124/1348 [02:21<00:28,  7.87it/s]#015 83%|âââââââââ | 1125/1348 [02:21<00:28,  7.90it/s]#015 84%|âââââââââ | 1126/1348 [02:22<00:28,  7.92it/s]#015 84%|âââââââââ | 1127/1348 [02:22<00:27,  7.92it/s]#015 84%|âââââââââ | 1128/1348 [02:22<00:27,  7.93it/s]#015 84%|âââââââââ | 1129/1348 [02:22<00:27,  7.92it/s]#015 84%|âââââââââ | 1130/1348 [02:22<00:27,  7.95it/s]#015 84%|âââââââââ | 1131/1348 [02:22<00:27,  7.91it/s]#015 84%|âââââââââ | 1132/1348 [02:22<00:27,  7.92it/s]#015 84%|âââââââââ | 1133/1348 [02:22<00:27,  7.94it/s]#015 84%|âââââââââ | 1134/1348 [02:23<00:26,  7.95it/s]#015 84%|âââââââââ | 1135/1348 [02:23<00:26,  7.96it/s]#015 84%|âââââââââ | 1136/1348 [02:23<00:26,  7.96it/s]#015 84%|âââââââââ | 1137/1348 [02:23<00:26,  7.96it/s]#015 84%|âââââââââ | 1138/1348 [02:23<00:26,  7.94it/s]#015 84%|âââââââââ | 1139/1348 [02:23<00:26,  7.91it/s]#015 85%|âââââââââ | 1140/1348 [02:23<00:26,  7.93it/s]#015 85%|âââââââââ | 1141/1348 [02:23<00:26,  7.95it/s]#015 85%|âââââââââ | 1142/1348 [02:24<00:26,  7.80it/s]#015 85%|âââââââââ | 1143/1348 [02:24<00:26,  7.85it/s]#015 85%|âââââââââ | 1144/1348 [02:24<00:25,  7.88it/s]#015 85%|âââââââââ | 1145/1348 [02:24<00:25,  7.91it/s]#015 85%|âââââââââ | 1146/1348 [02:24<00:25,  7.92it/s]#015 85%|âââââââââ | 1147/1348 [02:24<00:25,  7.90it/s]#015 85%|âââââââââ | 1148/1348 [02:24<00:25,  7.92it/s]#015 85%|âââââââââ | 1149/1348 [02:24<00:25,  7.94it/s]#015 85%|âââââââââ | 1150/1348 [02:25<00:24,  7.94it/s]#015 85%|âââââââââ | 1151/1348 [02:25<00:24,  7.96it/s]#015 85%|âââââââââ | 1152/1348 [02:25<00:24,  7.98it/s]#015 86%|âââââââââ | 1153/1348 [02:25<00:24,  7.96it/s]#015 86%|âââââââââ | 1154/1348 [02:25<00:24,  7.96it/s]#015 86%|âââââââââ | 1155/1348 [02:25<00:24,  7.92it/s]#015 86%|âââââââââ | 1156/1348 [02:25<00:24,  7.91it/s]#015 86%|âââââââââ | 1157/1348 [02:25<00:24,  7.92it/s]#015 86%|âââââââââ | 1158/1348 [02:26<00:23,  7.93it/s]#015 86%|âââââââââ | 1159/1348 [02:26<00:23,  7.94it/s]#015 86%|âââââââââ | 1160/1348 [02:26<00:23,  7.95it/s]#015 86%|âââââââââ | 1161/1348 [02:26<00:23,  7.94it/s]#015 86%|âââââââââ | 1162/1348 [02:26<00:23,  7.95it/s]#015 86%|âââââââââ | 1163/1348 [02:26<00:23,  7.93it/s]#015 86%|âââââââââ | 1164/1348 [02:26<00:23,  7.93it/s]#015 86%|âââââââââ | 1165/1348 [02:26<00:23,  7.93it/s]#015 86%|âââââââââ | 1166/1348 [02:27<00:22,  7.94it/s]#015 87%|âââââââââ | 1167/1348 [02:27<00:22,  7.96it/s]#015 87%|âââââââââ | 1168/1348 [02:27<00:22,  7.96it/s]#015 87%|âââââââââ | 1169/1348 [02:27<00:22,  7.96it/s]#015 87%|âââââââââ | 1170/1348 [02:27<00:22,  7.93it/s]#015 87%|âââââââââ | 1171/1348 [02:27<00:22,  7.91it/s]#015 87%|âââââââââ | 1172/1348 [02:27<00:22,  7.93it/s]#015 87%|âââââââââ | 1173/1348 [02:27<00:22,  7.95it/s]#015 87%|âââââââââ | 1174/1348 [02:28<00:21,  7.96it/s]#015 87%|âââââââââ | 1175/1348 [02:28<00:21,  7.97it/s]#015 87%|âââââââââ | 1176/1348 [02:28<00:21,  7.98it/s]#015 87%|âââââââââ | 1177/1348 [02:28<00:21,  7.97it/s]#015 87%|âââââââââ | 1178/1348 [02:28<00:21,  7.96it/s]#015 87%|âââââââââ | 1179/1348 [02:28<00:21,  7.93it/s]#015 88%|âââââââââ | 1180/1348 [02:28<00:21,  7.95it/s]#015 88%|âââââââââ | 1181/1348 [02:28<00:20,  7.97it/s]#015 88%|âââââââââ | 1182/1348 [02:29<00:21,  7.79it/s]#015 88%|âââââââââ | 1183/1348 [02:29<00:21,  7.81it/s]#015 88%|âââââââââ | 1184/1348 [02:29<00:20,  7.84it/s]#015 88%|âââââââââ | 1185/1348 [02:29<00:20,  7.87it/s]#015 88%|âââââââââ | 1186/1348 [02:29<00:20,  7.92it/s]#015 88%|âââââââââ | 1187/1348 [02:29<00:20,  7.89it/s]#015 88%|âââââââââ | 1188/1348 [02:29<00:20,  7.90it/s]#015 88%|âââââââââ | 1189/1348 [02:29<00:20,  7.93it/s]#015 88%|âââââââââ | 1190/1348 [02:30<00:19,  7.92it/s]#015 88%|âââââââââ | 1191/1348 [02:30<00:19,  7.90it/s]#015 88%|âââââââââ | 1192/1348 [02:30<00:19,  7.92it/s]#015 89%|âââââââââ | 1193/1348 [02:30<00:19,  7.93it/s]#015 89%|âââââââââ | 1194/1348 [02:30<00:19,  7.95it/s]#015 89%|âââââââââ | 1195/1348 [02:30<00:19,  7.90it/s]#015 89%|âââââââââ | 1196/1348 [02:30<00:19,  7.92it/s]#015 89%|âââââââââ | 1197/1348 [02:30<00:19,  7.94it/s]#015 89%|âââââââââ | 1198/1348 [02:31<00:18,  7.92it/s]#015 89%|âââââââââ | 1199/1348 [02:31<00:18,  7.92it/s]#015 89%|âââââââââ | 1200/1348 [02:31<00:18,  7.92it/s]#015 89%|âââââââââ | 1201/1348 [02:31<00:18,  7.94it/s]#015 89%|âââââââââ | 1202/1348 [02:31<00:18,  7.94it/s]#015 89%|âââââââââ | 1203/1348 [02:31<00:18,  7.91it/s]#015 89%|âââââââââ | 1204/1348 [02:31<00:18,  7.92it/s]#015 89%|âââââââââ | 1205/1348 [02:31<00:18,  7.93it/s]#015 89%|âââââââââ | 1206/1348 [02:32<00:17,  7.93it/s]#015 90%|âââââââââ | 1207/1348 [02:32<00:17,  7.95it/s]#015 90%|âââââââââ | 1208/1348 [02:32<00:17,  7.96it/s]#015 90%|âââââââââ | 1209/1348 [02:32<00:17,  7.97it/s]#015 90%|âââââââââ | 1210/1348 [02:32<00:17,  7.96it/s]#015 90%|âââââââââ | 1211/1348 [02:32<00:17,  7.92it/s]#015 90%|âââââââââ | 1212/1348 [02:32<00:17,  7.93it/s]#015 90%|âââââââââ | 1213/1348 [02:32<00:16,  7.95it/s]#015 90%|âââââââââ | 1214/1348 [02:33<00:16,  7.94it/s]#015 90%|âââââââââ | 1215/1348 [02:33<00:16,  7.94it/s]#015 90%|âââââââââ | 1216/1348 [02:33<00:16,  7.95it/s]#015 90%|âââââââââ | 1217/1348 [02:33<00:16,  7.97it/s]#015 90%|âââââââââ | 1218/1348 [02:33<00:16,  7.98it/s]#015 90%|âââââââââ | 1219/1348 [02:33<00:16,  7.93it/s]#015 91%|âââââââââ | 1220/1348 [02:33<00:16,  7.96it/s]#015 91%|âââââââââ | 1221/1348 [02:33<00:15,  7.96it/s]#015 91%|âââââââââ | 1222/1348 [02:34<00:16,  7.85it/s]#015 91%|âââââââââ | 1223/1348 [02:34<00:15,  7.85it/s]#015 91%|âââââââââ | 1224/1348 [02:34<00:15,  7.88it/s]#015 91%|âââââââââ | 1225/1348 [02:34<00:15,  7.89it/s]#015 91%|âââââââââ | 1226/1348 [02:34<00:15,  7.92it/s]#015 91%|âââââââââ | 1227/1348 [02:34<00:15,  7.92it/s]#015 91%|âââââââââ | 1228/1348 [02:34<00:15,  7.95it/s]#015 91%|âââââââââ | 1229/1348 [02:35<00:14,  7.94it/s]#015 91%|âââââââââ | 1230/1348 [02:35<00:14,  7.94it/s]#015 91%|ââââââââââ| 1231/1348 [02:35<00:14,  7.95it/s]#015 91%|ââââââââââ| 1232/1348 [02:35<00:14,  7.96it/s]#015 91%|ââââââââââ| 1233/1348 [02:35<00:14,  7.95it/s]#015 92%|ââââââââââ| 1234/1348 [02:35<00:14,  7.97it/s]#015 92%|ââââââââââ| 1235/1348 [02:35<00:14,  7.95it/s]#015 92%|ââââââââââ| 1236/1348 [02:35<00:14,  7.95it/s]#015 92%|ââââââââââ| 1237/1348 [02:36<00:13,  7.97it/s]#015 92%|ââââââââââ| 1238/1348 [02:36<00:13,  7.99it/s]#015 92%|ââââââââââ| 1239/1348 [02:36<00:13,  8.00it/s]#015 92%|ââââââââââ| 1240/1348 [02:36<00:13,  8.00it/s]#015 92%|ââââââââââ| 1241/1348 [02:36<00:13,  8.00it/s]#015 92%|ââââââââââ| 1242/1348 [02:36<00:13,  8.00it/s]#015 92%|ââââââââââ| 1243/1348 [02:36<00:13,  7.96it/s]#015 92%|ââââââââââ| 1244/1348 [02:36<00:13,  7.97it/s]#015 92%|ââââââââââ| 1245/1348 [02:37<00:12,  7.95it/s]#015 92%|ââââââââââ| 1246/1348 [02:37<00:12,  7.97it/s]#015 93%|ââââââââââ| 1247/1348 [02:37<00:12,  7.97it/s]#015 93%|ââââââââââ| 1248/1348 [02:37<00:12,  7.98it/s]#015 93%|ââââââââââ| 1249/1348 [02:37<00:12,  7.97it/s]#015 93%|ââââââââââ| 1250/1348 [02:37<00:12,  7.95it/s]#015 93%|ââââââââââ| 1251/1348 [02:37<00:12,  7.50it/s]#015 93%|ââââââââââ| 1252/1348 [02:37<00:12,  7.64it/s]#015 93%|ââââââââââ| 1253/1348 [02:38<00:12,  7.73it/s]#015 93%|ââââââââââ| 1254/1348 [02:38<00:12,  7.81it/s]#015 93%|ââââââââââ| 1255/1348 [02:38<00:11,  7.82it/s]#015 93%|ââââââââââ| 1256/1348 [02:38<00:11,  7.83it/s]#015 93%|ââââââââââ| 1257/1348 [02:38<00:11,  7.84it/s]#015 93%|ââââââââââ| 1258/1348 [02:38<00:11,  7.89it/s]#015 93%|ââââââââââ| 1259/1348 [02:38<00:11,  7.90it/s]#015 93%|ââââââââââ| 1260/1348 [02:38<00:11,  7.92it/s]#015 94%|ââââââââââ| 1261/1348 [02:39<00:10,  7.93it/s]#015 94%|ââââââââââ| 1262/1348 [02:39<00:10,  7.86it/s]#015 94%|ââââââââââ| 1263/1348 [02:39<00:10,  7.88it/s]#015 94%|ââââââââââ| 1264/1348 [02:39<00:10,  7.91it/s]#015 94%|ââââââââââ| 1265/1348 [02:39<00:10,  7.89it/s]#015 94%|ââââââââââ| 1266/1348 [02:39<00:10,  7.93it/s]#015 94%|ââââââââââ| 1267/1348 [02:39<00:10,  7.93it/s]#015 94%|ââââââââââ| 1268/1348 [02:39<00:10,  7.96it/s]#015 94%|ââââââââââ| 1269/1348 [02:40<00:09,  7.96it/s]#015 94%|ââââââââââ| 1270/1348 [02:40<00:09,  7.93it/s]#015 94%|ââââââââââ| 1271/1348 [02:40<00:09,  7.92it/s]#015 94%|ââââââââââ| 1272/1348 [02:40<00:09,  7.81it/s]#015 94%|ââââââââââ| 1273/1348 [02:40<00:09,  7.82it/s]#015 95%|ââââââââââ| 1274/1348 [02:40<00:09,  7.85it/s]#015 95%|ââââââââââ| 1275/1348 [02:40<00:09,  7.86it/s]#015 95%|ââââââââââ| 1276/1348 [02:40<00:09,  7.89it/s]#015 95%|ââââââââââ| 1277/1348 [02:41<00:08,  7.92it/s]#015 95%|ââââââââââ| 1278/1348 [02:41<00:08,  7.94it/s]#015 95%|ââââââââââ| 1279/1348 [02:41<00:08,  7.95it/s]#015 95%|ââââââââââ| 1280/1348 [02:41<00:08,  7.97it/s]#015 95%|ââââââââââ| 1281/1348 [02:41<00:08,  7.98it/s]#015 95%|ââââââââââ| 1282/1348 [02:41<00:08,  7.98it/s]#015 95%|ââââââââââ| 1283/1348 [02:41<00:08,  7.95it/s]#015 95%|ââââââââââ| 1284/1348 [02:41<00:08,  7.95it/s]#015 95%|ââââââââââ| 1285/1348 [02:42<00:07,  7.94it/s]#015 95%|ââââââââââ| 1286/1348 [02:42<00:07,  7.95it/s]#015 95%|ââââââââââ| 1287/1348 [02:42<00:07,  7.95it/s]#015 96%|ââââââââââ| 1288/1348 [02:42<00:07,  7.95it/s]#015 96%|ââââââââââ| 1289/1348 [02:42<00:07,  7.97it/s]#015 96%|ââââââââââ| 1290/1348 [02:42<00:07,  7.98it/s]#015 96%|ââââââââââ| 1291/1348 [02:42<00:07,  7.94it/s]#015 96%|ââââââââââ| 1292/1348 [02:42<00:07,  7.97it/s]#015 96%|ââââââââââ| 1293/1348 [02:43<00:06,  7.96it/s]#015 96%|ââââââââââ| 1294/1348 [02:43<00:06,  7.97it/s]#015 96%|ââââââââââ| 1295/1348 [02:43<00:06,  7.95it/s]#015 96%|ââââââââââ| 1296/1348 [02:43<00:06,  7.96it/s]#015 96%|ââââââââââ| 1297/1348 [02:43<00:06,  7.94it/s]#015 96%|ââââââââââ| 1298/1348 [02:43<00:06,  7.95it/s]#015 96%|ââââââââââ| 1299/1348 [02:43<00:06,  7.93it/s]#015 96%|ââââââââââ| 1300/1348 [02:43<00:06,  7.95it/s]#015 97%|ââââââââââ| 1301/1348 [02:44<00:05,  7.96it/s]#015 97%|ââââââââââ| 1302/1348 [02:44<00:05,  7.93it/s]#015 97%|ââââââââââ| 1303/1348 [02:44<00:05,  7.93it/s]#015 97%|ââââââââââ| 1304/1348 [02:44<00:05,  7.95it/s]#015 97%|ââââââââââ| 1305/1348 [02:44<00:05,  7.96it/s]#015 97%|ââââââââââ| 1306/1348 [02:44<00:05,  7.96it/s]#015 97%|ââââââââââ| 1307/1348 [02:44<00:05,  7.93it/s]#015 97%|ââââââââââ| 1308/1348 [02:44<00:05,  7.93it/s]#015 97%|ââââââââââ| 1309/1348 [02:45<00:04,  7.94it/s]#015 97%|ââââââââââ| 1310/1348 [02:45<00:04,  7.91it/s]#015 97%|ââââââââââ| 1311/1348 [02:45<00:04,  7.94it/s]#015 97%|ââââââââââ| 1312/1348 [02:45<00:04,  7.94it/s]#015 97%|ââââââââââ| 1313/1348 [02:45<00:04,  7.95it/s]#015 97%|ââââââââââ| 1314/1348 [02:45<00:04,  7.96it/s]#015 98%|ââââââââââ| 1315/1348 [02:45<00:04,  7.92it/s]#015 98%|ââââââââââ| 1316/1348 [02:45<00:04,  7.95it/s]#015 98%|ââââââââââ| 1317/1348 [02:46<00:03,  7.94it/s]#015 98%|ââââââââââ| 1318/1348 [02:46<00:03,  7.94it/s]#015 98%|ââââââââââ| 1319/1348 [02:46<00:03,  7.95it/s]#015 98%|ââââââââââ| 1320/1348 [02:46<00:03,  7.97it/s]#015 98%|ââââââââââ| 1321/1348 [02:46<00:03,  7.95it/s]#015 98%|ââââââââââ| 1322/1348 [02:46<00:03,  7.95it/s]#015 98%|ââââââââââ| 1323/1348 [02:46<00:03,  7.92it/s]#015 98%|ââââââââââ| 1324/1348 [02:46<00:03,  7.92it/s]#015 98%|ââââââââââ| 1325/1348 [02:47<00:02,  7.92it/s]#015 98%|ââââââââââ| 1326/1348 [02:47<00:02,  7.90it/s]#015 98%|âââââï¿½\u001b[0m\n",
      "\u001b[34mï¿½ââââ| 1327/1348 [02:47<00:02,  7.90it/s]#015 99%|ââââââââââ| 1328/1348 [02:47<00:02,  7.93it/s]#015 99%|ââââââââââ| 1329/1348 [02:47<00:02,  7.94it/s]#015 99%|ââââââââââ| 1330/1348 [02:47<00:02,  7.94it/s]#015 99%|ââââââââââ| 1331/1348 [02:47<00:02,  7.92it/s]#015 99%|ââââââââââ| 1332/1348 [02:48<00:02,  7.91it/s]#015 99%|ââââââââââ| 1333/1348 [02:48<00:01,  7.94it/s]#015 99%|ââââââââââ| 1334/1348 [02:48<00:01,  7.93it/s]#015 99%|ââââââââââ| 1335/1348 [02:48<00:01,  7.90it/s]#015 99%|ââââââââââ| 1336/1348 [02:48<00:01,  7.89it/s]#015 99%|ââââââââââ| 1337/1348 [02:48<00:01,  7.93it/s]#015 99%|ââââââââââ| 1338/1348 [02:48<00:01,  7.95it/s]#015 99%|ââââââââââ| 1339/1348 [02:48<00:01,  7.92it/s]#015 99%|ââââââââââ| 1340/1348 [02:49<00:01,  7.94it/s]#015 99%|ââââââââââ| 1341/1348 [02:49<00:00,  7.94it/s]#015100%|ââââââââââ| 1342/1348 [02:49<00:00,  7.91it/s]#015100%|ââââââââââ| 1343/1348 [02:49<00:00,  7.93it/s]#015100%|ââââââââââ| 1344/1348 [02:49<00:00,  7.94it/s]#015100%|ââââââââââ| 1345/1348 [02:49<00:00,  7.97it/s]#015100%|ââââââââââ| 1346/1348 [02:49<00:00,  7.98it/s]#015100%|ââââââââââ| 1347/1348 [02:49<00:00,  7.95it/s]#015100%|ââââââââââ| 1348/1348 [02:50<00:00,  7.96it/s]01/14/2021 16:08:45 - INFO - nn_pruning.examples.question_answering.qa_train -     Evaluation done in total 170.169111 secs (0.015780 sec per example)\u001b[0m\n",
      "\u001b[34m01/14/2021 16:08:57 - INFO - nn_pruning.examples.question_answering.qa_utils -   Post-processing 10570 example predictions split into 10784 features.\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/10570 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  0%|          | 36/10570 [00:00<00:29, 358.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 75/10570 [00:00<00:28, 367.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|          | 115/10570 [00:00<00:27, 376.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  1%|â         | 153/10570 [00:00<00:27, 376.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 192/10570 [00:00<00:27, 379.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 225/10570 [00:00<00:28, 361.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  2%|â         | 258/10570 [00:00<00:32, 317.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 288/10570 [00:00<00:36, 283.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 326/10570 [00:00<00:33, 306.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|â         | 366/10570 [00:01<00:30, 329.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 403/10570 [00:01<00:29, 340.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|â         | 440/10570 [00:01<00:29, 347.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 477/10570 [00:01<00:28, 353.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 516/10570 [00:01<00:27, 362.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|â         | 554/10570 [00:01<00:27, 367.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 591/10570 [00:01<00:27, 367.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 631/10570 [00:01<00:26, 374.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|â         | 669/10570 [00:01<00:26, 375.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 707/10570 [00:01<00:26, 375.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 745/10570 [00:02<00:26, 366.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|â         | 782/10570 [00:02<00:27, 359.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 819/10570 [00:02<00:28, 339.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 854/10570 [00:02<00:28, 340.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|â         | 891/10570 [00:02<00:27, 347.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 926/10570 [00:02<00:28, 342.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 961/10570 [00:02<00:27, 344.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|â         | 996/10570 [00:02<00:28, 337.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1030/10570 [00:02<00:28, 337.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1065/10570 [00:03<00:28, 339.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|â         | 1099/10570 [00:03<00:28, 333.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 1136/10570 [00:03<00:27, 343.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|â         | 1175/10570 [00:03<00:26, 355.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|ââ        | 1212/10570 [00:03<00:26, 357.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 1251/10570 [00:03<00:25, 363.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|ââ        | 1288/10570 [00:03<00:25, 363.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 1327/10570 [00:03<00:25, 368.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 1365/10570 [00:03<00:24, 369.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|ââ        | 1403/10570 [00:03<00:25, 353.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1440/10570 [00:04<00:25, 355.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1478/10570 [00:04<00:25, 360.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|ââ        | 1516/10570 [00:04<00:24, 364.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1554/10570 [00:04<00:24, 367.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1591/10570 [00:04<00:24, 366.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|ââ        | 1629/10570 [00:04<00:24, 368.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 1669/10570 [00:04<00:23, 376.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|ââ        | 1708/10570 [00:04<00:23, 378.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 1746/10570 [00:04<00:23, 375.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 1784/10570 [00:04<00:23, 376.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|ââ        | 1822/10570 [00:05<00:23, 375.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1860/10570 [00:05<00:23, 373.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1900/10570 [00:05<00:22, 380.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|ââ        | 1939/10570 [00:05<00:22, 380.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 1978/10570 [00:05<00:22, 381.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 2017/10570 [00:05<00:22, 377.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|ââ        | 2056/10570 [00:05<00:22, 378.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 2096/10570 [00:05<00:22, 383.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|ââ        | 2135/10570 [00:05<00:24, 344.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 2171/10570 [00:06<00:24, 348.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 2208/10570 [00:06<00:23, 354.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|ââ        | 2246/10570 [00:06<00:23, 360.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2283/10570 [00:06<00:22, 361.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2320/10570 [00:06<00:22, 361.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|âââ       | 2357/10570 [00:06<00:22, 358.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2393/10570 [00:06<00:23, 351.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2429/10570 [00:06<00:23, 353.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|âââ       | 2465/10570 [00:06<00:23, 350.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2501/10570 [00:06<00:24, 335.54it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2535/10570 [00:07<00:23, 336.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|âââ       | 2569/10570 [00:07<00:24, 327.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 2606/10570 [00:07<00:23, 338.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 2645/10570 [00:07<00:22, 350.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|âââ       | 2681/10570 [00:07<00:22, 351.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2719/10570 [00:07<00:21, 357.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2759/10570 [00:07<00:21, 367.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 26%|âââ       | 2796/10570 [00:07<00:21, 367.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 2834/10570 [00:07<00:20, 369.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|âââ       | 2871/10570 [00:08<00:21, 365.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 2908/10570 [00:08<00:21, 361.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 2945/10570 [00:08<00:20, 363.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|âââ       | 2982/10570 [00:08<00:20, 361.96it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 3019/10570 [00:08<00:20, 363.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 3056/10570 [00:08<00:20, 360.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|âââ       | 3093/10570 [00:08<00:20, 358.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3129/10570 [00:08<00:20, 358.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3165/10570 [00:08<00:20, 353.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|âââ       | 3201/10570 [00:08<00:21, 347.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 3236/10570 [00:09<00:21, 345.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|âââ       | 3271/10570 [00:09<00:21, 347.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|ââââ      | 3307/10570 [00:09<00:20, 348.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3344/10570 [00:09<00:20, 354.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3380/10570 [00:09<00:20, 354.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|ââââ      | 3416/10570 [00:09<00:20, 348.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3453/10570 [00:09<00:20, 352.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3489/10570 [00:09<00:20, 347.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|ââââ      | 3526/10570 [00:09<00:20, 351.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3562/10570 [00:09<00:19, 352.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3598/10570 [00:10<00:19, 348.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|ââââ      | 3635/10570 [00:10<00:19, 352.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3671/10570 [00:10<00:19, 354.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3707/10570 [00:10<00:19, 353.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|ââââ      | 3743/10570 [00:10<00:19, 351.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 3780/10570 [00:10<00:19, 355.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 3816/10570 [00:10<00:19, 349.59it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|ââââ      | 3852/10570 [00:10<00:19, 352.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3888/10570 [00:10<00:18, 353.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3924/10570 [00:11<00:18, 352.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|ââââ      | 3960/10570 [00:11<00:18, 353.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 3996/10570 [00:11<00:18, 353.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 4032/10570 [00:11<00:18, 353.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|ââââ      | 4069/10570 [00:11<00:18, 357.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4105/10570 [00:11<00:18, 345.71it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4140/10570 [00:11<00:19, 329.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|ââââ      | 4174/10570 [00:11<00:23, 268.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4203/10570 [00:11<00:26, 239.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4230/10570 [00:12<00:25, 246.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|ââââ      | 4259/10570 [00:12<00:24, 256.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4286/10570 [00:12<00:32, 192.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4309/10570 [00:12<00:34, 183.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|ââââ      | 4343/10570 [00:12<00:29, 212.98it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|âââââ     | 4379/10570 [00:12<00:25, 241.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4410/10570 [00:12<00:23, 257.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4447/10570 [00:12<00:21, 282.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|âââââ     | 4485/10570 [00:13<00:19, 304.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4518/10570 [00:13<00:19, 306.60it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4551/10570 [00:13<00:19, 311.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 43%|âââââ     | 4585/10570 [00:13<00:18, 319.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4618/10570 [00:13<00:19, 311.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4650/10570 [00:13<00:19, 302.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|âââââ     | 4683/10570 [00:13<00:19, 308.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4720/10570 [00:13<00:18, 324.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4755/10570 [00:13<00:17, 326.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|âââââ     | 4788/10570 [00:14<00:18, 311.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4825/10570 [00:14<00:17, 327.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4859/10570 [00:14<00:18, 308.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|âââââ     | 4896/10570 [00:14<00:17, 322.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 4932/10570 [00:14<00:16, 331.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 4967/10570 [00:14<00:16, 335.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|âââââ     | 5001/10570 [00:14<00:16, 328.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5035/10570 [00:14<00:16, 331.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5071/10570 [00:14<00:16, 337.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|âââââ     | 5106/10570 [00:14<00:16, 339.02it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5142/10570 [00:15<00:15, 343.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5177/10570 [00:15<00:15, 343.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|âââââ     | 5213/10570 [00:15<00:15, 345.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5248/10570 [00:15<00:15, 345.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5284/10570 [00:15<00:15, 349.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|âââââ     | 5321/10570 [00:15<00:14, 353.60it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 5357/10570 [00:15<00:14, 349.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|âââââ     | 5393/10570 [00:15<00:14, 350.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|ââââââ    | 5429/10570 [00:15<00:14, 348.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5464/10570 [00:15<00:15, 322.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5497/10570 [00:16<00:16, 310.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|ââââââ    | 5529/10570 [00:16<00:16, 313.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5563/10570 [00:16<00:15, 318.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5598/10570 [00:16<00:15, 326.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|ââââââ    | 5631/10570 [00:16<00:15, 323.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5664/10570 [00:16<00:15, 308.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5701/10570 [00:16<00:15, 322.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|ââââââ    | 5736/10570 [00:16<00:14, 328.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5770/10570 [00:16<00:14, 328.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5804/10570 [00:17<00:14, 330.59it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|ââââââ    | 5839/10570 [00:17<00:14, 335.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5873/10570 [00:17<00:13, 335.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5908/10570 [00:17<00:13, 338.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|ââââââ    | 5943/10570 [00:17<00:13, 339.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 5978/10570 [00:17<00:13, 341.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 6013/10570 [00:17<00:13, 335.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 57%|ââââââ    | 6047/10570 [00:17<00:13, 335.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6081/10570 [00:17<00:13, 327.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6114/10570 [00:17<00:13, 325.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|ââââââ    | 6151/10570 [00:18<00:13, 335.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6186/10570 [00:18<00:13, 337.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6220/10570 [00:18<00:12, 336.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|ââââââ    | 6254/10570 [00:18<00:13, 319.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6290/10570 [00:18<00:13, 328.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6325/10570 [00:18<00:12, 333.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6359/10570 [00:18<00:12, 334.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|ââââââ    | 6393/10570 [00:18<00:12, 322.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 6430/10570 [00:18<00:12, 333.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|ââââââ    | 6468/10570 [00:19<00:11, 343.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6503/10570 [00:19<00:11, 344.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6538/10570 [00:19<00:11, 345.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|âââââââ   | 6573/10570 [00:19<00:11, 344.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6608/10570 [00:19<00:11, 339.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6645/10570 [00:19<00:11, 346.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|âââââââ   | 6680/10570 [00:19<00:11, 344.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6715/10570 [00:19<00:11, 334.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6751/10570 [00:19<00:11, 341.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|âââââââ   | 6787/10570 [00:19<00:10, 345.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6822/10570 [00:20<00:11, 340.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6857/10570 [00:20<00:10, 338.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|âââââââ   | 6891/10570 [00:20<00:10, 335.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 6926/10570 [00:20<00:10, 338.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 6963/10570 [00:20<00:10, 344.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|âââââââ   | 6999/10570 [00:20<00:10, 349.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 7034/10570 [00:20<00:10, 348.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 7069/10570 [00:20<00:10, 348.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|âââââââ   | 7105/10570 [00:20<00:09, 350.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7141/10570 [00:20<00:09, 352.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7177/10570 [00:21<00:09, 352.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|âââââââ   | 7213/10570 [00:21<00:09, 349.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7248/10570 [00:21<00:09, 345.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7283/10570 [00:21<00:09, 344.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|âââââââ   | 7320/10570 [00:21<00:09, 348.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7355/10570 [00:21<00:10, 313.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7388/10570 [00:21<00:10, 317.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|âââââââ   | 7425/10570 [00:21<00:09, 330.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 7459/10570 [00:21<00:09, 332.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 7494/10570 [00:22<00:09, 337.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|âââââââ   | 7530/10570 [00:22<00:08, 343.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7565/10570 [00:22<00:08, 344.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7601/10570 [00:22<00:08, 348.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|ââââââââ  | 7637/10570 [00:22<00:08, 349.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7673/10570 [00:22<00:08, 335.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7709/10570 [00:22<00:08, 341.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|ââââââââ  | 7744/10570 [00:22<00:08, 338.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7778/10570 [00:22<00:08, 323.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7811/10570 [00:22<00:08, 311.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 74%|ââââââââ  | 7845/10570 [00:23<00:08, 318.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7881/10570 [00:23<00:08, 328.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7918/10570 [00:23<00:07, 337.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|ââââââââ  | 7954/10570 [00:23<00:07, 342.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 7989/10570 [00:23<00:07, 340.67it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 8024/10570 [00:23<00:07, 342.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|ââââââââ  | 8059/10570 [00:23<00:07, 332.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8096/10570 [00:23<00:07, 341.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8132/10570 [00:23<00:07, 345.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|ââââââââ  | 8167/10570 [00:24<00:07, 337.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8201/10570 [00:24<00:07, 332.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8235/10570 [00:24<00:07, 329.62it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|ââââââââ  | 8269/10570 [00:24<00:07, 327.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8302/10570 [00:24<00:07, 314.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8335/10570 [00:24<00:07, 318.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|ââââââââ  | 8371/10570 [00:24<00:06, 329.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8406/10570 [00:24<00:06, 332.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8443/10570 [00:24<00:06, 341.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|ââââââââ  | 8480/10570 [00:24<00:06, 347.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 8515/10570 [00:25<00:05, 347.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 8551/10570 [00:25<00:05, 350.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|ââââââââ  | 8587/10570 [00:25<00:05, 345.81it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8623/10570 [00:25<00:05, 349.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8659/10570 [00:25<00:05, 346.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|âââââââââ | 8696/10570 [00:25<00:05, 351.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8732/10570 [00:25<00:05, 344.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8767/10570 [00:25<00:05, 339.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|âââââââââ | 8802/10570 [00:25<00:05, 337.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8837/10570 [00:26<00:05, 338.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8873/10570 [00:26<00:04, 342.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|âââââââââ | 8908/10570 [00:26<00:04, 342.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 8944/10570 [00:26<00:04, 346.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 8980/10570 [00:26<00:04, 349.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|âââââââââ | 9016/10570 [00:26<00:04, 350.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 9052/10570 [00:26<00:04, 344.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 9087/10570 [00:26<00:04, 342.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%|âââââââââ | 9122/10570 [00:26<00:04, 343.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9157/10570 [00:26<00:04, 343.54it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9193/10570 [00:27<00:03, 347.72it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|âââââââââ | 9228/10570 [00:27<00:03, 347.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9265/10570 [00:27<00:03, 352.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9301/10570 [00:27<00:03, 350.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|âââââââââ | 9337/10570 [00:27<00:03, 347.88it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9373/10570 [00:27<00:03, 350.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9409/10570 [00:27<00:03, 348.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|âââââââââ | 9444/10570 [00:27<00:03, 347.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9480/10570 [00:27<00:03, 349.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9516/10570 [00:27<00:03, 350.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%|âââââââââ | 9552/10570 [00:28<00:02, 341.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 9587/10570 [00:28<00:02, 342.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|âââââââââ | 9624/10570 [00:28<00:02, 347.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|ââââââââââ| 9660/10570 [00:28<00:02, 349.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9697/10570 [00:28<00:02, 352.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9734/10570 [00:28<00:02, 357.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|ââââââââââ| 9770/10570 [00:28<00:02, 356.75it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9806/10570 [00:28<00:02, 351.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9842/10570 [00:28<00:02, 343.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|ââââââââââ| 9878/10570 [00:28<00:01, 347.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9913/10570 [00:29<00:01, 345.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9950/10570 [00:29<00:01, 350.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|ââââââââââ| 9986/10570 [00:29<00:01, 344.05it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 10022/10570 [00:29<00:01, 347.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|ââââââââââ| 10059/10570 [00:29<00:01, 351.36it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10095/10570 [00:29<00:01, 346.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10131/10570 [00:29<00:01, 350.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|ââââââââââ| 10167/10570 [00:29<00:01, 335.80it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10203/10570 [00:29<00:01, 341.01it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10240/10570 [00:30<00:00, 346.84it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|ââââââââââ| 10275/10570 [00:30<00:00, 345.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10311/10570 [00:30<00:00, 347.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10347/10570 [00:30<00:00, 349.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|ââââââââââ| 10383/10570 [00:30<00:00, 345.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10418/10570 [00:30<00:00, 342.60it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10453/10570 [00:30<00:00, 341.03it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|ââââââââââ| 10488/10570 [00:30<00:00, 335.66it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 10523/10570 [00:30<00:00, 339.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 10557/10570 [00:31<00:00, 279.54it/s]#033[A#015100%|ââââââââââ| 10570/10570 [00:31<00:00, 340.08it/s]\u001b[0m\n",
      "\u001b[34m01/14/2021 16:09:28 - INFO - nn_pruning.examples.question_answering.qa_utils -   Saving predictions to /opt/ml/model/checkpoint-554/predictions.json.\u001b[0m\n",
      "\u001b[34m01/14/2021 16:09:28 - INFO - nn_pruning.examples.question_answering.qa_utils -   Saving nbest_preds to /opt/ml/model/checkpoint-554/nbest_predictions.json.\u001b[0m\n",
      "\u001b[34m01/14/2021 16:09:34 - INFO - /opt/conda/lib/python3.6/site-packages/datasets/metric.py -   Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m#015100%|ââââââââââ| 1348/1348 [03:38<00:00,  6.16it/s]\u001b[0m\n",
      "\u001b[34m01/14/2021 16:09:34 - INFO - nn_pruning.examples.question_answering.qa_train -   ***** Eval results *****\u001b[0m\n",
      "\u001b[34m01/14/2021 16:09:34 - INFO - nn_pruning.examples.question_answering.qa_train -     exact_match = 21.021759697256385\u001b[0m\n",
      "\u001b[34m01/14/2021 16:09:34 - INFO - nn_pruning.examples.question_answering.qa_train -     f1 = 35.3024313287419\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-01-14 16:09:56 Uploading - Uploading generated training model\n",
      "2021-01-14 16:11:17 Completed - Training job completed\n",
      "ProfilerReport-1610639113: IssuesFound\n",
      "Training seconds: 1418\n",
      "Billable seconds: 1418\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Estimator\n",
    "\n",
    "The following code sample shows how you train a custom HuggingFace script `train.py`, passing in three hyperparameters (`epochs`,`train_batch_size`,`model_name`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface.estimator import HuggingFace\n",
    "\n",
    "\n",
    "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
    "                            source_dir='../scripts',\n",
    "                            sagemaker_session=sess,\n",
    "                            base_job_name='huggingface-sdk-extension',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            framework_version={'transformers':'4.1.1','datasets':'1.1.3'},\n",
    "                            py_version='py3',\n",
    "                            hyperparameters = {'epochs': 1,\n",
    "                                               'train_batch_size': 32,\n",
    "                                               'model_name':'distilbert-base-uncased'\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get S3 url for model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get latest training job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach to old estimator \n",
    "\n",
    "e.g. to get model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_job_name='huggingface-sdk-extension-2020-12-27-15-25-50-506'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator_loaded = Estimator.attach(old_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_loaded.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model from s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using huggingface utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface.utils import download_model\n",
    "\n",
    "download_model(model_data=huggingface_estimator_loaded.model_data,\n",
    "               unzip=True,\n",
    "               model_dir=huggingface_estimator_loaded.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using class built-in method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.download_model(unzip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access logs\n",
    "\n",
    "until [PR](https://github.com/aws/sagemaker-python-sdk/pull/2059) is merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.sagemaker_session.logs_for_job(huggingface_estimator.latest_training_job.name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**after merged PR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.logs()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
