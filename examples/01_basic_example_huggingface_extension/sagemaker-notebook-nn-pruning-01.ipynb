{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Sagemaker-sdk extension example using `Trainer` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Sagemaker Session with local AWS Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From outside these notebooks, `get_execution_role()` will return an exception because it does not know what is the role name that SageMaker requires.\n",
    "\n",
    "To solve this issue, pass the IAM role name instead of using `get_execution_role()`.\n",
    "\n",
    "Therefore you have to create an IAM-Role with correct permission for sagemaker to start training jobs and download files from s3. Beware that you need s3 permission on bucket-level `\"arn:aws:s3:::sagemaker-*\"` and on object-level     `\"arn:aws:s3:::sagemaker-*/*\"`. \n",
    "\n",
    "You can read [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) how to create a role with right permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local aws profile configured in ~/.aws/credentials\n",
    "local_profile_name='default' # optional if you only have default configured\n",
    "\n",
    "# role name for sagemaker -> needs the described permissions from above\n",
    "role_name = \"AmazonSageMaker-ExecutionRole-20201222T210251\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name lagunas to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::854676674973:role/service-role/AmazonSageMaker-ExecutionRole-20201222T210251\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "try:\n",
    "    sess = sagemaker.Session()\n",
    "    role = sagemaker.get_execution_role()\n",
    "except Exception:\n",
    "    import boto3\n",
    "    # creates a boto3 session using the local profile we defined\n",
    "    if local_profile_name:\n",
    "        os.environ['AWS_PROFILE'] = local_profile_name # setting env var bc local-mode cannot use boto3 session\n",
    "        #bt3 = boto3.session.Session(profile_name=local_profile_name)\n",
    "        #iam = bt3.client('iam')\n",
    "        # create sagemaker session with boto3 session\n",
    "        #sess = sagemaker.Session(boto_session=bt3)\n",
    "    iam = boto3.client('iam')\n",
    "    sess = sagemaker.Session()\n",
    "    # get role arn\n",
    "    role = iam.get_role(RoleName=role_name)['Role']['Arn']\n",
    "    \n",
    "\n",
    "\n",
    "print(role)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Session prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/imdb/test/dataset.arrow', 'datasets/imdb/test/dataset_info.json', 'datasets/imdb/test/state.json', 'datasets/imdb/train/dataset.arrow', 'datasets/imdb/train/dataset_info.json', 'datasets/imdb/train/state.json']\n",
      "sagemaker-eu-west-1-854676674973\n",
      "eu-west-1\n"
     ]
    }
   ],
   "source": [
    "print(sess.list_s3_files(sess.default_bucket(),'datasets/')) # list objects in s3 under datsets/\n",
    "print(sess.default_bucket()) # s3 bucketname\n",
    "print(sess.boto_region_name) # aws region of sagemaker session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Since we are using the `.py` module directly from `huggingface/` we have to adjust our `sys.path` to be able to import our estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to sagemaker S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an local estimator for testing\n",
    "\n",
    "You run PyTorch training scripts on SageMaker by creating PyTorch Estimators. SageMaker training of your script is invoked when you call fit on a PyTorch Estimator. The following code sample shows how you train a custom PyTorch script `train.py`, passing in three hyperparameters (`epochs`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`\n",
    "\n",
    "in sagemaker you can test you training in a \"local-mode\" by setting your instance_type to `'local'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing custom sdk-extension for HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface.estimator import HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an local Estimator\n",
    "\n",
    "The following code sample shows how you train a custom HuggingFace script `train.py`, passing in three hyperparameters (`epochs`,`train_batch_size`,`model_name`). We are not going to pass any data into sagemaker training job instead it will be downloaded in `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAX_DELETE_ALL_ATTEMPTS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_boto_create_method', '_boto_delete_members', '_boto_delete_method', '_boto_ignore', '_boto_list_method', '_boto_load_method', '_boto_update_members', '_boto_update_method', '_construct', '_custom_boto_names', '_custom_boto_types', '_invoke_api', '_list', '_search', 'create', 'create_trial', 'delete', 'delete_all', 'description', 'experiment_name', 'from_boto', 'list', 'list_trials', 'load', 'sagemaker_boto_client', 'save', 'search', 'tags', 'to_boto', 'with_boto']\n",
      "2021-01-24 15:44:17,544 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f5d3197b790>,experiment_name='nn-pruning-v11',description=None,tags=None,experiment_arn='arn:aws:sagemaker:eu-west-1:854676674973:experiment/nn-pruning-v11',response_metadata={'RequestId': 'c4da4c18-5fd7-4a37-bcf7-e8a66fe2a55b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'c4da4c18-5fd7-4a37-bcf7-e8a66fe2a55b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '86', 'date': 'Sun, 24 Jan 2021 14:44:16 GMT'}, 'RetryAttempts': 0})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "#boto3\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "VERSION=\"v11\"\n",
    "\n",
    "if local_profile_name:\n",
    "    os.environ['AWS_PROFILE'] = local_profile_name # setting env var bc local-mode cannot use boto3 session\n",
    "    \n",
    "ex_sm_sess = boto3.client('sagemaker')\n",
    "sess_experiment = Experiment(sagemaker_boto_client=ex_sm_sess)\n",
    "\n",
    "print(dir(sess_experiment))\n",
    "experiment = sess_experiment.create(experiment_name='nn-pruning-'+VERSION) # ^[a-zA-Z0-9](-*[a-zA-Z0-9]){0,119}\n",
    "#experiment = sess_experiment.load(experiment_name='nn-pruning-'+VERSION) # ^[a-zA-Z0-9](-*[a-zA-Z0-9]){0,119}\n",
    "\n",
    "print(experiment)\n",
    "\n",
    "print()\n",
    "\n",
    "for trial in experiment.list_trials():\n",
    "    print(\"Trial\", trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:45:00,914 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:45:00,918 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:45:26,919 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a16-l10-dl1--2021-01-24--15-45-00\n",
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:45:27,481 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:45:27,492 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:45:52,942 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a16-l20-dl1--2021-01-24--15-45-27\n",
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:45:53,534 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:45:53,546 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:46:19,786 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a16-l40-dl1--2021-01-24--15-45-53\n",
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:46:20,430 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:46:20,439 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:46:47,125 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a8-l10-dl1--2021-01-24--15-46-20\n",
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:46:47,621 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:46:47,633 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:47:14,614 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a8-l20-dl1--2021-01-24--15-46-47\n",
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:47:15,219 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:47:15,236 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:47:41,610 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a8-l40-dl1--2021-01-24--15-47-15\n",
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:47:42,183 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:47:42,188 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:48:08,623 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a4-l10-dl1--2021-01-24--15-47-42\n",
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:48:09,181 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:48:09,192 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:48:35,024 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a4-l20-dl1--2021-01-24--15-48-09\n",
      "nn-pruning-v11\n",
      "IMAGE_URI 854676674973.dkr.ecr.eu-west-1.amazonaws.com/huggingface-nn-pruning-training:0.0.1-gpu-transformers4.1.1-datasets1.1.3-cu110\n",
      "2021-01-24 15:48:35,538 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-01-24 15:48:35,550 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2021-01-24 15:49:02,456 - sagemaker - INFO - Creating training-job with name: nn-pruning-v11-a4-l40-dl1--2021-01-24--15-48-35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "local = False\n",
    "if local:\n",
    "    instance_type = \"local\"\n",
    "    sess = None\n",
    "    batch_size = 1\n",
    "    num_train_epochs = 0.0005\n",
    "    logging_steps=20\n",
    "else:\n",
    "    instance_type = \"ml.p3.2xlarge\"\n",
    "    sagemaker_session=sess\n",
    "    batch_size = 16\n",
    "    num_train_epochs=20\n",
    "    logging_steps=250\n",
    "    \n",
    "    \n",
    "def build_metric_definitions():\n",
    "    ret = []\n",
    "    train_metrics = ['loss',\n",
    " 'learning_rate',\n",
    " 'threshold',\n",
    " 'ampere_temperature',\n",
    " 'regu_lambda',\n",
    " 'ce_loss',\n",
    " 'distil_loss',\n",
    " 'nnz_perc_attention',\n",
    " 'regu_loss_attention',\n",
    " 'nnz_perc_dense',\n",
    " 'regu_loss_dense',\n",
    " 'regu_loss',\n",
    " 'nnz_perc',\n",
    " 'epoch']\n",
    "    eval_metrics = [\"f1\", \"exact_match\"]\n",
    "        \n",
    "    metric_types = {\"train\":(\"\",train_metrics), \"validation\":(\"eval_\", eval_metrics)}\n",
    "    for k, (prefix, metrics) in metric_types.items():\n",
    "        for m in metrics:\n",
    "            ret += {'Name': f\"{k}:{m}\", 'Regex':f\"'{prefix}{m}': (.*?)[,\"+\"}]\"},\n",
    "    return ret\n",
    "        \n",
    "    \n",
    "metric_definitions = build_metric_definitions()\n",
    "\n",
    "from nn_pruning.examples.question_answering.qa_sparse_xp import SparseQAShortNamer\n",
    "\n",
    "def now_aws_string():\n",
    "    from datetime import datetime\n",
    "    return str(datetime.now()).replace(\" \", \"--\").replace(\":\", \"-\").split(\".\")[0]\n",
    "\n",
    "def estimator_run(attention:int, regu_lambda:float, dense_lambda:float, wait=True, use_spot=False):\n",
    "    # defines trial_name in given input\n",
    "    trial_name = f\"nn-pruning-{VERSION}-a{attention}-l{regu_lambda}-dl{dense_lambda}--{now_aws_string()}\"\n",
    "    trial_name = trial_name.replace(\".0\", \"\").replace(\".\", \"-\")\n",
    "    \n",
    "    # creates trial for our experiment\n",
    "    trial = experiment.create_trial(trial_name=trial_name)\n",
    "        \n",
    "    dense = attention\n",
    "    hyperparameters = {\"attention_block_rows\":attention,\n",
    "                       \"attention_block_cols\":attention,\n",
    "                       \"dense_block_rows\":dense,\n",
    "                       \"dense_block_cols\":dense,\n",
    "                       \"regularization_final_lambda\": regu_lambda,\n",
    "                       \"num_train_epochs\":num_train_epochs,\n",
    "                       \"logging_steps\":logging_steps,\n",
    "                       \"per_device_train_batch_size\":batch_size,\n",
    "                       \"dense_lambda\":dense_lambda,\n",
    "                       \"dense_pruning_method\":\"sigmoied_threshold\"}\n",
    "    \n",
    "    hyperparameters = {k.replace(\"_\", \"-\"):v for k,v in hyperparameters.items()}\n",
    "\n",
    "    def get_hp_name(hyper_parameters):\n",
    "        p = {k.replace(\"-\", \"_\"):v for k,v in hyper_parameters.items()}    \n",
    "\n",
    "        sn = SparseQAShortNamer()\n",
    "\n",
    "        ret = sn.shortname(p)\n",
    "        return ret\n",
    "\n",
    "    base_job_name = \"nn-pruning-\" + VERSION #+ get_hp_name(hyperparameters)[3:].replace(\".\", \"-\")\n",
    "    print(base_job_name)\n",
    "    \n",
    "    \n",
    "    if use_spot:\n",
    "        checkpoint_s3_uri = f\"s3://sagemaker-eu-west-1-854676674973/{trial_name}/checkpoint/\"\n",
    "        additional = dict(use_spot_instances=True,\n",
    "                          max_wait=3600, \n",
    "                          checkpoint_local_path=\"/opt/local/model\",\n",
    "                          checkpoint_s3_uri = checkpoint_s3_uri\n",
    "                         )\n",
    "    else:\n",
    "        additional = {}\n",
    "\n",
    "    estimator = HuggingFace(entry_point='nn_pruning_train.py',\n",
    "                            source_dir='../scripts',\n",
    "                            sagemaker_session=sess,\n",
    "                            tags = [{'Key': 'name', 'Value': \"nn-pruning\"},\n",
    "                                    {\"Key\":\"version\", \"Value\": VERSION}],\n",
    "                            base_job_name=base_job_name,\n",
    "                            volume_size=300,\n",
    "                            instance_type=instance_type,\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            framework_version={'transformers':'4.1.1','datasets':'1.1.3'},\n",
    "                            py_version='py3',\n",
    "                            metric_definitions = metric_definitions,\n",
    "                            hyperparameters = hyperparameters,\n",
    "                             **additional)\n",
    "    \n",
    "    estimator.fit(job_name=trial_name,\n",
    "        experiment_config={\n",
    "            \"TrialName\": trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "        wait = wait\n",
    "    )\n",
    "        \n",
    "    \n",
    "    return estimator\n",
    "\n",
    "estimators = []\n",
    "\n",
    "attentions = [16, 8, 4]\n",
    "regu_lambdas = [10, 20, 40]\n",
    "dense_lambdas = [1.0]\n",
    "use_spot = False\n",
    "for i, attention in enumerate(attentions):\n",
    "    for j, regu_lambda in enumerate(regu_lambdas):\n",
    "        for dense_lambda in dense_lambdas:\n",
    "            estimator = estimator_run(attention, regu_lambda, dense_lambda, wait = False, use_spot=use_spot)\n",
    "#        print(estimator)\n",
    "#        estimator.fit(wait = True)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for exp in Experiment.list():\n",
    "#    print(exp)\n",
    "for trial in experiment.list_trials():\n",
    "    print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = False\n",
    "if delete:\n",
    "    experiment.delete_all(action=\"--force\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get latest training job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach to old estimator \n",
    "\n",
    "e.g. to get model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_job_name='huggingface-sdk-extension-2020-12-27-15-25-50-506'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator_loaded = Estimator.attach(old_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator_loaded.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model from s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using huggingface utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface.utils import download_model\n",
    "\n",
    "download_model(model_data=huggingface_estimator_loaded.model_data,\n",
    "               unzip=True,\n",
    "               model_dir=huggingface_estimator_loaded.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using class built-in method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.download_model(unzip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access logs\n",
    "\n",
    "until [PR](https://github.com/aws/sagemaker-python-sdk/pull/2059) is merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.sagemaker_session.logs_for_job(huggingface_estimator.latest_training_job.name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**after merged PR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"attention_block_rows\":attention,\n",
    "                   \"attention_block_cols\":attention,\n",
    "                   \"regularization_final_lambda\": regu_lambda,\n",
    "                   \"num_train_epochs\":num_train_epochs,\n",
    "                   \"logging_steps\":logging_steps,\n",
    "                   \"per_device_train_batch_size\":batch_size}\n",
    "hp2 = {k.replace(\"-\", \"_\"):v for k,v in hyperparameters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-01-15--14-57-42'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "str(datetime.now()).replace(\" \", \"--\").replace(\":\", \"-\").split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
